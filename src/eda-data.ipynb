{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data\n",
    "**Author:** Jane Hung  \n",
    "**Date:** 1 Mar 2020  \n",
    "**Citations:**  \n",
    "@inproceedings{xu_bert2019,\n",
    "    title = \"BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis\",\n",
    "    author = \"Xu, Hu and Liu, Bing and Shu, Lei and Yu, Philip S.\",\n",
    "    booktitle = \"Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics\",\n",
    "    year = \"2019\",\n",
    "}  \n",
    "https://drive.google.com/file/d/1NGH5bqzEx6aDlYJ7O3hepZF4i_p4iMR8/view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pprint\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import io\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.backend import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel, pipeline\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import log_loss, confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(filename):\n",
    "    f = open(filename,'r')\n",
    "    data = json.loads(f.read())\n",
    "    print('\\n',filename)\n",
    "    pprint.pprint(dict(list(data.items())[:1]))\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ../data/hu-data/ae/laptop/train.json\n",
      "{'0': {'label': ['B',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'B',\n",
      "                 'I',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O'],\n",
      "       'sentence': ['Keyboard',\n",
      "                    'is',\n",
      "                    'great',\n",
      "                    'but',\n",
      "                    'primary',\n",
      "                    'and',\n",
      "                    'secondary',\n",
      "                    'control',\n",
      "                    'buttons',\n",
      "                    'could',\n",
      "                    'be',\n",
      "                    'more',\n",
      "                    'durable',\n",
      "                    '.']}}\n",
      "\n",
      " ../data/hu-data/ae/rest/train.json\n",
      "{'0': {'label': ['O', 'O', 'O', 'B'],\n",
      "       'sentence': ['I', 'LOVE', 'their', 'Thai']}}\n",
      "\n",
      " ../data/hu-data/asc/laptop/train.json\n",
      "{'327_0': {'id': '327_0',\n",
      "           'polarity': 'positive',\n",
      "           'sentence': 'Also it is very good for college students who just '\n",
      "                       'need a reliable, easy to use computer.',\n",
      "           'term': 'use'}}\n",
      "\n",
      " ../data/hu-data/asc/rest/train.json\n",
      "{'1592_0': {'id': '1592_0',\n",
      "            'polarity': 'positive',\n",
      "            'sentence': 'Our server was very helpful and friendly.',\n",
      "            'term': 'server'}}\n"
     ]
    }
   ],
   "source": [
    "ae_laptop_train = read_json('../data/hu-data/ae/laptop/train.json')\n",
    "ae_rest_train = read_json('../data/hu-data/ae/rest/train.json')\n",
    "\n",
    "\n",
    "asc_laptop_train = read_json('../data/hu-data/asc/laptop/train.json')\n",
    "asc_rest_train = read_json('../data/hu-data/asc/rest/train.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ../data/hu-data/ae/laptop/dev.json\n",
      "{'0': {'label': ['O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O'],\n",
      "       'sentence': ['I',\n",
      "                    'have',\n",
      "                    'had',\n",
      "                    'this',\n",
      "                    'laptop',\n",
      "                    'for',\n",
      "                    'a',\n",
      "                    'few',\n",
      "                    'months',\n",
      "                    'now',\n",
      "                    'and',\n",
      "                    'i',\n",
      "                    'would',\n",
      "                    'say',\n",
      "                    'im',\n",
      "                    'pretty',\n",
      "                    'satisfied',\n",
      "                    '.']}}\n",
      "\n",
      " ../data/hu-data/ae/rest/dev.json\n",
      "{'0': {'label': ['O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'B',\n",
      "                 'I',\n",
      "                 'I',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O'],\n",
      "       'sentence': ['In',\n",
      "                    'the',\n",
      "                    'summer',\n",
      "                    'months',\n",
      "                    ',',\n",
      "                    'the',\n",
      "                    'back',\n",
      "                    'garden',\n",
      "                    'area',\n",
      "                    'is',\n",
      "                    'really',\n",
      "                    'nice',\n",
      "                    '.']}}\n",
      "\n",
      " ../data/hu-data/asc/laptop/dev.json\n",
      "{'1113_0': {'id': '1113_0',\n",
      "            'polarity': 'negative',\n",
      "            'sentence': 'Not even safe mode boots.',\n",
      "            'term': 'safe mode'}}\n",
      "\n",
      " ../data/hu-data/asc/rest/dev.json\n",
      "{'2516_0': {'id': '2516_0',\n",
      "            'polarity': 'positive',\n",
      "            'sentence': \"This is the only Thai place I go too in NYC, it's \"\n",
      "                        'wonderful, and live relaxed Jazz on certain nights.',\n",
      "            'term': 'Jazz'}}\n"
     ]
    }
   ],
   "source": [
    "ae_laptop_dev  = read_json('../data/hu-data/ae/laptop/dev.json')\n",
    "ae_rest_dev = read_json('../data/hu-data/ae/rest/dev.json')\n",
    "\n",
    "\n",
    "asc_laptop_dev = read_json('../data/hu-data/asc/laptop/dev.json')\n",
    "asc_rest_dev = read_json('../data/hu-data/asc/rest/dev.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ../data/hu-data/ae/laptop/test.json\n",
      "{'0': {'label': ['B',\n",
      "                 'I',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O'],\n",
      "       'sentence': ['Boot',\n",
      "                    'time',\n",
      "                    'is',\n",
      "                    'super',\n",
      "                    'fast',\n",
      "                    ',',\n",
      "                    'around',\n",
      "                    'anywhere',\n",
      "                    'from',\n",
      "                    '35',\n",
      "                    'seconds',\n",
      "                    'to',\n",
      "                    '1',\n",
      "                    'minute',\n",
      "                    '.']}}\n",
      "\n",
      " ../data/hu-data/ae/rest/test.json\n",
      "{'0': {'label': ['O', 'O'], 'sentence': ['Yum', '!']}}\n",
      "\n",
      " ../data/hu-data/asc/laptop/test.json\n",
      "{'718:1_0': {'id': '718:1_0',\n",
      "             'polarity': 'positive',\n",
      "             'sentence': 'the retina display display make pictures i took '\n",
      "                         'years ago jaw dropping.',\n",
      "             'term': 'retina display display'}}\n",
      "\n",
      " ../data/hu-data/asc/rest/test.json\n",
      "{'11359619#487952#7_1': {'id': '11359619#487952#7_1',\n",
      "                         'polarity': 'positive',\n",
      "                         'sentence': 'for an appetizer, their calamari is a '\n",
      "                                     'winner.',\n",
      "                         'term': 'calamari'}}\n"
     ]
    }
   ],
   "source": [
    "ae_laptop_test  = read_json('../data/hu-data/ae/laptop/test.json')\n",
    "ae_rest_test = read_json('../data/hu-data/ae/rest/test.json')\n",
    "\n",
    "\n",
    "asc_laptop_test = read_json('../data/hu-data/asc/laptop/test.json')\n",
    "asc_rest_test = read_json('../data/hu-data/asc/rest/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[B, O, O, O, O, O, O, B, I, O, O, O, O, O]</td>\n",
       "      <td>[Keyboard, is, great, but, primary, and, secon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[I, bought, this, laptop, about, a, month, ago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[I, am, however, pleased, that, it, is, still,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[I, went, to, my, local, Best, Buy, looking, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[The, Apple, MC371LL/, A, 2.4Ghz, 15.4-, inch,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               label  \\\n",
       "0         [B, O, O, O, O, O, O, B, I, O, O, O, O, O]   \n",
       "1         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "2               [O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                            sentence  \n",
       "0  [Keyboard, is, great, but, primary, and, secon...  \n",
       "1  [I, bought, this, laptop, about, a, month, ago...  \n",
       "2  [I, am, however, pleased, that, it, is, still,...  \n",
       "3  [I, went, to, my, local, Best, Buy, looking, f...  \n",
       "4  [The, Apple, MC371LL/, A, 2.4Ghz, 15.4-, inch,...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_laptop_train_df = pd.DataFrame.from_dict(ae_laptop_train,orient='index')\n",
    "ae_laptop_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[I, have, had, this, laptop, for, a, few, mont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...</td>\n",
       "      <td>[Additional, caveat, :, the, base, installatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...</td>\n",
       "      <td>[it, is, of, high, quality, ,, has, a, killer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[O, B, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[The, screen, gets, smeary, and, dusty, very, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[I, previously, owned, an, HP, desktop, and, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               label  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1  [O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...   \n",
       "2  [O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...   \n",
       "3         [O, B, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                  [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                            sentence  \n",
       "0  [I, have, had, this, laptop, for, a, few, mont...  \n",
       "1  [Additional, caveat, :, the, base, installatio...  \n",
       "2  [it, is, of, high, quality, ,, has, a, killer,...  \n",
       "3  [The, screen, gets, smeary, and, dusty, very, ...  \n",
       "4  [I, previously, owned, an, HP, desktop, and, a...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_laptop_dev_df = pd.DataFrame.from_dict(ae_laptop_dev,orient='index')\n",
    "ae_laptop_dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[Boot, time, is, super, fast, ,, around, anywh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[tech, support, would, not, fix, the, problem,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[O, O, O, O, O, O, O]</td>\n",
       "      <td>[but, in, resume, this, computer, rocks, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[B, I, O, O, O]</td>\n",
       "      <td>[Set, up, was, easy, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[O, O, O, O, O, B, I, O, B, I, O]</td>\n",
       "      <td>[Did, not, enjoy, the, new, Windows, 8, and, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               label  \\\n",
       "0      [B, I, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1  [B, I, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2                              [O, O, O, O, O, O, O]   \n",
       "3                                    [B, I, O, O, O]   \n",
       "4                  [O, O, O, O, O, B, I, O, B, I, O]   \n",
       "\n",
       "                                            sentence  \n",
       "0  [Boot, time, is, super, fast, ,, around, anywh...  \n",
       "1  [tech, support, would, not, fix, the, problem,...  \n",
       "2        [but, in, resume, this, computer, rocks, !]  \n",
       "3                            [Set, up, was, easy, .]  \n",
       "4  [Did, not, enjoy, the, new, Windows, 8, and, t...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_laptop_test_df = pd.DataFrame.from_dict(ae_laptop_test,orient='index')\n",
    "ae_laptop_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>term</th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>327_0</th>\n",
       "      <td>positive</td>\n",
       "      <td>use</td>\n",
       "      <td>327_0</td>\n",
       "      <td>Also it is very good for college students who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077_0</th>\n",
       "      <td>positive</td>\n",
       "      <td>noise</td>\n",
       "      <td>3077_0</td>\n",
       "      <td>For those that care about noise this thing doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592_1</th>\n",
       "      <td>positive</td>\n",
       "      <td>force</td>\n",
       "      <td>1592_1</td>\n",
       "      <td>Enjoy that Toshib force and durability unparal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329_0</th>\n",
       "      <td>negative</td>\n",
       "      <td>expense</td>\n",
       "      <td>329_0</td>\n",
       "      <td>I know that everyone thinks Macs are overprice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184_0</th>\n",
       "      <td>negative</td>\n",
       "      <td>word processor</td>\n",
       "      <td>1184_0</td>\n",
       "      <td>) And printing from either word processor is a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        polarity            term      id  \\\n",
       "327_0   positive             use   327_0   \n",
       "3077_0  positive           noise  3077_0   \n",
       "1592_1  positive           force  1592_1   \n",
       "329_0   negative         expense   329_0   \n",
       "1184_0  negative  word processor  1184_0   \n",
       "\n",
       "                                                 sentence  \n",
       "327_0   Also it is very good for college students who ...  \n",
       "3077_0  For those that care about noise this thing doe...  \n",
       "1592_1  Enjoy that Toshib force and durability unparal...  \n",
       "329_0   I know that everyone thinks Macs are overprice...  \n",
       "1184_0  ) And printing from either word processor is a...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asc_laptop_train_df = pd.DataFrame.from_dict(asc_laptop_train,orient='index')\n",
    "asc_laptop_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>term</th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1113_0</th>\n",
       "      <td>negative</td>\n",
       "      <td>safe mode</td>\n",
       "      <td>1113_0</td>\n",
       "      <td>Not even safe mode boots.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595_0</th>\n",
       "      <td>positive</td>\n",
       "      <td>Keyboard</td>\n",
       "      <td>2595_0</td>\n",
       "      <td>Keyboard was also very nice and had a solid feel.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039_0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Keyboard</td>\n",
       "      <td>1039_0</td>\n",
       "      <td>Keyboard is plastic and spongey feeling.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315_0</th>\n",
       "      <td>positive</td>\n",
       "      <td>quality</td>\n",
       "      <td>315_0</td>\n",
       "      <td>I would recommend this laptop to anyone lookin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284_0</th>\n",
       "      <td>negative</td>\n",
       "      <td>screen</td>\n",
       "      <td>1284_0</td>\n",
       "      <td>Thus, when you carry it at a slanted angle, th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        polarity       term      id  \\\n",
       "1113_0  negative  safe mode  1113_0   \n",
       "2595_0  positive   Keyboard  2595_0   \n",
       "1039_0  negative   Keyboard  1039_0   \n",
       "315_0   positive    quality   315_0   \n",
       "1284_0  negative     screen  1284_0   \n",
       "\n",
       "                                                 sentence  \n",
       "1113_0                          Not even safe mode boots.  \n",
       "2595_0  Keyboard was also very nice and had a solid feel.  \n",
       "1039_0           Keyboard is plastic and spongey feeling.  \n",
       "315_0   I would recommend this laptop to anyone lookin...  \n",
       "1284_0  Thus, when you carry it at a slanted angle, th...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asc_laptop_dev_df = pd.DataFrame.from_dict(asc_laptop_dev,orient='index')\n",
    "asc_laptop_dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>term</th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>718:1_0</th>\n",
       "      <td>positive</td>\n",
       "      <td>retina display display</td>\n",
       "      <td>718:1_0</td>\n",
       "      <td>the retina display display make pictures i too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217:1_1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>CD/DVD drive</td>\n",
       "      <td>217:1_1</td>\n",
       "      <td>Needs a CD/DVD drive and a bigger power switch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217:1_0</th>\n",
       "      <td>negative</td>\n",
       "      <td>power switch</td>\n",
       "      <td>217:1_0</td>\n",
       "      <td>Needs a CD/DVD drive and a bigger power switch.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044:1_0</th>\n",
       "      <td>negative</td>\n",
       "      <td>battery</td>\n",
       "      <td>1044:1_0</td>\n",
       "      <td>The battery is not as shown in the product pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040:1_0</th>\n",
       "      <td>negative</td>\n",
       "      <td>keyboard</td>\n",
       "      <td>1040:1_0</td>\n",
       "      <td>It feels cheap, the keyboard is not very sensi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          polarity                    term        id  \\\n",
       "718:1_0   positive  retina display display   718:1_0   \n",
       "217:1_1    neutral            CD/DVD drive   217:1_1   \n",
       "217:1_0   negative            power switch   217:1_0   \n",
       "1044:1_0  negative                 battery  1044:1_0   \n",
       "1040:1_0  negative                keyboard  1040:1_0   \n",
       "\n",
       "                                                   sentence  \n",
       "718:1_0   the retina display display make pictures i too...  \n",
       "217:1_1     Needs a CD/DVD drive and a bigger power switch.  \n",
       "217:1_0     Needs a CD/DVD drive and a bigger power switch.  \n",
       "1044:1_0  The battery is not as shown in the product pho...  \n",
       "1040:1_0  It feels cheap, the keyboard is not very sensi...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asc_laptop_test_df = pd.DataFrame.from_dict(asc_laptop_test,orient='index')\n",
    "asc_laptop_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with AE - BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14475"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO 5x the amount of training sentences for BERT to work with\n",
    "batch_sentences = [val['sentence'] for key, val in ae_laptop_train.items()]*5\n",
    "batch_sentences.extend([val['sentence'] for key, val in ae_laptop_dev.items()])\n",
    "batch_sentences.extend([val['sentence'] for key, val in ae_laptop_test.items()])\n",
    "train_size = len(ae_laptop_train)*5\n",
    "dev_size = len(ae_laptop_dev)\n",
    "test_size = len(ae_laptop_test)\n",
    "train_size\n",
    "dev_size\n",
    "test_size\n",
    "assert len(batch_sentences) == train_size+dev_size+test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15425"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_label = [val['label'] for key, val in ae_laptop_train.items()]*5\n",
    "batch_label.extend([val['label'] for key, val in ae_laptop_dev.items()])\n",
    "batch_label.extend([val['label'] for key, val in ae_laptop_test.items()])\n",
    "\n",
    "len(batch_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting for BERT as taken by course code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addWord(word, pos, ner):\n",
    "    \"\"\"\n",
    "    Convert a word into a word token and add supplied NER and POS labels. Note that the word can be  \n",
    "    tokenized to two or more tokens. Correspondingly, we add - for now - custom 'X' tokens to the labels in order to \n",
    "    maintain the 1:1 mappings between word tokens and labels.\n",
    "    \n",
    "    arguments: word, pos label, ner label\n",
    "    returns: dictionary with tokens and labels\n",
    "    \"\"\"\n",
    "    # the dataset contains various '\"\"\"' combinations which we choose to truncate to '\"', etc. \n",
    "    if word == '\"\"\"\"':\n",
    "        word = '\"'\n",
    "    elif word == '``':\n",
    "        word = '`'\n",
    "        \n",
    "    tokens = tokenizer.tokenize(word)\n",
    "    tokenLength = len(tokens)      # find number of tokens corresponfing to word to later add 'X' tokens to labels\n",
    "    \n",
    "    addDict = dict()\n",
    "    \n",
    "    addDict['wordToken'] = tokens\n",
    "    addDict['posToken'] = [pos] + ['posX'] * (tokenLength - 1)\n",
    "    addDict['nerToken'] = [ner] + ['nerX'] * (tokenLength - 1)\n",
    "    addDict['tokenLength'] = tokenLength\n",
    "    \n",
    "    return addDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists for sentences, tokens, labels, etc.  \n",
    "sentenceList = []\n",
    "sentenceTokenList = []\n",
    "posTokenList = []\n",
    "nerTokenList = []\n",
    "sentLengthList = []\n",
    "\n",
    "# lists for BERT input\n",
    "bertSentenceIDs = []\n",
    "bertMasks = []\n",
    "bertSequenceIDs = []\n",
    "\n",
    "sentence = ''\n",
    "\n",
    "# always start with [CLS] tokens\n",
    "sentenceTokens = ['[CLS]']\n",
    "posTokens = ['[posCLS]']\n",
    "nerTokens = ['[nerCLS]']\n",
    "\n",
    "for sentence,label in zip(batch_sentences,batch_label):\n",
    "    for ind,token in enumerate(sentence):\n",
    "        word, pos, ner = token, nltk.pos_tag(token),label[ind]\n",
    "\n",
    "        # if new sentence starts\n",
    "        if (ind == 0):            \n",
    "\n",
    "            sentenceLength = min(max_length -1, len(sentenceTokens))\n",
    "            sentLengthList.append(sentenceLength)\n",
    "\n",
    "            # Create space for at least a final '[SEP]' token\n",
    "            if sentenceLength >= max_length - 1: \n",
    "                sentenceTokens = sentenceTokens[:max_length - 2]\n",
    "                posTokens = posTokens[:max_length - 2]\n",
    "                nerTokens = nerTokens[:max_length - 2]\n",
    "\n",
    "            # add a ['SEP'] token and padding\n",
    "\n",
    "            sentenceTokens += ['[SEP]'] + ['[PAD]'] * (max_length -1 - len(sentenceTokens))\n",
    "\n",
    "            posTokens += ['[posSEP]'] + ['[posPAD]'] * (max_length - 1 - len(posTokens) )\n",
    "            nerTokens += ['[nerSEP]'] + ['[nerPAD]'] * (max_length - 1 - len(nerTokens) )\n",
    "\n",
    "            sentenceList.append(sentence)\n",
    "\n",
    "            sentenceTokenList.append(sentenceTokens)\n",
    "\n",
    "            bertSentenceIDs.append(tokenizer.convert_tokens_to_ids(sentenceTokens))\n",
    "            bertMasks.append([1] * (sentenceLength + 1) + [0] * (max_length -1 - sentenceLength ))\n",
    "            bertSequenceIDs.append([0] * (max_length))\n",
    "\n",
    "            posTokenList.append(posTokens)\n",
    "            nerTokenList.append(nerTokens)\n",
    "\n",
    "            sentence = ''\n",
    "            sentenceTokens = ['[CLS]']\n",
    "            posTokens = ['[posCLS]']\n",
    "            nerTokens = ['[nerCLS]']\n",
    "\n",
    "            sentence += ' ' + word\n",
    "\n",
    "        addDict = addWord(word, pos, ner)\n",
    "\n",
    "        sentenceTokens += addDict['wordToken']\n",
    "        posTokens += addDict['posToken']\n",
    "        nerTokens += addDict['nerToken']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'keyboard', 'is', 'great', 'but', 'primary', 'and', 'secondary', 'control', 'buttons', 'could', 'be', 'more', 'durable', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(sentenceTokenList[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[nerCLS]', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', '[nerSEP]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]']\n"
     ]
    }
   ],
   "source": [
    "print(nerTokenList[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertMasks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertSequenceIDs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.,   0.,  10., 187., 240., 358., 543., 500., 685., 686., 618.,\n",
       "        721., 743., 825., 761., 728., 714., 556., 565., 533., 462., 521.,\n",
       "        372., 387., 372., 433., 294., 295., 212., 179., 202., 165., 151.,\n",
       "        145., 140., 109., 105.,  77.,  73.,  87.,  68.,  64.,  60.,  55.,\n",
       "         36.,  50.,  41., 296.]),\n",
       " array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.,\n",
       "        27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39.,\n",
       "        40., 41., 42., 43., 44., 45., 46., 47., 48., 49.]),\n",
       " <BarContainer object of 48 artists>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentenceLengths= [l for l in sentLengthList]\n",
    "\n",
    "plt.hist(np.array(sentenceLengths), bins=(max_length-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSentences = len(bertSentenceIDs)\n",
    "\n",
    "nerClasses = pd.DataFrame(np.array(nerTokenList).reshape(-1))\n",
    "nerClasses.columns = ['tag']\n",
    "nerClasses.tag = pd.Categorical(nerClasses.tag)\n",
    "nerClasses['cat'] = nerClasses.tag.cat.codes\n",
    "nerClasses['sym'] = nerClasses.tag.cat.codes\n",
    "nerLabels = np.array(nerClasses.cat).reshape(numSentences, -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>O</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[nerCLS]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nerPAD]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[nerSEP]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>nerX</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tag  cat\n",
       "51          B    0\n",
       "59          I    1\n",
       "52          O    2\n",
       "0    [nerCLS]    3\n",
       "2    [nerPAD]    4\n",
       "1    [nerSEP]    5\n",
       "113      nerX    6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nerClasses[['tag','cat']].drop_duplicates().sort_values('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs = np.array([bertSentenceIDs, bertMasks, bertSequenceIDs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 15425, 50)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainSentence_ids = bert_inputs[0][:train_size]\n",
    "trainMasks = bert_inputs[1][:train_size]\n",
    "trainSequence_ids = bert_inputs[2][:train_size]\n",
    "\n",
    "devSentence_ids = bert_inputs[0][train_size:train_size+dev_size]\n",
    "devMasks = bert_inputs[1][train_size:train_size+dev_size]\n",
    "devSequence_ids = bert_inputs[2][train_size:train_size+dev_size]\n",
    "\n",
    "testSentence_ids = bert_inputs[0][train_size+dev_size:]\n",
    "testMasks = bert_inputs[1][train_size+dev_size:]\n",
    "testSequence_ids = bert_inputs[2][train_size+dev_size:]\n",
    "\n",
    "nerLabels_train = nerLabels[:train_size]\n",
    "nerLabels_dev = nerLabels[train_size:train_size+dev_size]\n",
    "nerLabels_test = nerLabels[train_size+dev_size:]\n",
    "\n",
    "X_train = np.array([trainSentence_ids,trainMasks,trainSequence_ids])\n",
    "X_dev = np.array([devSentence_ids,devMasks,devSequence_ids])\n",
    "X_test = np.array([testSentence_ids,testMasks,testSequence_ids])\n",
    "\n",
    "nerLabels_train = np.array(nerLabels_train)\n",
    "nerLabels_dev = np.array(nerLabels_dev)\n",
    "nerLabels_test = np.array(nerLabels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14475, 50)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(150, 50)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(800, 50)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSentence_ids.shape\n",
    "devSentence_ids.shape\n",
    "testSentence_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a parameter pair k_start, k_end to look at slices. This helps with quick tests.\n",
    "\n",
    "k_start = 0\n",
    "k_end = 1000 #-1\n",
    "\n",
    "if k_end == -1:\n",
    "    k_end_train = X_train[0].shape[0]\n",
    "    k_end_dev = X_dev[0].shape[0]\n",
    "    k_end_test = X_test[0].shape[0]\n",
    "else:\n",
    "    k_end_train = k_end_test = k_end_dev = k_end\n",
    "    \n",
    "\n",
    "\n",
    "bert_inputs_train_k = [X_train[0][k_start:k_end_train], X_train[1][k_start:k_end_train], \n",
    "                       X_train[2][k_start:k_end_train]]\n",
    "bert_inputs_dev_k = [X_dev[0][k_start:k_end_dev], X_dev[1][k_start:k_end_dev], \n",
    "                      X_dev[2][k_start:k_end_dev]]\n",
    "bert_inputs_test_k = [X_test[0][k_start:k_end_test], X_test[1][k_start:k_end_test], \n",
    "                      X_test[2][k_start:k_end_test]]\n",
    "\n",
    "\n",
    "labels_train_k = nerLabels_train[k_start:k_end_train]\n",
    "labels_dev_k = nerLabels_dev[k_start:k_end_dev]\n",
    "labels_test_k = nerLabels_test[k_start:k_end_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = [bert_inputs_train_k, labels_train_k]\n",
    "dev_all = [bert_inputs_dev_k, labels_dev_k]\n",
    "test_all = [bert_inputs_test_k, labels_test_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_all[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "numNerClasses = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss function explicitly, filtering out 'extra inserted labels'\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length + 1) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns:  cost\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    y_label = tf.reshape(Flatten()(tf.cast(y_true, tf.int32)),[-1])\n",
    "    \n",
    "    mask = (y_label < 3)   # This mask is used to remove all tokens that do not correspond to the original base text.\n",
    "\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)  # mask the labels\n",
    "    \n",
    "    y_flat_pred = tf.reshape(Flatten()(tf.cast(y_pred, tf.float32)),[-1, numNerClasses])\n",
    "    \n",
    "    y_flat_pred_masked = tf.boolean_mask(y_flat_pred, mask) # mask the predictions\n",
    "    \n",
    "    return tf.reduce_mean(sparse_categorical_crossentropy(y_label_masked, y_flat_pred_masked,from_logits=False ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_acc_orig_tokens(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss dfunction filtering out also the newly inserted labels\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns: accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "    \n",
    "    mask = (y_label < 3)\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
    "    \n",
    "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
    "                                                    [-1, numNerClasses]), axis=1)\n",
    "    \n",
    "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_acc_orig_non_other_tokens(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss dfunction explicitly filtering out also the 'Other'- labels\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns: accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "    \n",
    "    mask = (y_label < 2)\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
    "    \n",
    "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
    "                                                    [-1, numNerClasses]), axis=1)\n",
    "    \n",
    "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_customized = tf.keras.optimizers.Adam(lr=0.0005, beta_1=0.91, beta_2=0.999, epsilon=None, decay=0.1, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_model(max_input_length, train_layers, optimizer):\n",
    "    \"\"\"\n",
    "    Implementation of NER model\n",
    "    \n",
    "    variables:\n",
    "        max_input_length: number of tokens (max_length + 1)\n",
    "        train_layers: number of layers to be retrained\n",
    "        optimizer: optimizer to be used\n",
    "    \n",
    "    returns: model\n",
    "    \"\"\"\n",
    "    \n",
    "    in_id = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"segment_ids\")\n",
    "    \n",
    "    \n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Note: Bert layer from Hugging Face returns two values: sequence ouput, and pooled output. Here, we only want\n",
    "    # the former. (See https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel) \n",
    "    \n",
    "    bert_layer = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    # Freeze layers, i.e. only train number of layers specified, starting from the top\n",
    "    \n",
    "    if not train_layers == -1:\n",
    "        \n",
    "        retrain_layers = []\n",
    "    \n",
    "        for retrain_layer_number in range(train_layers):\n",
    "\n",
    "            layer_code = '_' + str(11 - retrain_layer_number)\n",
    "            retrain_layers.append(layer_code)\n",
    "\n",
    "        for w in bert_layer.weights:\n",
    "            if not any([x in w.name for x in retrain_layers]):\n",
    "                w._trainable = False\n",
    "\n",
    "        # End of freezing section\n",
    "    \n",
    "    bert_sequence = bert_layer(bert_inputs)[0]\n",
    "    \n",
    "    print('Let us check the shape of the BERT layer output:', bert_sequence)\n",
    "    \n",
    "    dense = tf.keras.layers.Dense(512å, activation='relu', name='dense')(bert_sequence)\n",
    "    \n",
    "    dense = tf.keras.layers.Dropout(rate=0.1)(dense)\n",
    "    \n",
    "    pred = tf.keras.layers.Dense(numNerClasses, activation='softmax', name='ner')(dense)\n",
    "     \n",
    "    print('pred: ', pred)\n",
    "    \n",
    "    ## Prepare for multipe loss functions, although not used here\n",
    "    \n",
    "    losses = {\n",
    "        \"ner\": custom_loss,\n",
    "        }\n",
    "    lossWeights = {\"ner\": 1.0\n",
    "                  }\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "\n",
    "    model.compile(loss=losses, optimizer=optimizer, metrics=[custom_acc_orig_tokens, \n",
    "                                                          custom_acc_orig_non_other_tokens])\n",
    "    \n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  101,  9019,  2003,  2307,  2021,  3078,  1998,  3905,  2491,\n",
       "       11287,  2071,  2022,  2062, 25634,  1012,   102,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([3, 0, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 5, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4], dtype=int8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_inputs_train_k[0][1]\n",
    "labels_train_k[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let us check the shape of the BERT layer output: Tensor(\"tf_bert_model/Identity:0\", shape=(None, 50, 768), dtype=float32)\n",
      "pred:  Tensor(\"ner/Identity:0\", shape=(None, 50, 7), dtype=float32)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 50, 256)      196864      tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 50, 256)      0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 50, 128)      32896       dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 50, 128)      0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ner (Dense)                     (None, 50, 7)        903         dropout_38[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 109,712,903\n",
      "Trainable params: 109,712,903\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "# retrain 1 layer\n",
    "model = ner_model(max_length + 1, train_layers=-1, optimizer = adam_customized)\n",
    "\n",
    "model.fit(\n",
    "    bert_inputs_train_k, \n",
    "    {\"ner\": labels_train_k },\n",
    "    validation_data=(bert_inputs_dev_k, {\"ner\": labels_dev_k }),\n",
    "    epochs=2, # lowering number of epochs since we have replicated training data 5x\n",
    "    batch_size=16\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs_infer = [X_test[0], X_test[1], X_test[2]]\n",
    "result = model.predict(\n",
    "    bert_inputs_infer, \n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(result, axis=2)[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 2 2 2 2 5 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "print(nerLabels_test[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'I', 'O', '[nerCLS]', '[nerPAD]', '[nerSEP]', 'nerX']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a dataframe that we can index\n",
    "nerClassDict = nerClasses[['tag','cat']].drop_duplicates().sort_values('cat')\n",
    "nerClassDict = list(nerClassDict.tag.values.tolist())\n",
    "nerClassDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index categorical label dataframe for the actual tag\n",
    "format_result = []\n",
    "for sample in np.argmax(result, axis=2):\n",
    "    format_result.append([nerClassDict[label] for label in sample])\n",
    "    \n",
    "len(format_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the nerX back to either IOB. Remove padding, class, and sep tokens\n",
    "def clean_IOB_result(sample):\n",
    "    clean = []\n",
    "    for ind,label in enumerate(sample):\n",
    "        if label in ['I','O','B']:\n",
    "            clean.append(label)\n",
    "        elif label == 'nerX':\n",
    "            clean.append(sample[ind-1])\n",
    "    return(clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>predictions_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[Boot, time, is, super, fast, ,, around, anywh...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[tech, support, would, not, fix, the, problem,...</td>\n",
       "      <td>[O, B, B, I, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[O, O, O, O, O, O, O]</td>\n",
       "      <td>[but, in, resume, this, computer, rocks, !]</td>\n",
       "      <td>[O, B, I, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[B, I, O, O, O]</td>\n",
       "      <td>[Set, up, was, easy, .]</td>\n",
       "      <td>[O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[O, O, O, O, O, B, I, O, B, I, O]</td>\n",
       "      <td>[Did, not, enjoy, the, new, Windows, 8, and, t...</td>\n",
       "      <td>[O, B, I, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               label  \\\n",
       "0      [B, I, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "1  [B, I, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2                              [O, O, O, O, O, O, O]   \n",
       "3                                    [B, I, O, O, O]   \n",
       "4                  [O, O, O, O, O, B, I, O, B, I, O]   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [Boot, time, is, super, fast, ,, around, anywh...   \n",
       "1  [tech, support, would, not, fix, the, problem,...   \n",
       "2        [but, in, resume, this, computer, rocks, !]   \n",
       "3                            [Set, up, was, easy, .]   \n",
       "4  [Did, not, enjoy, the, new, Windows, 8, and, t...   \n",
       "\n",
       "                                       predictions_3  \n",
       "0      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
       "1  [O, B, B, I, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "2                              [O, B, I, O, O, O, O]  \n",
       "3                                    [O, O, O, O, O]  \n",
       "4                  [O, B, I, O, O, O, O, O, O, O, O]  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_laptop_test_df['predictions_3'] = [clean_IOB_result(sample) for sample in format_result]\n",
    "# chop off any predictions that are longer than the sentence because it's not picking up the padding and class tokens\n",
    "sentence_len = ae_laptop_test_df['sentence'].apply(len)\n",
    "ae_laptop_test_df['predictions_3'] = [sample[:sentence_len[ind]] for ind,sample in enumerate(ae_laptop_test_df['predictions_3'])]\n",
    "ae_laptop_test_df.head()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'O': 38394, 'B': 732, 'I': 874})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Counter({2: 38394, 0: 732, 1: 874})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_flatten = [token for result in format_result for token in result]\n",
    "Counter(results_flatten)\n",
    "unf_results_flatten = [token for result in np.argmax(result, axis=2) for token in result]\n",
    "Counter(unf_results_flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with AE baseline - NN+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_ae(tokenized_sentence):\n",
    "    \"\"\"\n",
    "    Tag sentences using POS tagger and identify consecutive nouns as entities\n",
    "    \"\"\"\n",
    "    pos_sent = tokenized_sentence.apply(lambda sent:nltk.pos_tag(sent,tagset='universal'))\n",
    "    \n",
    "    \n",
    "    # tag with IOB terminology\n",
    "    ae_tag = lambda sent:['O' if token[1] != 'NOUN' \n",
    "                          else 'B' if ((token[1]=='NOUN') & ((sent[ind-1][1]!='NOUN') | (ind==0))) \n",
    "                          else 'I' for ind,token in enumerate(sent)]\n",
    "\n",
    "    return(pos_sent.apply(ae_tag))\n",
    "\n",
    "# since the POS tagger is based on the words themselves and not context.\n",
    "ae_laptop_dev_df['predictions'] = pos_ae(ae_laptop_dev_df['sentence'])\n",
    "ae_laptop_dev_df.head()\n",
    "\n",
    "def convert_int(tagged_tokens):\n",
    "    \"\"\"\n",
    "    Convert B,I,O tags to integers\n",
    "    \"\"\"\n",
    "    return(tagged_tokens.apply(lambda sent: [0 if token=='O' else 1 if token=='B' else 2 for token in sent]))\n",
    "\n",
    "convert_int(ae_laptop_dev_df['predictions'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore AE Regex Parser - business rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try a more sophisticated method for chunking\n",
    "def regex_parser(tokenized_sentence,verbose=False):\n",
    "    \"\"\"\n",
    "    Use a Regex Parser to provide some context around noun phrases\n",
    "    \"\"\"\n",
    "    pos_sent = nltk.pos_tag(tokenized_sentence)\n",
    "#     print(pos_sent)\n",
    "#     grammar = r\"\"\"\n",
    "#       NP: {<DT|PP\\$>?<JJ>*<NN>}   # chunk determiner/possessive, adjectives and noun\n",
    "#           {<NNP>+}                # chunk sequences of proper nouns\n",
    "#     \"\"\"\n",
    "    \n",
    "    # Update Grammar Regex to include prepositional phrases ala Semeval annotation guidelines\n",
    "    grammar = r\"\"\"\n",
    "    NP: {<NN><IN><DT><NN|NNP>+}\n",
    "        {<NNP><NN>}\n",
    "        {<NNP>+}\n",
    "        {<NN>+}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    cp = nltk.RegexpParser(grammar)\n",
    "\n",
    "    tree = cp.parse(pos_sent)\n",
    "    \n",
    "    if verbose: print(tree)\n",
    "    \n",
    "    iob = [el[2][0] for el in nltk.chunk.util.tree2conlltags(tree)]\n",
    "    \n",
    "    return(iob)\n",
    "\n",
    "# print example\n",
    "ae_laptop_train['15']['sentence']\n",
    "regex_parser(ae_laptop_train['15']['sentence'])\n",
    "\n",
    "print(['cover','for','the','DVD','drive'])\n",
    "regex_parser(['cover','for','the','DVD','drive'])\n",
    "\n",
    "ae_laptop_dev_df.iloc[4]['sentence']\n",
    "regex_parser(ae_laptop_dev_df.iloc[4]['sentence'],verbose=True)\n",
    "\n",
    "# since the POS tagger is based on the words themselves and not context.\n",
    "ae_laptop_dev_df['predictions_1'] = ae_laptop_dev_df['sentence'].apply(lambda x: regex_parser(x))\n",
    "ae_laptop_dev_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore AE evaluation - CE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haven't seen many papers using CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only using 0,1 because there aren't many very large token phrases\n",
    "log_loss(convert_int(pd.DataFrame(ae_laptop_dev_df.iloc[0]['label'])),convert_int(pd.DataFrame(ae_laptop_dev_df.iloc[0]['predictions'])),labels=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore AE evaluation - SemEval14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.davidsbatista.net/blog/2018/05/09/Named_Entity_Evaluation/  \n",
    "- partial boundary match over the surface string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO need to explore how we want to move forward with all sentences rather than just 1.\n",
    "# Should try to implement the SemEval14 evaluation criteria bc this is best practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO amend this tree structure for all predictions as well\n",
    "print('\\nGold Standard:')\n",
    "# tag every sentence with the pos\n",
    "gold_tree = ae_laptop_dev_df['sentence'].apply(lambda x: nltk.pos_tag(x))\n",
    "print(gold_tree)\n",
    "iob_gold_tree = [nltk.Tree('S',\n",
    "                           [(el[0], el[1], ae_laptop_dev_df.iloc[tree_ind]['label'][ind])\n",
    "                            if ae_laptop_dev_df.iloc[tree_ind]['label'][ind]=='O'\n",
    "                            else (el[0], el[1], ae_laptop_dev_df.iloc[tree_ind]['label'][ind] + '-NP')\n",
    "                            for ind,el in enumerate(tree)])\n",
    "                for tree_ind, tree in enumerate(gold_tree)]\n",
    "ae_laptop_dev_df['iob_gold_tree'] = iob_gold_tree\n",
    "ae_laptop_dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(sentence_lst, predictions_lst):\n",
    "    \"\"\"\n",
    "    Reformat the IOB structure to get the actual entities from the sentence\n",
    "    \"\"\"\n",
    "    \n",
    "    # for every sentence, iterate through\n",
    "    all_entities = []\n",
    "    for sample in range(len(predictions_lst)):\n",
    "    \n",
    "        # chop off the last words because we max out at 50 for BERT\n",
    "    \n",
    "        # get indices where entities are identified\n",
    "        predictions = np.array(predictions_lst[sample])\n",
    "        predictions = predictions[:50]\n",
    "        ind = (predictions == 'B') | (predictions == 'I')\n",
    "        \n",
    "        # create list of numerical indices and boolean indices. ex. [(4, True), (10, True), (11, True), (15, True)]\n",
    "        ind_tuple = [num_ind for num_ind in list(enumerate(ind)) if num_ind[1]==True]\n",
    "        \n",
    "        # get the sentence of interest. identify what these entities are\n",
    "        sentence = np.array(sentence_lst[sample])\n",
    "        sentence = sentence[:50]\n",
    "\n",
    "        # group the phrases together\n",
    "        entities = []\n",
    "        for subset,num_ind_tuple in zip(sentence[ind], ind_tuple): # [('price', (4, True)), ('netbook', (10, True)), ('*', (11, True)), ('machine', (15, True))]\n",
    "            # put the B in entities\n",
    "            if predictions[num_ind_tuple[0]][0] == 'B':\n",
    "                entities.append([subset])\n",
    "            # if the tag is I and it should have been a B. Fix in post processing.\n",
    "            elif (predictions[num_ind_tuple[0]][0] == 'I') & (len(entities)==0):\n",
    "                entities.append([subset])\n",
    "            # if the tag is I, add to the last item of the list\n",
    "            elif predictions[num_ind_tuple[0]][0] == 'I':\n",
    "                last_entry = entities.pop()\n",
    "                last_entry.append(subset)\n",
    "                entities.append(last_entry)\n",
    "            # there should not be any 'O' indices here\n",
    "            else:\n",
    "                print('Error')\n",
    "        all_entities.append(entities)\n",
    "    return(all_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'predictions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-0f124f2d0916>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_entities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mprediction_entities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mae_laptop_dev_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mae_laptop_dev_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mgold_entities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mae_laptop_dev_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mae_laptop_dev_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mprediction_entities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'predictions'"
     ]
    }
   ],
   "source": [
    "prediction_entities = get_entities(ae_laptop_dev_df.sentence,ae_laptop_dev_df.predictions)\n",
    "gold_entities = get_entities(ae_laptop_dev_df.sentence,ae_laptop_dev_df.label)\n",
    "prediction_entities[:5]\n",
    "gold_entities[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ae_eval_features(gold_entities,prediction_entities,verbose=False):\n",
    "    # TODO need to generalize and do for all samples\n",
    "    # TODO may later need to update these calculations to encompass sentence location.\n",
    "    y_true_df = pd.DataFrame([[ind,sub_el] for ind,el in enumerate(gold_entities) for sub_el in el], columns=['sample_index','entity'])\n",
    "    y_pred_df = pd.DataFrame([[ind,sub_el] for ind,el in enumerate(prediction_entities) for sub_el in el], columns=['sample_index','entity'])\n",
    "    print('True')\n",
    "    display(y_true_df.head())\n",
    "    print('Pred')\n",
    "    display(y_pred_df.head())\n",
    "\n",
    "    cor = 0\n",
    "    inc = 0\n",
    "    par = 0\n",
    "    mis = 0\n",
    "    spu = 0\n",
    "\n",
    "    for el in range(len(gold_entities)):\n",
    "        if verbose:\n",
    "            print('\\n',el)\n",
    "        true_subset = y_true_df[y_true_df.sample_index == el]\n",
    "        pred_subset = y_pred_df[y_pred_df.sample_index == el]\n",
    "        true_entities = set(true_subset.entity.apply(lambda x: '_'.join(x)))\n",
    "        pred_entities = set(pred_subset.entity.apply(lambda x: '_'.join(x)))\n",
    "        if verbose:\n",
    "            print('True')\n",
    "            print(true_entities)\n",
    "            print('Pred')\n",
    "            print(pred_entities)\n",
    "\n",
    "        # get correct\n",
    "        cor_entities = true_entities & pred_entities\n",
    "        if verbose:\n",
    "            print(f'Correct entities: {cor_entities}')\n",
    "        cor += len(cor_entities)\n",
    "        true_entities = true_entities - cor_entities\n",
    "        pred_entities = pred_entities - cor_entities\n",
    "\n",
    "        # get partial and missed\n",
    "        for true in true_entities:\n",
    "            # Take into account if the prediction contains a portion of the correct and if correct contains a portion of the prediction\n",
    "            par_entities = set([pred for pred in pred_entities if (true in pred) | (pred in true)])\n",
    "            if len(par_entities) != 0:\n",
    "                if verbose:\n",
    "                    print(f'Partial entities: {set([true])}')\n",
    "                par += len(par_entities)\n",
    "                true_entities = true_entities - set([true])\n",
    "                pred_entities = pred_entities - par_entities\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f'Missed entities: {set([true])}')\n",
    "                mis += 1/''\n",
    "                true_entities = true_entities - set([true])\n",
    "\n",
    "        if len(true_entities) == 0:\n",
    "            if verbose:\n",
    "                print(f'Spurious entities: {pred_entities}')\n",
    "            spu += len(pred_entities)\n",
    "        else:\n",
    "            print('Error')\n",
    "\n",
    "    print(f'\\nCorrect: {cor}')\n",
    "    print(f'Partial: {par}')\n",
    "    print(f'Missed: {mis}')\n",
    "    print(f'Spurious: {spu}')\n",
    "    return(cor,par,mis,spu,inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor,par,mis,spu,inc = get_ae_eval_features(gold_entities,prediction_entities,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ae_eval(sentence_lst, y_true, y_pred,verbose=False):\n",
    "    \"\"\"\n",
    "    Get entity recognition evaluations accoridng to the partial match SemEval strategy\n",
    "    \"\"\"\n",
    "    prediction_entities = get_entities(sentence_lst,y_pred)\n",
    "    gold_entities = get_entities(sentence_lst,y_true)\n",
    "    \n",
    "    cor,par,mis,spu,inc = get_ae_eval_features(gold_entities,prediction_entities,verbose=verbose)\n",
    "    \n",
    "    pos_eval = cor + inc + par + mis\n",
    "    act_eval = cor + inc + par + spu\n",
    "\n",
    "    precision = (cor + .5 * par) / act_eval\n",
    "    recall = (cor + .5 * par) / pos_eval\n",
    "    f1 = ( 2* precision * recall) / (precision + recall)\n",
    "    \n",
    "    print(f'\\nPrecision: \\t{precision}')\n",
    "    print(f'Recall: \\t{recall}')\n",
    "    print(f'F1-Score: \\t{f1}')\n",
    "    return(precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ae_eval(ae_laptop_dev_df.sentence,ae_laptop_dev_df.label,ae_laptop_dev_df.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ae_eval(ae_laptop_dev_df.sentence,ae_laptop_dev_df.label,ae_laptop_dev_df.predictions_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_ae_eval_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-fb38daf60775>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ae_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mae_laptop_test_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mae_laptop_test_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mae_laptop_test_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-68fdcb6bdf5d>\u001b[0m in \u001b[0;36mget_ae_eval\u001b[0;34m(sentence_lst, y_true, y_pred, verbose)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mgold_entities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_lst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ae_eval_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold_entities\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprediction_entities\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpos_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcor\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpar\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_ae_eval_features' is not defined"
     ]
    }
   ],
   "source": [
    "get_ae_eval(ae_laptop_test_df.sentence,ae_laptop_test_df.label,ae_laptop_test_df.predictions_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore AE evaluation - ChunkScore\n",
    "https://stackoverflow.com/questions/17325554/difference-between-iob-accuracy-and-precision  \n",
    "Somehow, this is not working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO get ChunkScore to work\n",
    "tokenized_sentence = ae_laptop_train['15']['sentence']\n",
    "pos_sent = nltk.pos_tag(tokenized_sentence)\n",
    "\n",
    "##\n",
    "grammar = r\"\"\"\n",
    "  NP: {<DT|PP\\$>?<JJ>*<NN>}   # chunk determiner/possessive, adjectives and noun\n",
    "      {<NNP>+}                # chunk sequences of proper nouns\n",
    "\"\"\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "\n",
    "tree = cp.parse(pos_sent)\n",
    "\n",
    "iob = [el[2][0] for el in nltk.chunk.util.tree2conlltags(tree)]\n",
    "\n",
    "print('Prediction:')\n",
    "print(tree)\n",
    "nltk.chunk.util.tree2conlltags(tree)\n",
    "regex_parser(ae_laptop_train['15']['sentence'])\n",
    "##\n",
    "\n",
    "gold_tree = pos_sent\n",
    "print('\\nGold Standard:')\n",
    "# create the tree with IOB input\n",
    "iob_gold_tree = nltk.Tree('S',[(el[0], el[1], ae_laptop_train['15']['label'][ind]) if ae_laptop_train['15']['label'][ind]=='O' \n",
    "                               else (el[0], el[1], ae_laptop_train['15']['label'][ind] + '-NP')for ind,el in enumerate(gold_tree)])\n",
    "print(nltk.chunk.util.conlltags2tree(iob_gold_tree))\n",
    "# print(nltk.chunk.util.conlltags2tree([(el[0], el[1], ae_laptop_train['15']['label'][ind])for ind,el in enumerate(gold_tree)]))\n",
    "# print(nltk.chunk.util.conlltags2tree())\n",
    "print(cp.evaluate([iob_gold_tree]))\n",
    "\n",
    "# nltk.chunk.util.tagstr2tree(' '.join(tokenized_sentence), chunk_label='NP', root_label='S', sep='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO get ChunkScore to work on all dev\n",
    "print('\\nGold Standard:')\n",
    "# tag every sentence with the pos\n",
    "gold_tree = ae_laptop_dev_df['sentence'].apply(lambda x: nltk.pos_tag(x))\n",
    "print(gold_tree)\n",
    "iob_gold_tree = [nltk.Tree('S',\n",
    "                           [(el[0], el[1], ae_laptop_dev_df.iloc[tree_ind]['label'][ind])\n",
    "                            if ae_laptop_dev_df.iloc[tree_ind]['label'][ind]=='O'\n",
    "                            else (el[0], el[1], ae_laptop_dev_df.iloc[tree_ind]['label'][ind] + '-NP')\n",
    "                            for ind,el in enumerate(tree)])\n",
    "                for tree_ind, tree in enumerate(gold_tree)]\n",
    "ae_laptop_dev_df['iob_gold_tree'] = iob_gold_tree\n",
    "ae_laptop_dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore AE evaluation - Token Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(true,predictions):\n",
    "    accuracy = []\n",
    "    for true_el, predict_el in zip(true,predictions):\n",
    "        accuracy.append((np.array(predict_el) == np.array(true_el)).sum() / (len(true_el)))\n",
    "    return(accuracy)\n",
    "\n",
    "ae_laptop_dev_df['accuracy'] = get_accuracy(ae_laptop_dev_df.label,ae_laptop_dev_df.predictions)\n",
    "ae_laptop_dev_df['accuracy_1'] = get_accuracy(ae_laptop_dev_df.label,ae_laptop_dev_df.predictions_1)\n",
    "ae_laptop_dev_df.head()\n",
    "ae_laptop_dev_df[['accuracy','accuracy_1']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export samples that are well / poorly extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bad_examples(n = 1):\n",
    "    ind = np.argpartition(ae_laptop_dev_df.accuracy + ae_laptop_dev_df.accuracy_1,n)[:n]\n",
    "    print(ind)\n",
    "    sort_ind = ind[np.argsort((ae_laptop_dev_df.accuracy + ae_laptop_dev_df.accuracy_1).iloc[ind])]\n",
    "    bad_example = ae_laptop_dev_df.iloc[sort_ind]\n",
    "    \n",
    "    display(bad_example)\n",
    "    print(*[' '.join(sent) for sent in bad_example.sentence],sep='\\n')\n",
    "    \n",
    "get_bad_examples(3)\n",
    "\n",
    "def get_good_examples(n = 1):\n",
    "    ind = np.argpartition(ae_laptop_dev_df.accuracy + ae_laptop_dev_df.accuracy_1,-n)[-n:]\n",
    "    print(ind)\n",
    "    sort_ind = ind[np.argsort((ae_laptop_dev_df.accuracy + ae_laptop_dev_df.accuracy_1).iloc[ind])]\n",
    "    good_example = ae_laptop_dev_df.iloc[sort_ind]\n",
    "    \n",
    "    display(good_example)\n",
    "    print(*[' '.join(sent) for sent in good_example.sentence],sep='\\n')\n",
    "# good_example = ae_laptop_dev_df.iloc[np.argmax(ae_laptop_dev_df.accuracy + ae_laptop_dev_df.accuracy_1)]\n",
    "get_good_examples(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with ASC baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not even safe mode boots.---------------------------------------- -0.3412 (negative)\n",
      "Keyboard was also very nice and had a solid feel.---------------- 0.5709 (positive)\n",
      "Keyboard is plastic and spongey feeling.------------------------- 0.128 (positive)\n",
      "I would recommend this laptop to anyone looking to get a new laptop who is willing to spend a little more money to get great quality! 0.784 (positive)\n",
      "Thus, when you carry it at a slanted angle, the screen will \"topple\" or \"slide\" down, if you understand what I mean. 0.0 (neutral)\n",
      "When I called Sony the Customer Service was Great.--------------- 0.6249 (positive)\n",
      "I also did not like the loud noises it made or how the bottom of the computer would get really hot. -0.2755 (negative)\n",
      "I also did not like the loud noises it made or how the bottom of the computer would get really hot. -0.2755 (negative)\n",
      "Also, one of the users mentioned how the edges on the macbook is sharp, if you have money to spend on one of the incase shells, it doesn't seem to be a problem. -0.4019 (negative)\n",
      "Also, one of the users mentioned how the edges on the macbook is sharp, if you have money to spend on one of the incase shells, it doesn't seem to be a problem. -0.4019 (negative)\n"
     ]
    }
   ],
   "source": [
    "def vader_asc(sentence_lst):\n",
    "    \"\"\"\n",
    "    For every sentence in the list, tag it as a positive/negative sentiment based on the sum of the words.\n",
    "    \"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    pos_neg_tag_lst = []\n",
    "    for ind,sentence in enumerate(sentence_lst):\n",
    "        vs = analyzer.polarity_scores(sentence)\n",
    "        pos_neg_tag = 'negative' if vs['compound'] <= -0.05 else 'positive' if vs['compound'] >= 0.05 else 'neutral' \n",
    "        # print first 10 examples\n",
    "        if ind <10: print(\"{:-<65} {} ({})\".format(sentence, str(vs['compound']),pos_neg_tag))\n",
    "        pos_neg_tag_lst.append(pos_neg_tag)\n",
    "    return(pos_neg_tag_lst)\n",
    "\n",
    "asc_laptop_dev_df['predictions'] = vader_asc(asc_laptop_dev_df.sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with ASC - BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2895"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sentences = [val['sentence'] for key, val in asc_laptop_train.items()]*5\n",
    "batch_sentences.extend([val['sentence'] for key, val in asc_laptop_dev.items()])\n",
    "batch_sentences.extend([val['sentence'] for key, val in asc_laptop_test.items()])\n",
    "train_size = len(asc_laptop_train)*5\n",
    "dev_size = len(asc_laptop_dev)\n",
    "test_size = len(asc_laptop_test)\n",
    "train_size\n",
    "dev_size\n",
    "test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_label = [val['polarity'] for key, val in asc_laptop_train.items()]*5\n",
    "batch_label.extend([val['polarity'] for key, val in asc_laptop_dev.items()])\n",
    "batch_label.extend([val['polarity'] for key, val in asc_laptop_test.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs = tokenizer(batch_label, batch_sentences, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO check this\n",
    "ascLabels = pd.Categorical(batch_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSentence_ids = bert_inputs[0][:train_size]\n",
    "trainMasks = bert_inputs[1][:train_size]\n",
    "trainSequence_ids = bert_inputs[2][:train_size]\n",
    "\n",
    "devSentence_ids = bert_inputs[0][train_size:train_size+dev_size]\n",
    "devMasks = bert_inputs[1][train_size:train_size+dev_size]\n",
    "devSequence_ids = bert_inputs[2][train_size:train_size+dev_size]\n",
    "\n",
    "testSentence_ids = bert_inputs[0][train_size+dev_size:]\n",
    "testMasks = bert_inputs[1][train_size+dev_size:]\n",
    "testSequence_ids = bert_inputs[2][train_size+dev_size:]\n",
    "\n",
    "ascLabels_train = ascLabels[:train_size]\n",
    "ascLabels_dev = ascLabels[train_size:train_size+dev_size]\n",
    "ascLabels_test = ascLabels[train_size+dev_size:]\n",
    "\n",
    "X_train = np.array([trainSentence_ids,trainMasks,trainSequence_ids])\n",
    "X_dev = np.array([devSentence_ids,devMasks,devSequence_ids])\n",
    "X_test = np.array([testSentence_ids,testMasks,testSequence_ids])\n",
    "\n",
    "ascLabels_train = np.array(ascLabels_train)\n",
    "ascLabels_dev = np.array(ascLabels_dev)\n",
    "ascLabels_test = np.array(ascLabels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "model = TFBertForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss)\n",
    "model.fit(X_train,{\"asc\": ascLabels_train },validation_data=(X_dev,{\"asc\": ascLabels_dev}), epochs=2, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore ASC evaluation - accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asc_laptop_dev_df.head()\n",
    "(asc_laptop_dev_df.polarity == asc_laptop_dev_df.predictions).value_counts(normalize=True)\n",
    "accuracy_score(asc_laptop_dev_df.polarity,asc_laptop_dev_df.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore ASC evaluation - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(asc_laptop_dev_df.polarity,asc_laptop_dev_df.predictions,labels=['negative','neutral','positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore ASC evaluation - Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(asc_laptop_dev_df.polarity,asc_laptop_dev_df.predictions,labels=['negative','neutral','positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine ASC evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_asc_eval(y_true, y_pred):\n",
    "    print(confusion_matrix(y_true,y_pred,labels=['negative','neutral','positive']))\n",
    "    print(classification_report(y_true,asc_laptop_dev_df.predictions,labels=['negative','neutral','positive']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
