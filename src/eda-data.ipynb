{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data\n",
    "**Author:** Jane Hung  \n",
    "**Date:** 1 Mar 2020  \n",
    "**Citations:**  \n",
    "@inproceedings{xu_bert2019,\n",
    "    title = \"BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis\",\n",
    "    author = \"Xu, Hu and Liu, Bing and Shu, Lei and Yu, Philip S.\",\n",
    "    booktitle = \"Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics\",\n",
    "    year = \"2019\",\n",
    "}  \n",
    "https://drive.google.com/file/d/1NGH5bqzEx6aDlYJ7O3hepZF4i_p4iMR8/view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pprint\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import io\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.backend import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel, pipeline\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import log_loss, confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(filename):\n",
    "    f = open(filename,'r')\n",
    "    data = json.loads(f.read())\n",
    "    print('\\n',filename)\n",
    "    pprint.pprint(dict(list(data.items())[:1]))\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ../data/hu-data/ae/laptop/train.json\n",
      "{'0': {'label': ['B',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'B',\n",
      "                 'I',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O'],\n",
      "       'sentence': ['Keyboard',\n",
      "                    'is',\n",
      "                    'great',\n",
      "                    'but',\n",
      "                    'primary',\n",
      "                    'and',\n",
      "                    'secondary',\n",
      "                    'control',\n",
      "                    'buttons',\n",
      "                    'could',\n",
      "                    'be',\n",
      "                    'more',\n",
      "                    'durable',\n",
      "                    '.']}}\n",
      "\n",
      " ../data/hu-data/ae/rest/train.json\n",
      "{'0': {'label': ['O', 'O', 'O', 'B'],\n",
      "       'sentence': ['I', 'LOVE', 'their', 'Thai']}}\n",
      "\n",
      " ../data/hu-data/asc/laptop/train.json\n",
      "{'327_0': {'id': '327_0',\n",
      "           'polarity': 'positive',\n",
      "           'sentence': 'Also it is very good for college students who just '\n",
      "                       'need a reliable, easy to use computer.',\n",
      "           'term': 'use'}}\n",
      "\n",
      " ../data/hu-data/asc/rest/train.json\n",
      "{'1592_0': {'id': '1592_0',\n",
      "            'polarity': 'positive',\n",
      "            'sentence': 'Our server was very helpful and friendly.',\n",
      "            'term': 'server'}}\n"
     ]
    }
   ],
   "source": [
    "ae_laptop_train = read_json('../data/hu-data/ae/laptop/train.json')\n",
    "ae_rest_train = read_json('../data/hu-data/ae/rest/train.json')\n",
    "\n",
    "\n",
    "asc_laptop_train = read_json('../data/hu-data/asc/laptop/train.json')\n",
    "asc_rest_train = read_json('../data/hu-data/asc/rest/train.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ../data/hu-data/ae/laptop/dev.json\n",
      "{'0': {'label': ['O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O'],\n",
      "       'sentence': ['I',\n",
      "                    'have',\n",
      "                    'had',\n",
      "                    'this',\n",
      "                    'laptop',\n",
      "                    'for',\n",
      "                    'a',\n",
      "                    'few',\n",
      "                    'months',\n",
      "                    'now',\n",
      "                    'and',\n",
      "                    'i',\n",
      "                    'would',\n",
      "                    'say',\n",
      "                    'im',\n",
      "                    'pretty',\n",
      "                    'satisfied',\n",
      "                    '.']}}\n",
      "\n",
      " ../data/hu-data/ae/rest/dev.json\n",
      "{'0': {'label': ['O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'B',\n",
      "                 'I',\n",
      "                 'I',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O'],\n",
      "       'sentence': ['In',\n",
      "                    'the',\n",
      "                    'summer',\n",
      "                    'months',\n",
      "                    ',',\n",
      "                    'the',\n",
      "                    'back',\n",
      "                    'garden',\n",
      "                    'area',\n",
      "                    'is',\n",
      "                    'really',\n",
      "                    'nice',\n",
      "                    '.']}}\n",
      "\n",
      " ../data/hu-data/asc/laptop/dev.json\n",
      "{'1113_0': {'id': '1113_0',\n",
      "            'polarity': 'negative',\n",
      "            'sentence': 'Not even safe mode boots.',\n",
      "            'term': 'safe mode'}}\n",
      "\n",
      " ../data/hu-data/asc/rest/dev.json\n",
      "{'2516_0': {'id': '2516_0',\n",
      "            'polarity': 'positive',\n",
      "            'sentence': \"This is the only Thai place I go too in NYC, it's \"\n",
      "                        'wonderful, and live relaxed Jazz on certain nights.',\n",
      "            'term': 'Jazz'}}\n"
     ]
    }
   ],
   "source": [
    "ae_laptop_dev  = read_json('../data/hu-data/ae/laptop/dev.json')\n",
    "ae_rest_dev = read_json('../data/hu-data/ae/rest/dev.json')\n",
    "\n",
    "\n",
    "asc_laptop_dev = read_json('../data/hu-data/asc/laptop/dev.json')\n",
    "asc_rest_dev = read_json('../data/hu-data/asc/rest/dev.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: How do we get from the ASC data back to the AE data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'polarity': 'positive',\n",
       " 'term': 'use',\n",
       " 'id': '327_0',\n",
       " 'sentence': 'Also it is very good for college students who just need a reliable, easy to use computer.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'label': ['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O'],\n",
       " 'sentence': ['If',\n",
       "  'you',\n",
       "  'could',\n",
       "  'stretch',\n",
       "  'by',\n",
       "  'a',\n",
       "  'few',\n",
       "  '100',\n",
       "  'dollars',\n",
       "  'I',\n",
       "  'highly',\n",
       "  'recommend',\n",
       "  'you',\n",
       "  'should',\n",
       "  'replace',\n",
       "  'your',\n",
       "  'Windows',\n",
       "  'laptop',\n",
       "  'with',\n",
       "  'this',\n",
       "  'one',\n",
       "  '.']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asc_laptop_train['327_0']\n",
    "ae_laptop_train['400']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with MultiNomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sentences = [val['sentence'] for key, val in ae_laptop_train.items()]\n",
    "batch_sentences.extend([val['sentence'] for key, val in ae_laptop_dev.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(3045, 97), dtype=int32, numpy=\n",
       "array([[  101,  7443,  4015, ...,     0,     0,     0],\n",
       "       [  101,   146,  3306, ...,     0,     0,     0],\n",
       "       [  101,   146,  1821, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  1198, 11824, ...,     0,     0,     0],\n",
       "       [  101,  1422,  1488, ...,     0,     0,     0],\n",
       "       [  101,  1188,  1110, ...,     0,     0,     0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(3045, 97), dtype=int32, numpy=\n",
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(3045, 97), dtype=int32, numpy=\n",
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_inputs = tokenizer(batch_sentences, padding=True, is_split_into_words=True,return_tensors='tf',max_length=50)\n",
    "encoded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2895, 97), dtype=int32, numpy=\n",
       "array([[ 101, 7443, 4015, ...,    0,    0,    0],\n",
       "       [ 101,  146, 3306, ...,    0,    0,    0],\n",
       "       [ 101,  146, 1821, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 101, 1422, 1910, ...,    0,    0,    0],\n",
       "       [ 101,  146, 1250, ...,    0,    0,    0],\n",
       "       [ 101,  146, 1821, ...,    0,    0,    0]], dtype=int32)>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO update encoder with Test data as well\n",
    "train_sentences = encoded_inputs['input_ids'][:2895]\n",
    "test_sentences = encoded_inputs['input_ids'][-150:]\n",
    "train_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(97,), dtype=int32, numpy=\n",
       "array([  101,  7443,  4015,  1110,  1632,  1133,  2425,  1105,  3718,\n",
       "        1654, 11760,  1180,  1129,  1167,  3840,  9739,   119,   102,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0], dtype=int32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[0]\n",
    "np.sum(train_sentences[0] != 0)\n",
    "# start and end token are included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(280815, 1), dtype=int32, numpy=\n",
       "array([[ 101],\n",
       "       [7443],\n",
       "       [4015],\n",
       "       ...,\n",
       "       [   0],\n",
       "       [   0],\n",
       "       [   0]], dtype=int32)>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mask = encoded_inputs['attention_mask'][:2895]\n",
    "test_mask = encoded_inputs['attention_mask'][:2895]\n",
    "\n",
    "# [train_sentences[ind][mask] for ind,mask in enumerate(train_mask[:5])]\n",
    "tf.reshape(train_sentences,[-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels = np.array([token for key, val in ae_laptop_train.items() for token in val['label']])\n",
    "# test_labels = np.array([token for key, val in ae_laptop_dev.items() for token in val['label']])\n",
    "label_list = ['I','O','B']\n",
    "\n",
    "def format_labels(data_dict,max_length=97):\n",
    "    convert_labels = [val['label'] for key, val in data_dict.items() ]\n",
    "    convert_labels = [[label_list.index(token) for token in label] for label in convert_labels]\n",
    "    convert_labels_num = []\n",
    "    for label in convert_labels:\n",
    "        sp_token = [1]\n",
    "        sp_token.extend(label)\n",
    "        sp_token.append(1)\n",
    "#         mask = np.ones(max_length-len(sp_token)).astype(int)\n",
    "#         sp_token.extend(mask.tolist())\n",
    "        convert_labels_num.append(np.array(sp_token))\n",
    "    convert_labels_num = np.array(convert_labels_num).reshape(-1)\n",
    "    return(convert_labels_num)\n",
    "train_labels = format_labels(ae_laptop_train)\n",
    "test_labels = format_labels(ae_laptop_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([280815, 1])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(280815,)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(14550,)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = tf.reshape(train_sentences,[-1,1])\n",
    "train_sentences.shape\n",
    "train_labels.reshape(-1).shape\n",
    "test_sentences = tf.reshape(test_sentences,[-1,1])\n",
    "test_labels.reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB().fit(train_sentences, train_labels)\n",
    "y_pred = nb.predict(test_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9863230240549828"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'O': 14550})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Counter([label_list[pred] for pred in y_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    in_x = tf.keras.layers.Input=(shape=(5,34), name='in_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 34), dtype=int32, numpy=\n",
       "array([[  101,  7443,  4015,  1110,  1632,  1133,  2425,  1105,  3718,\n",
       "         1654, 11760,  1180,  1129,  1167,  3840,  9739,   119,   102,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0],\n",
       "       [  101,   146,  3306,  1142, 12574,  1164,   170,  2370,  2403,\n",
       "         1106,  4971,  1139,  3254,  4163,  4426, 12574,   119,   102,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0],\n",
       "       [  101,   146,  1821,  1649,  7229,  1115,  1122,  1110,  1253,\n",
       "         5205,  1107,  1175,   119,   102,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0],\n",
       "       [  101,   146,  1355,  1106,  1139,  1469,  1798, 26123,  1702,\n",
       "         1111,   170,  1207, 12574,  1290,  2317,  2795,   119,   102,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0],\n",
       "       [  101,  1109,  7302, 12029, 26303,  1475, 23955,   120,   138,\n",
       "          123,   119,   125,  2349,  1324,  1584,  1405,   119,   125,\n",
       "          118,  4305,  6603,  2064,  9753,  5096,  5322,  6470,  1110,\n",
       "          170,  9210,  5671,  1104,  1948,   119,   102]], dtype=int32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss)\n",
    "model.fit(train_dataset, epochs=2, steps_per_epoch=115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert_layer = TFBertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_outputs = bert_layer(encoded_inputs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.62940717 0.27119648 0.0993964 ]\n",
      "  [0.5521288  0.32269278 0.12517846]\n",
      "  [0.47849244 0.27222136 0.24928619]\n",
      "  [0.47228867 0.2948147  0.23289666]\n",
      "  [0.5608343  0.24918106 0.18998466]\n",
      "  [0.5211468  0.28075665 0.1980966 ]\n",
      "  [0.43167362 0.18180855 0.3865179 ]\n",
      "  [0.35747558 0.18084107 0.46168327]\n",
      "  [0.38504198 0.21248028 0.4024778 ]\n",
      "  [0.47862995 0.34622508 0.17514503]\n",
      "  [0.3984128  0.4571889  0.1443983 ]\n",
      "  [0.45698577 0.25686792 0.28614628]\n",
      "  [0.505183   0.24390472 0.25091225]\n",
      "  [0.5434213  0.18932696 0.2672517 ]\n",
      "  [0.52607447 0.24107142 0.23285408]\n",
      "  [0.341828   0.3258147  0.33235732]\n",
      "  [0.45448542 0.4131721  0.1323425 ]\n",
      "  [0.44645542 0.42504993 0.12849459]\n",
      "  [0.43365318 0.31858042 0.24776636]\n",
      "  [0.47218317 0.26131245 0.26650432]\n",
      "  [0.41782546 0.32365337 0.25852123]\n",
      "  [0.4358579  0.22902009 0.33512202]\n",
      "  [0.47156313 0.26289684 0.26554   ]\n",
      "  [0.4558886  0.23761722 0.30649415]\n",
      "  [0.42939723 0.2565927  0.31401002]\n",
      "  [0.42766923 0.28254724 0.28978354]\n",
      "  [0.41212502 0.31251138 0.27536356]\n",
      "  [0.46935815 0.23063137 0.30001047]\n",
      "  [0.44827008 0.24437675 0.30735314]\n",
      "  [0.40735754 0.35428494 0.2383575 ]\n",
      "  [0.37166864 0.4035329  0.22479853]\n",
      "  [0.44931382 0.27807626 0.27260998]\n",
      "  [0.4588181  0.28452718 0.25665474]\n",
      "  [0.35634243 0.40345675 0.24020077]]\n",
      "\n",
      " [[0.69298255 0.21248046 0.09453702]\n",
      "  [0.59239906 0.333927   0.07367387]\n",
      "  [0.40009066 0.35008597 0.24982339]\n",
      "  [0.523731   0.33834773 0.13792127]\n",
      "  [0.46655756 0.30462864 0.22881377]\n",
      "  [0.47379753 0.30374163 0.22246091]\n",
      "  [0.4230844  0.34096253 0.23595299]\n",
      "  [0.52204597 0.28617272 0.19178133]\n",
      "  [0.45899022 0.27482286 0.26618698]\n",
      "  [0.570629   0.27245483 0.15691616]\n",
      "  [0.50708216 0.14832485 0.34459296]\n",
      "  [0.49764112 0.28756094 0.21479797]\n",
      "  [0.44239494 0.2836825  0.27392262]\n",
      "  [0.6056465  0.23030324 0.16405024]\n",
      "  [0.35035712 0.32674512 0.32289776]\n",
      "  [0.45366237 0.31520277 0.23113485]\n",
      "  [0.48543116 0.27437094 0.24019791]\n",
      "  [0.1860903  0.6996686  0.11424107]\n",
      "  [0.46015555 0.32802352 0.21182089]\n",
      "  [0.49261114 0.28865188 0.21873698]\n",
      "  [0.48474464 0.2764098  0.23884556]\n",
      "  [0.4808086  0.30720028 0.21199113]\n",
      "  [0.4535769  0.28144786 0.26497528]\n",
      "  [0.44799894 0.25742057 0.2945804 ]\n",
      "  [0.4537334  0.28369123 0.26257533]\n",
      "  [0.4742222  0.2901712  0.23560663]\n",
      "  [0.43505785 0.22974138 0.33520073]\n",
      "  [0.44519782 0.23515002 0.31965217]\n",
      "  [0.46187568 0.24651223 0.29161215]\n",
      "  [0.37210304 0.32804832 0.2998487 ]\n",
      "  [0.42184058 0.23730418 0.34085524]\n",
      "  [0.41055164 0.2903999  0.29904845]\n",
      "  [0.43494868 0.28745267 0.27759868]\n",
      "  [0.5121796  0.28960362 0.19821674]]\n",
      "\n",
      " [[0.7159526  0.18567908 0.09836831]\n",
      "  [0.59658176 0.29208958 0.11132866]\n",
      "  [0.47439215 0.29446027 0.23114757]\n",
      "  [0.4890631  0.2980451  0.21289182]\n",
      "  [0.4801336  0.27526286 0.24460353]\n",
      "  [0.56936544 0.22815743 0.20247717]\n",
      "  [0.56792533 0.27383667 0.158238  ]\n",
      "  [0.6007512  0.22177258 0.17747617]\n",
      "  [0.61779004 0.16196063 0.22024935]\n",
      "  [0.5280927  0.26241285 0.20949449]\n",
      "  [0.4519905  0.33083373 0.21717581]\n",
      "  [0.43087256 0.23852658 0.3306009 ]\n",
      "  [0.50057095 0.24001484 0.25941417]\n",
      "  [0.5008316  0.24696243 0.252206  ]\n",
      "  [0.4062206  0.33438593 0.25939342]\n",
      "  [0.430536   0.3421309  0.22733311]\n",
      "  [0.40964985 0.3367753  0.25357485]\n",
      "  [0.42040706 0.33959192 0.24000102]\n",
      "  [0.4719111  0.28097278 0.2471161 ]\n",
      "  [0.5413144  0.19429418 0.2643914 ]\n",
      "  [0.3935477  0.23034872 0.37610358]\n",
      "  [0.39327914 0.22677888 0.37994203]\n",
      "  [0.48711312 0.28609362 0.22679329]\n",
      "  [0.53499514 0.19873421 0.26627067]\n",
      "  [0.5187705  0.21590124 0.26532823]\n",
      "  [0.4719186  0.25245392 0.2756274 ]\n",
      "  [0.43928665 0.28766304 0.2730503 ]\n",
      "  [0.41968453 0.30124632 0.2790692 ]\n",
      "  [0.43664876 0.2843442  0.279007  ]\n",
      "  [0.41710997 0.33121768 0.2516723 ]\n",
      "  [0.43870348 0.24285726 0.31843925]\n",
      "  [0.514732   0.21584919 0.2694188 ]\n",
      "  [0.38573864 0.28216648 0.33209488]\n",
      "  [0.42178017 0.2532067  0.32501316]]\n",
      "\n",
      " [[0.7213089  0.1998948  0.07879636]\n",
      "  [0.5576762  0.3665438  0.07577993]\n",
      "  [0.50206673 0.26171532 0.23621793]\n",
      "  [0.5078029  0.23276553 0.25943154]\n",
      "  [0.5733108  0.17496276 0.25172645]\n",
      "  [0.4178485  0.30404633 0.27810514]\n",
      "  [0.4862872  0.3070244  0.2066884 ]\n",
      "  [0.54890245 0.2881248  0.16297275]\n",
      "  [0.539088   0.24834168 0.21257035]\n",
      "  [0.6675743  0.17971383 0.15271185]\n",
      "  [0.55325526 0.24618013 0.20056461]\n",
      "  [0.59838665 0.22250731 0.17910606]\n",
      "  [0.3939713  0.3372593  0.26876944]\n",
      "  [0.43230185 0.33462858 0.23306958]\n",
      "  [0.59531814 0.1953388  0.2093431 ]\n",
      "  [0.51648635 0.26326853 0.22024515]\n",
      "  [0.3629672  0.5228965  0.11413629]\n",
      "  [0.336904   0.55377585 0.10932024]\n",
      "  [0.48369566 0.3083838  0.20792049]\n",
      "  [0.46720335 0.30608416 0.22671257]\n",
      "  [0.4217538  0.35459518 0.22365102]\n",
      "  [0.4469481  0.26542845 0.28762347]\n",
      "  [0.42626697 0.3236376  0.2500955 ]\n",
      "  [0.44745773 0.23660953 0.31593275]\n",
      "  [0.43979618 0.24086145 0.31934237]\n",
      "  [0.4008666  0.2811365  0.31799695]\n",
      "  [0.4133518  0.27653953 0.3101086 ]\n",
      "  [0.35705185 0.3291811  0.31376705]\n",
      "  [0.36192632 0.30738583 0.33068785]\n",
      "  [0.36734235 0.28301132 0.34964627]\n",
      "  [0.38641196 0.28428432 0.3293037 ]\n",
      "  [0.3781637  0.2583761  0.3634602 ]\n",
      "  [0.39108402 0.24749343 0.36142254]\n",
      "  [0.46949747 0.32667467 0.20382781]]\n",
      "\n",
      " [[0.6958132  0.22948338 0.07470341]\n",
      "  [0.52493435 0.41863796 0.05642769]\n",
      "  [0.6229538  0.22404246 0.15300383]\n",
      "  [0.56390643 0.2733553  0.16273826]\n",
      "  [0.28098717 0.47872773 0.2402851 ]\n",
      "  [0.39351273 0.39959997 0.20688727]\n",
      "  [0.3627994  0.39030355 0.24689701]\n",
      "  [0.40671292 0.3511439  0.24214315]\n",
      "  [0.40841863 0.37062258 0.22095878]\n",
      "  [0.3654615  0.221862   0.41267654]\n",
      "  [0.47171575 0.25171986 0.2765644 ]\n",
      "  [0.44972178 0.22087324 0.32940504]\n",
      "  [0.333268   0.3360175  0.33071452]\n",
      "  [0.47647157 0.18303774 0.3404906 ]\n",
      "  [0.6117542  0.19965973 0.18858606]\n",
      "  [0.50814813 0.27368873 0.21816318]\n",
      "  [0.48412824 0.21652639 0.2993453 ]\n",
      "  [0.50316066 0.19434555 0.30249372]\n",
      "  [0.54316616 0.22400472 0.23282911]\n",
      "  [0.4509241  0.33810025 0.21097563]\n",
      "  [0.6389167  0.21466362 0.14641964]\n",
      "  [0.37207043 0.4628484  0.1650812 ]\n",
      "  [0.59995407 0.20464775 0.19539812]\n",
      "  [0.5953063  0.2954619  0.10923181]\n",
      "  [0.48507127 0.29128915 0.2236396 ]\n",
      "  [0.43493825 0.34574082 0.21932095]\n",
      "  [0.51863664 0.2550685  0.22629486]\n",
      "  [0.4869768  0.26226553 0.2507577 ]\n",
      "  [0.6108696  0.1792755  0.20985487]\n",
      "  [0.5356511  0.14896916 0.31537977]\n",
      "  [0.5008245  0.20482495 0.29435053]\n",
      "  [0.4676101  0.2966646  0.23572527]\n",
      "  [0.25427803 0.63444865 0.11127335]\n",
      "  [0.17069307 0.75633055 0.0729764 ]]], shape=(5, 34, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dense = tf.keras.layers.Dense(256,activation='relu',name='dense')(bert_outputs)\n",
    "dense = tf.keras.layers.Dropout(rate=0.1)(dense)\n",
    "dense = tf.keras.layers.Dense(128,activation='relu',name='dense')(dense)\n",
    "dense = tf.keras.layers.Dropout(rate=0.1)(dense)\n",
    "pred = tf.keras.layers.Dense(3,activation='softmax',name='ner')(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 34), dtype=int64, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 1, 1, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = tf.argmax(pred, axis=2)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B',\n",
       " 'I',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'I',\n",
       " 'B',\n",
       " 'B',\n",
       " 'I',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'I',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'I',\n",
       " 'I',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'I',\n",
       " 'I',\n",
       " 'I',\n",
       " 'B',\n",
       " 'B',\n",
       " 'O',\n",
       " 'B',\n",
       " 'B',\n",
       " 'I',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'I',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'B',\n",
       " 'I',\n",
       " 'I']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = [\n",
    "    \"B\",\"I\",\"O\"\n",
    "]\n",
    "[label_list[pred] for predict in predictions for pred in predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Also it is very good for college students who just need a reliable, easy to use computer.',\n",
       " \"For those that care about noise this thing doesn't really make any;\",\n",
       " 'Enjoy that Toshib force and durability unparalleled',\n",
       " \"I know that everyone thinks Macs are overpriced and overrated, but once you get past the initial expense you'll find that they're worth every penny (besides, there's always the financing plan that Best Buy offers).\",\n",
       " ') And printing from either word processor is an adventure.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# asc\n",
    "batch_sentences = [val['sentence'] for key,val in asc_laptop_train.items()]\n",
    "batch_sentences = batch_sentences[:5]\n",
    "batch_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'BertTokenizer' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-0ed0be4836f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'BertTokenizer' object is not callable"
     ]
    }
   ],
   "source": [
    "batch = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3d23f1b5cc41e882ee064a30f85351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d7e54e42cf4652a234ff3127842aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert_layer = TFBertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_outputs = bert_layer(batch)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tf.Tensor(\n",
      "[[[0.01177816 0.05434072 0.03788872 ... 0.02129374 0.06065724 0.0731818 ]\n",
      "  [0.04900315 0.05948583 0.06014106 ... 0.05878973 0.04976443 0.05862797]\n",
      "  [0.04090223 0.03227794 0.08251592 ... 0.04508767 0.05121644 0.07041943]\n",
      "  ...\n",
      "  [0.06782057 0.03102842 0.05161003 ... 0.03413488 0.04394203 0.09786536]\n",
      "  [0.05863757 0.03616944 0.05452959 ... 0.04281745 0.0403833  0.09180778]\n",
      "  [0.0562749  0.03269291 0.05930537 ... 0.0407129  0.04230465 0.09767301]]\n",
      "\n",
      " [[0.0151496  0.0454305  0.06081259 ... 0.02655643 0.04172375 0.06082682]\n",
      "  [0.03468909 0.04066752 0.07092169 ... 0.03017898 0.04306805 0.07808218]\n",
      "  [0.04939688 0.0523417  0.07778107 ... 0.03853113 0.03840958 0.04697841]\n",
      "  ...\n",
      "  [0.06478462 0.04184391 0.07625443 ... 0.03314834 0.04314109 0.06738793]\n",
      "  [0.05132351 0.04204523 0.07971936 ... 0.03857699 0.03868467 0.06687815]\n",
      "  [0.05211025 0.04535615 0.07807521 ... 0.03893257 0.03590168 0.06448051]]\n",
      "\n",
      " [[0.01143003 0.04085291 0.04761512 ... 0.01897375 0.05019692 0.05095039]\n",
      "  [0.04574499 0.02224451 0.06411871 ... 0.03345349 0.05519029 0.131467  ]\n",
      "  [0.05317339 0.02175225 0.09432457 ... 0.03105479 0.03449141 0.1612218 ]\n",
      "  ...\n",
      "  [0.04365258 0.02617014 0.06320437 ... 0.04034196 0.03990983 0.11142118]\n",
      "  [0.04217996 0.02573222 0.06545193 ... 0.03924407 0.03873512 0.11222357]\n",
      "  [0.04218432 0.02605744 0.06747419 ... 0.03910202 0.03944251 0.11176091]]\n",
      "\n",
      " [[0.01537677 0.03900072 0.05026825 ... 0.0285248  0.04774236 0.07874355]\n",
      "  [0.05737169 0.03427441 0.04618213 ... 0.04312816 0.04138633 0.11021977]\n",
      "  [0.06751557 0.03584098 0.05745272 ... 0.03190563 0.04948663 0.1658989 ]\n",
      "  ...\n",
      "  [0.06614535 0.02397279 0.06523623 ... 0.04383694 0.03812877 0.09305226]\n",
      "  [0.1063605  0.01813145 0.07111841 ... 0.02434614 0.04255294 0.09364914]\n",
      "  [0.02819702 0.1133533  0.01793603 ... 0.01241531 0.03920487 0.03116379]]\n",
      "\n",
      " [[0.00964017 0.04211779 0.0400604  ... 0.02125417 0.05320503 0.06966449]\n",
      "  [0.04748664 0.04875056 0.06420206 ... 0.04205277 0.04528201 0.07092831]\n",
      "  [0.05945295 0.04618289 0.05648134 ... 0.04075282 0.04280348 0.09124292]\n",
      "  ...\n",
      "  [0.05199694 0.04288278 0.06781331 ... 0.04229915 0.04143074 0.08095594]\n",
      "  [0.06727878 0.03818509 0.07503955 ... 0.03148477 0.05121363 0.06104828]\n",
      "  [0.07032403 0.03786919 0.07789138 ... 0.02939828 0.05185788 0.05492956]]], shape=(5, 53, 21), dtype=float32)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Tensor.op is meaningless when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-4a05a376a0ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m               }\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m model.compile(loss=losses, optimizer=optimizer, metrics=[custom_acc_orig_tokens, \n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m       \u001b[0;31m# Functional model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m       \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;31m#     'arguments during initialization. Got an unexpected argument:')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_history'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_keras_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_graph_inputs_and_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mcreate_keras_history\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mthe\u001b[0m \u001b[0mraw\u001b[0m \u001b[0mTensorflow\u001b[0m \u001b[0moperations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m   \"\"\"\n\u001b[0;32m--> 191\u001b[0;31m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreated_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_keras_history_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcreated_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    224\u001b[0m                        \u001b[0;34m'op wrapping. Please wrap these ops in a Lambda layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                        '\\n\\n```\\n{example}\\n```\\n'.format(example=example))\n\u001b[0;32m--> 226\u001b[0;31m     \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m  \u001b[0;31m# The Op that created this Tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocessed_ops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m       \u001b[0;31m# Recursively set `_keras_history`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1212\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m     raise AttributeError(\n\u001b[0m\u001b[1;32m   1215\u001b[0m         \"Tensor.op is meaningless when eager execution is enabled.\")\n\u001b[1;32m   1216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Tensor.op is meaningless when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "dense = tf.keras.layers.Dense(256, activation='relu', name='dense')(bert_outputs)\n",
    "\n",
    "dense = tf.keras.layers.Dropout(rate=0.1)(dense)\n",
    "\n",
    "pred = tf.keras.layers.Dense(21, activation='softmax', name='ner')(dense)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=batch, outputs=pred)\n",
    "\n",
    "model.compile(loss=losses, optimizer=optimizer, metrics=[custom_acc_orig_tokens, \n",
    "                                                      custom_acc_orig_non_other_tokens])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with AE baseline - NN+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[I, have, had, this, laptop, for, a, few, mont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...</td>\n",
       "      <td>[Additional, caveat, :, the, base, installatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...</td>\n",
       "      <td>[it, is, of, high, quality, ,, has, a, killer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[O, B, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[The, screen, gets, smeary, and, dusty, very, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[I, previously, owned, an, HP, desktop, and, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>[O, O, O, O, O]</td>\n",
       "      <td>[The, benefits, were, immediate, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[All-, in-, all, ,, I, would, definitely, reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>[O, O, O, O, O]</td>\n",
       "      <td>[just, chill, and, enjoy, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[My, son, and, his, family, have, a, hard, tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[This, is, what, they, told, me, :, It, heats,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 label  \\\n",
       "0    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1    [O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...   \n",
       "2    [O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...   \n",
       "3           [O, B, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                    [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "..                                                 ...   \n",
       "145                                    [O, O, O, O, O]   \n",
       "146         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "147                                    [O, O, O, O, O]   \n",
       "148  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "149  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                              sentence  \n",
       "0    [I, have, had, this, laptop, for, a, few, mont...  \n",
       "1    [Additional, caveat, :, the, base, installatio...  \n",
       "2    [it, is, of, high, quality, ,, has, a, killer,...  \n",
       "3    [The, screen, gets, smeary, and, dusty, very, ...  \n",
       "4    [I, previously, owned, an, HP, desktop, and, a...  \n",
       "..                                                 ...  \n",
       "145                [The, benefits, were, immediate, !]  \n",
       "146  [All-, in-, all, ,, I, would, definitely, reco...  \n",
       "147                       [just, chill, and, enjoy, .]  \n",
       "148  [My, son, and, his, family, have, a, hard, tim...  \n",
       "149  [This, is, what, they, told, me, :, It, heats,...  \n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_laptop_dev_df = pd.DataFrame.from_dict(ae_laptop_dev,orient='index')\n",
    "ae_laptop_dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[I, have, had, this, laptop, for, a, few, mont...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, B, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...</td>\n",
       "      <td>[Additional, caveat, :, the, base, installatio...</td>\n",
       "      <td>[O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...</td>\n",
       "      <td>[it, is, of, high, quality, ,, has, a, killer,...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, B, I, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[O, B, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[The, screen, gets, smeary, and, dusty, very, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[I, previously, owned, an, HP, desktop, and, a...</td>\n",
       "      <td>[O, O, O, O, B, I, O, O, B, I, O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               label  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1  [O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...   \n",
       "2  [O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...   \n",
       "3         [O, B, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                  [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [I, have, had, this, laptop, for, a, few, mont...   \n",
       "1  [Additional, caveat, :, the, base, installatio...   \n",
       "2  [it, is, of, high, quality, ,, has, a, killer,...   \n",
       "3  [The, screen, gets, smeary, and, dusty, very, ...   \n",
       "4  [I, previously, owned, an, HP, desktop, and, a...   \n",
       "\n",
       "                                         predictions  \n",
       "0  [O, O, O, O, B, O, O, O, B, O, O, O, O, O, O, ...  \n",
       "1  [O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...  \n",
       "2  [O, O, O, O, B, O, O, O, B, I, O, O, O, O, O, ...  \n",
       "3         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
       "4                  [O, O, O, O, B, I, O, O, B, I, O]  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0      [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...\n",
       "1      [0, 1, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, ...\n",
       "2      [0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, ...\n",
       "3             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "4                      [0, 0, 0, 0, 1, 2, 0, 0, 1, 2, 0]\n",
       "                             ...                        \n",
       "145                                      [0, 1, 0, 0, 0]\n",
       "146           [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
       "147                                      [0, 1, 0, 1, 0]\n",
       "148    [0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...\n",
       "149    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Name: predictions, Length: 150, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pos_ae(tokenized_sentence):\n",
    "    \"\"\"\n",
    "    Tag sentences using POS tagger and identify consecutive nouns as entities\n",
    "    \"\"\"\n",
    "    pos_sent = tokenized_sentence.apply(lambda sent:nltk.pos_tag(sent,tagset='universal'))\n",
    "    \n",
    "    \n",
    "    # tag with IOB terminology\n",
    "    ae_tag = lambda sent:['O' if token[1] != 'NOUN' \n",
    "                          else 'B' if ((token[1]=='NOUN') & ((sent[ind-1][1]!='NOUN') | (ind==0))) \n",
    "                          else 'I' for ind,token in enumerate(sent)]\n",
    "\n",
    "    return(pos_sent.apply(ae_tag))\n",
    "\n",
    "# since the POS tagger is based on the words themselves and not context.\n",
    "ae_laptop_dev_df['predictions'] = pos_ae(ae_laptop_dev_df['sentence'])\n",
    "ae_laptop_dev_df.head()\n",
    "\n",
    "def convert_int(tagged_tokens):\n",
    "    \"\"\"\n",
    "    Convert B,I,O tags to integers\n",
    "    \"\"\"\n",
    "    return(tagged_tokens.apply(lambda sent: [0 if token=='O' else 1 if token=='B' else 2 for token in sent]))\n",
    "\n",
    "convert_int(ae_laptop_dev_df['predictions'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore AE Regex Parser - business rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Toshiba',\n",
       " 'is',\n",
       " 'aware',\n",
       " 'of',\n",
       " 'the',\n",
       " 'issue',\n",
       " 'but',\n",
       " 'unless',\n",
       " 'the',\n",
       " 'extended',\n",
       " 'warrenty',\n",
       " 'is',\n",
       " 'bought',\n",
       " 'Toshiba',\n",
       " 'will',\n",
       " 'do',\n",
       " 'nothing',\n",
       " 'about',\n",
       " 'it',\n",
       " '.']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['B',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cover', 'for', 'the', 'DVD', 'drive']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['B', 'I', 'I', 'I', 'I']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'previously',\n",
       " 'owned',\n",
       " 'an',\n",
       " 'HP',\n",
       " 'desktop',\n",
       " 'and',\n",
       " 'a',\n",
       " 'Dell',\n",
       " 'laptop',\n",
       " '.']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  I/PRP\n",
      "  previously/RB\n",
      "  owned/VBD\n",
      "  an/DT\n",
      "  (NP HP/NNP desktop/NN)\n",
      "  and/CC\n",
      "  a/DT\n",
      "  (NP Dell/NNP laptop/NN)\n",
      "  ./.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'B', 'I', 'O']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>predictions</th>\n",
       "      <th>predictions_1</th>\n",
       "      <th>iob_gold_tree</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[I, have, had, this, laptop, for, a, few, mont...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, B, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[(I, PRP, O), (have, VBP, O), (had, VBN, O), (...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...</td>\n",
       "      <td>[Additional, caveat, :, the, base, installatio...</td>\n",
       "      <td>[O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...</td>\n",
       "      <td>[O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...</td>\n",
       "      <td>[(Additional, JJ, O), (caveat, NN, O), (:, :, ...</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...</td>\n",
       "      <td>[it, is, of, high, quality, ,, has, a, killer,...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, B, I, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, B, B, O, O, O, O, O, ...</td>\n",
       "      <td>[(it, PRP, O), (is, VBZ, O), (of, IN, O), (hig...</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[O, B, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[The, screen, gets, smeary, and, dusty, very, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[(The, DT, O), (screen, JJ, B-NP), (gets, VBZ,...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[I, previously, owned, an, HP, desktop, and, a...</td>\n",
       "      <td>[O, O, O, O, B, I, O, O, B, I, O]</td>\n",
       "      <td>[O, O, O, O, B, I, O, O, B, I, O]</td>\n",
       "      <td>[(I, PRP, O), (previously, RB, O), (owned, VBD...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               label  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1  [O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...   \n",
       "2  [O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...   \n",
       "3         [O, B, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                  [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [I, have, had, this, laptop, for, a, few, mont...   \n",
       "1  [Additional, caveat, :, the, base, installatio...   \n",
       "2  [it, is, of, high, quality, ,, has, a, killer,...   \n",
       "3  [The, screen, gets, smeary, and, dusty, very, ...   \n",
       "4  [I, previously, owned, an, HP, desktop, and, a...   \n",
       "\n",
       "                                         predictions  \\\n",
       "0  [O, O, O, O, B, O, O, O, B, O, O, O, O, O, O, ...   \n",
       "1  [O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...   \n",
       "2  [O, O, O, O, B, O, O, O, B, I, O, O, O, O, O, ...   \n",
       "3         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                  [O, O, O, O, B, I, O, O, B, I, O]   \n",
       "\n",
       "                                       predictions_1  \\\n",
       "0  [O, O, O, O, B, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1  [O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...   \n",
       "2  [O, O, O, O, B, O, O, O, B, B, O, O, O, O, O, ...   \n",
       "3         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                  [O, O, O, O, B, I, O, O, B, I, O]   \n",
       "\n",
       "                                       iob_gold_tree  accuracy  accuracy_1  \n",
       "0  [(I, PRP, O), (have, VBP, O), (had, VBN, O), (...  0.888889    0.944444  \n",
       "1  [(Additional, JJ, O), (caveat, NN, O), (:, :, ...  0.840000    0.840000  \n",
       "2  [(it, PRP, O), (is, VBZ, O), (of, IN, O), (hig...  0.894737    0.921053  \n",
       "3  [(The, DT, O), (screen, JJ, B-NP), (gets, VBZ,...  0.928571    0.928571  \n",
       "4  [(I, PRP, O), (previously, RB, O), (owned, VBD...  0.636364    0.636364  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try a more sophisticated method for chunking\n",
    "def regex_parser(tokenized_sentence,verbose=False):\n",
    "    \"\"\"\n",
    "    Use a Regex Parser to provide some context around noun phrases\n",
    "    \"\"\"\n",
    "    pos_sent = nltk.pos_tag(tokenized_sentence)\n",
    "#     print(pos_sent)\n",
    "#     grammar = r\"\"\"\n",
    "#       NP: {<DT|PP\\$>?<JJ>*<NN>}   # chunk determiner/possessive, adjectives and noun\n",
    "#           {<NNP>+}                # chunk sequences of proper nouns\n",
    "#     \"\"\"\n",
    "    \n",
    "    # Update Grammar Regex to include prepositional phrases ala Semeval annotation guidelines\n",
    "    grammar = r\"\"\"\n",
    "    NP: {<NN><IN><DT><NN|NNP>+}\n",
    "        {<NNP><NN>}\n",
    "        {<NNP>+}\n",
    "        {<NN>+}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    cp = nltk.RegexpParser(grammar)\n",
    "\n",
    "    tree = cp.parse(pos_sent)\n",
    "    \n",
    "    if verbose: print(tree)\n",
    "    \n",
    "    iob = [el[2][0] for el in nltk.chunk.util.tree2conlltags(tree)]\n",
    "    \n",
    "    return(iob)\n",
    "\n",
    "# print example\n",
    "ae_laptop_train['15']['sentence']\n",
    "regex_parser(ae_laptop_train['15']['sentence'])\n",
    "\n",
    "print(['cover','for','the','DVD','drive'])\n",
    "regex_parser(['cover','for','the','DVD','drive'])\n",
    "\n",
    "ae_laptop_dev_df.iloc[4]['sentence']\n",
    "regex_parser(ae_laptop_dev_df.iloc[4]['sentence'],verbose=True)\n",
    "\n",
    "# since the POS tagger is based on the words themselves and not context.\n",
    "ae_laptop_dev_df['predictions_1'] = ae_laptop_dev_df['sentence'].apply(lambda x: regex_parser(x))\n",
    "ae_laptop_dev_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore AE evaluation - CE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haven't seen many papers using CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.837730665815654"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only using 0,1 because there aren't many very large token phrases\n",
    "log_loss(convert_int(pd.DataFrame(ae_laptop_dev_df.iloc[0]['label'])),convert_int(pd.DataFrame(ae_laptop_dev_df.iloc[0]['predictions'])),labels=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore AE evaluation - SemEval14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.davidsbatista.net/blog/2018/05/09/Named_Entity_Evaluation/  \n",
    "- partial boundary match over the surface string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO need to explore how we want to move forward with all sentences rather than just 1.\n",
    "# Should try to implement the SemEval14 evaluation criteria bc this is best practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO amend this tree structure for all predictions as well\n",
    "print('\\nGold Standard:')\n",
    "# tag every sentence with the pos\n",
    "gold_tree = ae_laptop_dev_df['sentence'].apply(lambda x: nltk.pos_tag(x))\n",
    "print(gold_tree)\n",
    "iob_gold_tree = [nltk.Tree('S',\n",
    "                           [(el[0], el[1], ae_laptop_dev_df.iloc[tree_ind]['label'][ind])\n",
    "                            if ae_laptop_dev_df.iloc[tree_ind]['label'][ind]=='O'\n",
    "                            else (el[0], el[1], ae_laptop_dev_df.iloc[tree_ind]['label'][ind] + '-NP')\n",
    "                            for ind,el in enumerate(tree)])\n",
    "                for tree_ind, tree in enumerate(gold_tree)]\n",
    "ae_laptop_dev_df['iob_gold_tree'] = iob_gold_tree\n",
    "ae_laptop_dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['laptop'], ['months']],\n",
       " [['caveat'],\n",
       "  ['base', 'installation'],\n",
       "  ['Toshiba'],\n",
       "  ['software'],\n",
       "  ['user'],\n",
       "  ['liking']],\n",
       " [['quality'], ['killer', 'GUI'], ['lots'], ['applications']],\n",
       " [],\n",
       " [['HP', 'desktop'], ['Dell', 'laptop']]]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [['base', 'installation'], ['software']],\n",
       " [['quality'], ['GUI'], ['applications'], ['use']],\n",
       " [['screen']],\n",
       " []]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_entities(sentence_lst, predictions_lst):\n",
    "    \"\"\"\n",
    "    Reformat the IOB structure to get the actual entities from the sentence\n",
    "    \"\"\"\n",
    "    \n",
    "    # for every sentence, iterate through\n",
    "    all_entities = []\n",
    "    for sample in range(len(predictions_lst)):\n",
    "    \n",
    "        # get indices where entities are identified\n",
    "        predictions = np.array(predictions_lst[sample])\n",
    "        ind = (predictions == 'B') | (predictions == 'I')\n",
    "        \n",
    "        # create list of numerical indices and boolean indices. ex. [(4, True), (10, True), (11, True), (15, True)]\n",
    "        ind_tuple = [num_ind for num_ind in list(enumerate(ind)) if num_ind[1]==True]\n",
    "        \n",
    "        # get the sentence of interest. identify what these entities are\n",
    "        sentence = np.array(sentence_lst[sample])\n",
    "\n",
    "        # group the phrases together\n",
    "        entities = []\n",
    "        for subset,num_ind_tuple in zip(sentence[ind], ind_tuple): # [('price', (4, True)), ('netbook', (10, True)), ('*', (11, True)), ('machine', (15, True))]\n",
    "            # put the B in entities\n",
    "            if predictions[num_ind_tuple[0]][0] == 'B':\n",
    "                entities.append([subset])\n",
    "            # if the tag is I, add to the last item of the list\n",
    "            elif predictions[num_ind_tuple[0]][0] == 'I':\n",
    "                last_entry = entities.pop()\n",
    "                last_entry.append(subset)\n",
    "                entities.append(last_entry)\n",
    "            # there should not be any 'O' indices here\n",
    "            else:\n",
    "                print('Error')\n",
    "        all_entities.append(entities)\n",
    "    return(all_entities)\n",
    "\n",
    "prediction_entities = get_entities(ae_laptop_dev_df.sentence,ae_laptop_dev_df.predictions)\n",
    "gold_entities = get_entities(ae_laptop_dev_df.sentence,ae_laptop_dev_df.label)\n",
    "prediction_entities[:5]\n",
    "gold_entities[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_index</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[base, installation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[software]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[quality]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>[GUI]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>[applications]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_index                entity\n",
       "0             1  [base, installation]\n",
       "1             1            [software]\n",
       "2             2             [quality]\n",
       "3             2                 [GUI]\n",
       "4             2        [applications]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_index</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[laptop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[months]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[caveat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[base, installation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[Toshiba]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_index                entity\n",
       "0             0              [laptop]\n",
       "1             0              [months]\n",
       "2             1              [caveat]\n",
       "3             1  [base, installation]\n",
       "4             1             [Toshiba]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correct: 107\n",
      "Partial: 25\n",
      "Missed: 15\n",
      "Spurious: 310\n"
     ]
    }
   ],
   "source": [
    "def get_ae_eval_features(gold_entities,prediction_entities,verbose=False):\n",
    "    # TODO need to generalize and do for all samples\n",
    "    # TODO may later need to update these calculations to encompass sentence location.\n",
    "    y_true_df = pd.DataFrame([[ind,sub_el] for ind,el in enumerate(gold_entities) for sub_el in el], columns=['sample_index','entity'])\n",
    "    y_pred_df = pd.DataFrame([[ind,sub_el] for ind,el in enumerate(prediction_entities) for sub_el in el], columns=['sample_index','entity'])\n",
    "    print('True')\n",
    "    display(y_true_df.head())\n",
    "    print('Pred')\n",
    "    display(y_pred_df.head())\n",
    "\n",
    "    cor = 0\n",
    "    inc = 0\n",
    "    par = 0\n",
    "    mis = 0\n",
    "    spu = 0\n",
    "\n",
    "    for el in range(len(gold_entities)):\n",
    "        if verbose:\n",
    "            print('\\n',el)\n",
    "        true_subset = y_true_df[y_true_df.sample_index == el]\n",
    "        pred_subset = y_pred_df[y_pred_df.sample_index == el]\n",
    "        true_entities = set(true_subset.entity.apply(lambda x: '_'.join(x)))\n",
    "        pred_entities = set(pred_subset.entity.apply(lambda x: '_'.join(x)))\n",
    "        if verbose:\n",
    "            print('True')\n",
    "            print(true_entities)\n",
    "            print('Pred')\n",
    "            print(pred_entities)\n",
    "\n",
    "        # get correct\n",
    "        cor_entities = true_entities & pred_entities\n",
    "        if verbose:\n",
    "            print(f'Correct entities: {cor_entities}')\n",
    "        cor += len(cor_entities)\n",
    "        true_entities = true_entities - cor_entities\n",
    "        pred_entities = pred_entities - cor_entities\n",
    "\n",
    "        # get partial and missed\n",
    "        for true in true_entities:\n",
    "            # Take into account if the prediction contains a portion of the correct and if correct contains a portion of the prediction\n",
    "            par_entities = set([pred for pred in pred_entities if (true in pred) | (pred in true)])\n",
    "            if len(par_entities) != 0:\n",
    "                if verbose:\n",
    "                    print(f'Partial entities: {set([true])}')\n",
    "                par += len(par_entities)\n",
    "                true_entities = true_entities - set([true])\n",
    "                pred_entities = pred_entities - par_entities\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f'Missed entities: {set([true])}')\n",
    "                mis += 1\n",
    "                true_entities = true_entities - set([true])\n",
    "\n",
    "        if len(true_entities) == 0:\n",
    "            if verbose:\n",
    "                print(f'Spurious entities: {pred_entities}')\n",
    "            spu += len(pred_entities)\n",
    "        else:\n",
    "            print('Error')\n",
    "\n",
    "    print(f'\\nCorrect: {cor}')\n",
    "    print(f'Partial: {par}')\n",
    "    print(f'Missed: {mis}')\n",
    "    print(f'Spurious: {spu}')\n",
    "    return(cor,par,mis,spu,inc)\n",
    "cor,par,mis,spu,inc = get_ae_eval_features(gold_entities,prediction_entities,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_index</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[base, installation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[software]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[quality]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>[GUI]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>[applications]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_index                entity\n",
       "0             1  [base, installation]\n",
       "1             1            [software]\n",
       "2             2             [quality]\n",
       "3             2                 [GUI]\n",
       "4             2        [applications]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_index</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[laptop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[months]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[caveat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[base, installation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[Toshiba]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_index                entity\n",
       "0             0              [laptop]\n",
       "1             0              [months]\n",
       "2             1              [caveat]\n",
       "3             1  [base, installation]\n",
       "4             1             [Toshiba]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correct: 107\n",
      "Partial: 25\n",
      "Missed: 15\n",
      "Spurious: 310\n",
      "\n",
      "Precision: \t0.2703619909502262\n",
      "Recall: \t0.8129251700680272\n",
      "F1-Score: \t0.40577249575551777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2703619909502262, 0.8129251700680272, 0.40577249575551777)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ae_eval(sentence_lst, y_true, y_pred,verbose=False):\n",
    "    \"\"\"\n",
    "    Get entity recognition evaluations accoridng to the partial match SemEval strategy\n",
    "    \"\"\"\n",
    "    prediction_entities = get_entities(sentence_lst,y_pred)\n",
    "    gold_entities = get_entities(sentence_lst,y_true)\n",
    "    \n",
    "    cor,par,mis,spu,inc = get_ae_eval_features(gold_entities,prediction_entities,verbose=verbose)\n",
    "    \n",
    "    pos_eval = cor + inc + par + mis\n",
    "    act_eval = cor + inc + par + spu\n",
    "\n",
    "    precision = (cor + .5 * par) / act_eval\n",
    "    recall = (cor + .5 * par) / pos_eval\n",
    "    f1 = ( 2* precision * recall) / (precision + recall)\n",
    "    \n",
    "    print(f'\\nPrecision: \\t{precision}')\n",
    "    print(f'Recall: \\t{recall}')\n",
    "    print(f'F1-Score: \\t{f1}')\n",
    "    return(precision, recall, f1)\n",
    "\n",
    "get_ae_eval(ae_laptop_dev_df.sentence,ae_laptop_dev_df.label,ae_laptop_dev_df.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_index</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[base, installation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[software]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[quality]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>[GUI]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>[applications]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_index                entity\n",
       "0             1  [base, installation]\n",
       "1             1            [software]\n",
       "2             2             [quality]\n",
       "3             2                 [GUI]\n",
       "4             2        [applications]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_index</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[laptop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[caveat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[base, installation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[Toshiba]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[software]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_index                entity\n",
       "0             0              [laptop]\n",
       "1             1              [caveat]\n",
       "2             1  [base, installation]\n",
       "3             1             [Toshiba]\n",
       "4             1            [software]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correct: 81\n",
      "Partial: 26\n",
      "Missed: 39\n",
      "Spurious: 253\n",
      "\n",
      "Precision: \t0.2611111111111111\n",
      "Recall: \t0.6438356164383562\n",
      "F1-Score: \t0.3715415019762846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2611111111111111, 0.6438356164383562, 0.3715415019762846)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ae_eval(ae_laptop_dev_df.sentence,ae_laptop_dev_df.label,ae_laptop_dev_df.predictions_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore AE evaluation - ChunkScore\n",
    "https://stackoverflow.com/questions/17325554/difference-between-iob-accuracy-and-precision  \n",
    "Somehow, this is not working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      "(S\n",
      "  (NP Toshiba/NNP)\n",
      "  is/VBZ\n",
      "  aware/JJ\n",
      "  of/IN\n",
      "  (NP the/DT issue/NN)\n",
      "  but/CC\n",
      "  unless/IN\n",
      "  (NP the/DT extended/JJ warrenty/NN)\n",
      "  is/VBZ\n",
      "  bought/VBN\n",
      "  (NP Toshiba/NNP)\n",
      "  will/MD\n",
      "  do/VB\n",
      "  (NP nothing/NN)\n",
      "  about/IN\n",
      "  it/PRP\n",
      "  ./.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Toshiba', 'NNP', 'B-NP'),\n",
       " ('is', 'VBZ', 'O'),\n",
       " ('aware', 'JJ', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('the', 'DT', 'B-NP'),\n",
       " ('issue', 'NN', 'I-NP'),\n",
       " ('but', 'CC', 'O'),\n",
       " ('unless', 'IN', 'O'),\n",
       " ('the', 'DT', 'B-NP'),\n",
       " ('extended', 'JJ', 'I-NP'),\n",
       " ('warrenty', 'NN', 'I-NP'),\n",
       " ('is', 'VBZ', 'O'),\n",
       " ('bought', 'VBN', 'O'),\n",
       " ('Toshiba', 'NNP', 'B-NP'),\n",
       " ('will', 'MD', 'O'),\n",
       " ('do', 'VB', 'O'),\n",
       " ('nothing', 'NN', 'B-NP'),\n",
       " ('about', 'IN', 'O'),\n",
       " ('it', 'PRP', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['B',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gold Standard:\n",
      "(S\n",
      "  Toshiba/NNP\n",
      "  is/VBZ\n",
      "  aware/JJ\n",
      "  of/IN\n",
      "  the/DT\n",
      "  issue/NN\n",
      "  but/CC\n",
      "  unless/IN\n",
      "  the/DT\n",
      "  (NP extended/JJ warrenty/NN)\n",
      "  is/VBZ\n",
      "  bought/VBN\n",
      "  Toshiba/NNP\n",
      "  will/MD\n",
      "  do/VB\n",
      "  nothing/NN\n",
      "  about/IN\n",
      "  it/PRP\n",
      "  ./.)\n",
      "ChunkParse score:\n",
      "    IOB Accuracy:  60.0%%\n",
      "    Precision:      0.0%%\n",
      "    Recall:         0.0%%\n",
      "    F-Measure:      0.0%%\n"
     ]
    }
   ],
   "source": [
    "# TODO get ChunkScore to work\n",
    "tokenized_sentence = ae_laptop_train['15']['sentence']\n",
    "pos_sent = nltk.pos_tag(tokenized_sentence)\n",
    "\n",
    "##\n",
    "grammar = r\"\"\"\n",
    "  NP: {<DT|PP\\$>?<JJ>*<NN>}   # chunk determiner/possessive, adjectives and noun\n",
    "      {<NNP>+}                # chunk sequences of proper nouns\n",
    "\"\"\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "\n",
    "tree = cp.parse(pos_sent)\n",
    "\n",
    "iob = [el[2][0] for el in nltk.chunk.util.tree2conlltags(tree)]\n",
    "\n",
    "print('Prediction:')\n",
    "print(tree)\n",
    "nltk.chunk.util.tree2conlltags(tree)\n",
    "regex_parser(ae_laptop_train['15']['sentence'])\n",
    "##\n",
    "\n",
    "gold_tree = pos_sent\n",
    "print('\\nGold Standard:')\n",
    "# create the tree with IOB input\n",
    "iob_gold_tree = nltk.Tree('S',[(el[0], el[1], ae_laptop_train['15']['label'][ind]) if ae_laptop_train['15']['label'][ind]=='O' \n",
    "                               else (el[0], el[1], ae_laptop_train['15']['label'][ind] + '-NP')for ind,el in enumerate(gold_tree)])\n",
    "print(nltk.chunk.util.conlltags2tree(iob_gold_tree))\n",
    "# print(nltk.chunk.util.conlltags2tree([(el[0], el[1], ae_laptop_train['15']['label'][ind])for ind,el in enumerate(gold_tree)]))\n",
    "# print(nltk.chunk.util.conlltags2tree())\n",
    "print(cp.evaluate([iob_gold_tree]))\n",
    "\n",
    "# nltk.chunk.util.tagstr2tree(' '.join(tokenized_sentence), chunk_label='NP', root_label='S', sep='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gold Standard:\n",
      "0      [(I, PRP), (have, VBP), (had, VBN), (this, DT)...\n",
      "1      [(Additional, JJ), (caveat, NN), (:, :), (the,...\n",
      "2      [(it, PRP), (is, VBZ), (of, IN), (high, JJ), (...\n",
      "3      [(The, DT), (screen, JJ), (gets, VBZ), (smeary...\n",
      "4      [(I, PRP), (previously, RB), (owned, VBD), (an...\n",
      "                             ...                        \n",
      "145    [(The, DT), (benefits, NNS), (were, VBD), (imm...\n",
      "146    [(All-, JJ), (in-, JJ), (all, DT), (,, ,), (I,...\n",
      "147    [(just, RB), (chill, NN), (and, CC), (enjoy, N...\n",
      "148    [(My, PRP$), (son, NN), (and, CC), (his, PRP$)...\n",
      "149    [(This, DT), (is, VBZ), (what, WP), (they, PRP...\n",
      "Name: sentence, Length: 150, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>predictions</th>\n",
       "      <th>predictions_1</th>\n",
       "      <th>iob_gold_tree</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[I, have, had, this, laptop, for, a, few, mont...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, B, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[(I, PRP, O), (have, VBP, O), (had, VBN, O), (...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...</td>\n",
       "      <td>[Additional, caveat, :, the, base, installatio...</td>\n",
       "      <td>[O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...</td>\n",
       "      <td>[O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...</td>\n",
       "      <td>[(Additional, JJ, O), (caveat, NN, O), (:, :, ...</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...</td>\n",
       "      <td>[it, is, of, high, quality, ,, has, a, killer,...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, B, I, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, B, B, O, O, O, O, O, ...</td>\n",
       "      <td>[(it, PRP, O), (is, VBZ, O), (of, IN, O), (hig...</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[O, B, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[The, screen, gets, smeary, and, dusty, very, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[(The, DT, O), (screen, JJ, B-NP), (gets, VBZ,...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[I, previously, owned, an, HP, desktop, and, a...</td>\n",
       "      <td>[O, O, O, O, B, I, O, O, B, I, O]</td>\n",
       "      <td>[O, O, O, O, B, B, O, O, B, B, O]</td>\n",
       "      <td>[(I, PRP, O), (previously, RB, O), (owned, VBD...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               label  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1  [O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...   \n",
       "2  [O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...   \n",
       "3         [O, B, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                  [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [I, have, had, this, laptop, for, a, few, mont...   \n",
       "1  [Additional, caveat, :, the, base, installatio...   \n",
       "2  [it, is, of, high, quality, ,, has, a, killer,...   \n",
       "3  [The, screen, gets, smeary, and, dusty, very, ...   \n",
       "4  [I, previously, owned, an, HP, desktop, and, a...   \n",
       "\n",
       "                                         predictions  \\\n",
       "0  [O, O, O, O, B, O, O, O, B, O, O, O, O, O, O, ...   \n",
       "1  [O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...   \n",
       "2  [O, O, O, O, B, O, O, O, B, I, O, O, O, O, O, ...   \n",
       "3         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                  [O, O, O, O, B, I, O, O, B, I, O]   \n",
       "\n",
       "                                       predictions_1  \\\n",
       "0  [O, O, O, O, B, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1  [O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...   \n",
       "2  [O, O, O, O, B, O, O, O, B, B, O, O, O, O, O, ...   \n",
       "3         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                  [O, O, O, O, B, B, O, O, B, B, O]   \n",
       "\n",
       "                                       iob_gold_tree  accuracy  accuracy_1  \n",
       "0  [(I, PRP, O), (have, VBP, O), (had, VBN, O), (...  0.888889    1.000000  \n",
       "1  [(Additional, JJ, O), (caveat, NN, O), (:, :, ...  0.840000    0.840000  \n",
       "2  [(it, PRP, O), (is, VBZ, O), (of, IN, O), (hig...  0.894737    0.921053  \n",
       "3  [(The, DT, O), (screen, JJ, B-NP), (gets, VBZ,...  0.928571    0.928571  \n",
       "4  [(I, PRP, O), (previously, RB, O), (owned, VBD...  0.636364    0.818182  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO get ChunkScore to work on all dev\n",
    "print('\\nGold Standard:')\n",
    "# tag every sentence with the pos\n",
    "gold_tree = ae_laptop_dev_df['sentence'].apply(lambda x: nltk.pos_tag(x))\n",
    "print(gold_tree)\n",
    "iob_gold_tree = [nltk.Tree('S',\n",
    "                           [(el[0], el[1], ae_laptop_dev_df.iloc[tree_ind]['label'][ind])\n",
    "                            if ae_laptop_dev_df.iloc[tree_ind]['label'][ind]=='O'\n",
    "                            else (el[0], el[1], ae_laptop_dev_df.iloc[tree_ind]['label'][ind] + '-NP')\n",
    "                            for ind,el in enumerate(tree)])\n",
    "                for tree_ind, tree in enumerate(gold_tree)]\n",
    "ae_laptop_dev_df['iob_gold_tree'] = iob_gold_tree\n",
    "ae_laptop_dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore AE evaluation - Token Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>predictions</th>\n",
       "      <th>predictions_1</th>\n",
       "      <th>iob_gold_tree</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[I, have, had, this, laptop, for, a, few, mont...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, B, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[(I, PRP, O), (have, VBP, O), (had, VBN, O), (...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...</td>\n",
       "      <td>[Additional, caveat, :, the, base, installatio...</td>\n",
       "      <td>[O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...</td>\n",
       "      <td>[O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...</td>\n",
       "      <td>[(Additional, JJ, O), (caveat, NN, O), (:, :, ...</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...</td>\n",
       "      <td>[it, is, of, high, quality, ,, has, a, killer,...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, B, I, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, B, B, O, O, O, O, O, ...</td>\n",
       "      <td>[(it, PRP, O), (is, VBZ, O), (of, IN, O), (hig...</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[O, B, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[The, screen, gets, smeary, and, dusty, very, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[(The, DT, O), (screen, JJ, B-NP), (gets, VBZ,...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[I, previously, owned, an, HP, desktop, and, a...</td>\n",
       "      <td>[O, O, O, O, B, I, O, O, B, I, O]</td>\n",
       "      <td>[O, O, O, O, B, B, O, O, B, B, O]</td>\n",
       "      <td>[(I, PRP, O), (previously, RB, O), (owned, VBD...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               label  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1  [O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...   \n",
       "2  [O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...   \n",
       "3         [O, B, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                  [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [I, have, had, this, laptop, for, a, few, mont...   \n",
       "1  [Additional, caveat, :, the, base, installatio...   \n",
       "2  [it, is, of, high, quality, ,, has, a, killer,...   \n",
       "3  [The, screen, gets, smeary, and, dusty, very, ...   \n",
       "4  [I, previously, owned, an, HP, desktop, and, a...   \n",
       "\n",
       "                                         predictions  \\\n",
       "0  [O, O, O, O, B, O, O, O, B, O, O, O, O, O, O, ...   \n",
       "1  [O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...   \n",
       "2  [O, O, O, O, B, O, O, O, B, I, O, O, O, O, O, ...   \n",
       "3         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                  [O, O, O, O, B, I, O, O, B, I, O]   \n",
       "\n",
       "                                       predictions_1  \\\n",
       "0  [O, O, O, O, B, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1  [O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...   \n",
       "2  [O, O, O, O, B, O, O, O, B, B, O, O, O, O, O, ...   \n",
       "3         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                  [O, O, O, O, B, B, O, O, B, B, O]   \n",
       "\n",
       "                                       iob_gold_tree  accuracy  accuracy_1  \n",
       "0  [(I, PRP, O), (have, VBP, O), (had, VBN, O), (...  0.888889    0.944444  \n",
       "1  [(Additional, JJ, O), (caveat, NN, O), (:, :, ...  0.840000    0.840000  \n",
       "2  [(it, PRP, O), (is, VBZ, O), (of, IN, O), (hig...  0.894737    0.921053  \n",
       "3  [(The, DT, O), (screen, JJ, B-NP), (gets, VBZ,...  0.928571    0.928571  \n",
       "4  [(I, PRP, O), (previously, RB, O), (owned, VBD...  0.636364    0.636364  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.845546</td>\n",
       "      <td>0.843995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.094523</td>\n",
       "      <td>0.106273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.786654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.851648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.919956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         accuracy  accuracy_1\n",
       "count  150.000000  150.000000\n",
       "mean     0.845546    0.843995\n",
       "std      0.094523    0.106273\n",
       "min      0.571429    0.555556\n",
       "25%      0.777778    0.786654\n",
       "50%      0.846154    0.851648\n",
       "75%      0.909091    0.919956\n",
       "max      1.000000    1.000000"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_accuracy(true,predictions):\n",
    "    accuracy = []\n",
    "    for true_el, predict_el in zip(true,predictions):\n",
    "        accuracy.append((np.array(predict_el) == np.array(true_el)).sum() / (len(true_el)))\n",
    "    return(accuracy)\n",
    "\n",
    "ae_laptop_dev_df['accuracy'] = get_accuracy(ae_laptop_dev_df.label,ae_laptop_dev_df.predictions)\n",
    "ae_laptop_dev_df['accuracy_1'] = get_accuracy(ae_laptop_dev_df.label,ae_laptop_dev_df.predictions_1)\n",
    "ae_laptop_dev_df.head()\n",
    "ae_laptop_dev_df[['accuracy','accuracy_1']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export samples that are well / poorly extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    107\n",
      "1    147\n",
      "2      4\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>predictions</th>\n",
       "      <th>predictions_1</th>\n",
       "      <th>iob_gold_tree</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>[O, O, O, O, O, O, O]</td>\n",
       "      <td>[The, Mac, Book, Pro, performs, flawlessly, .]</td>\n",
       "      <td>[O, B, I, I, O, O, O]</td>\n",
       "      <td>[O, B, I, I, O, O, O]</td>\n",
       "      <td>[(The, DT, O), (Mac, NNP, O), (Book, NNP, O), ...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>[O, O, O, O, O]</td>\n",
       "      <td>[just, chill, and, enjoy, .]</td>\n",
       "      <td>[O, B, O, B, O]</td>\n",
       "      <td>[O, B, O, B, O]</td>\n",
       "      <td>[(just, RB, O), (chill, NN, O), (and, CC, O), ...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[I, previously, owned, an, HP, desktop, and, a...</td>\n",
       "      <td>[O, O, O, O, B, I, O, O, B, I, O]</td>\n",
       "      <td>[O, O, O, O, B, B, O, O, B, B, O]</td>\n",
       "      <td>[(I, PRP, O), (previously, RB, O), (owned, VBD...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 label  \\\n",
       "107              [O, O, O, O, O, O, O]   \n",
       "147                    [O, O, O, O, O]   \n",
       "4    [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                              sentence  \\\n",
       "107     [The, Mac, Book, Pro, performs, flawlessly, .]   \n",
       "147                       [just, chill, and, enjoy, .]   \n",
       "4    [I, previously, owned, an, HP, desktop, and, a...   \n",
       "\n",
       "                           predictions                      predictions_1  \\\n",
       "107              [O, B, I, I, O, O, O]              [O, B, I, I, O, O, O]   \n",
       "147                    [O, B, O, B, O]                    [O, B, O, B, O]   \n",
       "4    [O, O, O, O, B, I, O, O, B, I, O]  [O, O, O, O, B, B, O, O, B, B, O]   \n",
       "\n",
       "                                         iob_gold_tree  accuracy  accuracy_1  \n",
       "107  [(The, DT, O), (Mac, NNP, O), (Book, NNP, O), ...  0.571429    0.571429  \n",
       "147  [(just, RB, O), (chill, NN, O), (and, CC, O), ...  0.600000    0.600000  \n",
       "4    [(I, PRP, O), (previously, RB, O), (owned, VBD...  0.636364    0.636364  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mac Book Pro performs flawlessly .\n",
      "just chill and enjoy .\n",
      "I previously owned an HP desktop and a Dell laptop .\n",
      "147     45\n",
      "148     70\n",
      "149    113\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>predictions</th>\n",
       "      <th>predictions_1</th>\n",
       "      <th>iob_gold_tree</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[O, O, B, O, B, O]</td>\n",
       "      <td>[Like, the, price, and, operation, .]</td>\n",
       "      <td>[O, O, B, O, B, O]</td>\n",
       "      <td>[O, O, B, O, B, O]</td>\n",
       "      <td>[(Like, IN, O), (the, DT, O), (price, NN, B-NP...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>[O, B, O, O, O, B, O, O, O]</td>\n",
       "      <td>[The, design, is, awesome, ,, quality, is, unp...</td>\n",
       "      <td>[O, B, O, O, O, B, O, O, O]</td>\n",
       "      <td>[O, B, O, O, O, B, O, O, O]</td>\n",
       "      <td>[(The, DT, O), (design, NN, B-NP), (is, VBZ, O...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>[O, B, I, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[The, battery, life, is, amazingly, long, at, ...</td>\n",
       "      <td>[O, B, I, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, B, I, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[(The, DT, O), (battery, NN, B-NP), (life, NN,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             label  \\\n",
       "45                              [O, O, B, O, B, O]   \n",
       "70                     [O, B, O, O, O, B, O, O, O]   \n",
       "113  [O, B, I, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                              sentence  \\\n",
       "45               [Like, the, price, and, operation, .]   \n",
       "70   [The, design, is, awesome, ,, quality, is, unp...   \n",
       "113  [The, battery, life, is, amazingly, long, at, ...   \n",
       "\n",
       "                                       predictions  \\\n",
       "45                              [O, O, B, O, B, O]   \n",
       "70                     [O, B, O, O, O, B, O, O, O]   \n",
       "113  [O, B, I, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                     predictions_1  \\\n",
       "45                              [O, O, B, O, B, O]   \n",
       "70                     [O, B, O, O, O, B, O, O, O]   \n",
       "113  [O, B, I, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                         iob_gold_tree  accuracy  accuracy_1  \n",
       "45   [(Like, IN, O), (the, DT, O), (price, NN, B-NP...       1.0         1.0  \n",
       "70   [(The, DT, O), (design, NN, B-NP), (is, VBZ, O...       1.0         1.0  \n",
       "113  [(The, DT, O), (battery, NN, B-NP), (life, NN,...       1.0         1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Like the price and operation .\n",
      "The design is awesome , quality is unprecedented .\n",
      "The battery life is amazingly long at 7hrs and 5hrs if you use it .\n"
     ]
    }
   ],
   "source": [
    "def get_bad_examples(n = 1):\n",
    "    ind = np.argpartition(ae_laptop_dev_df.accuracy + ae_laptop_dev_df.accuracy_1,n)[:n]\n",
    "    print(ind)\n",
    "    sort_ind = ind[np.argsort((ae_laptop_dev_df.accuracy + ae_laptop_dev_df.accuracy_1).iloc[ind])]\n",
    "    bad_example = ae_laptop_dev_df.iloc[sort_ind]\n",
    "    \n",
    "    display(bad_example)\n",
    "    print(*[' '.join(sent) for sent in bad_example.sentence],sep='\\n')\n",
    "    \n",
    "get_bad_examples(3)\n",
    "\n",
    "def get_good_examples(n = 1):\n",
    "    ind = np.argpartition(ae_laptop_dev_df.accuracy + ae_laptop_dev_df.accuracy_1,-n)[-n:]\n",
    "    print(ind)\n",
    "    sort_ind = ind[np.argsort((ae_laptop_dev_df.accuracy + ae_laptop_dev_df.accuracy_1).iloc[ind])]\n",
    "    good_example = ae_laptop_dev_df.iloc[sort_ind]\n",
    "    \n",
    "    display(good_example)\n",
    "    print(*[' '.join(sent) for sent in good_example.sentence],sep='\\n')\n",
    "# good_example = ae_laptop_dev_df.iloc[np.argmax(ae_laptop_dev_df.accuracy + ae_laptop_dev_df.accuracy_1)]\n",
    "get_good_examples(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with ASC baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>term</th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1113_0</th>\n",
       "      <td>negative</td>\n",
       "      <td>safe mode</td>\n",
       "      <td>1113_0</td>\n",
       "      <td>Not even safe mode boots.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595_0</th>\n",
       "      <td>positive</td>\n",
       "      <td>Keyboard</td>\n",
       "      <td>2595_0</td>\n",
       "      <td>Keyboard was also very nice and had a solid feel.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039_0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Keyboard</td>\n",
       "      <td>1039_0</td>\n",
       "      <td>Keyboard is plastic and spongey feeling.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315_0</th>\n",
       "      <td>positive</td>\n",
       "      <td>quality</td>\n",
       "      <td>315_0</td>\n",
       "      <td>I would recommend this laptop to anyone lookin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284_0</th>\n",
       "      <td>negative</td>\n",
       "      <td>screen</td>\n",
       "      <td>1284_0</td>\n",
       "      <td>Thus, when you carry it at a slanted angle, th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        polarity       term      id  \\\n",
       "1113_0  negative  safe mode  1113_0   \n",
       "2595_0  positive   Keyboard  2595_0   \n",
       "1039_0  negative   Keyboard  1039_0   \n",
       "315_0   positive    quality   315_0   \n",
       "1284_0  negative     screen  1284_0   \n",
       "\n",
       "                                                 sentence  \n",
       "1113_0                          Not even safe mode boots.  \n",
       "2595_0  Keyboard was also very nice and had a solid feel.  \n",
       "1039_0           Keyboard is plastic and spongey feeling.  \n",
       "315_0   I would recommend this laptop to anyone lookin...  \n",
       "1284_0  Thus, when you carry it at a slanted angle, th...  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asc_laptop_dev_df = pd.DataFrame.from_dict(asc_laptop_dev,orient='index')\n",
    "asc_laptop_dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not even safe mode boots.---------------------------------------- -0.3412 (negative)\n",
      "Keyboard was also very nice and had a solid feel.---------------- 0.5709 (positive)\n",
      "Keyboard is plastic and spongey feeling.------------------------- 0.128 (positive)\n",
      "I would recommend this laptop to anyone looking to get a new laptop who is willing to spend a little more money to get great quality! 0.784 (positive)\n",
      "Thus, when you carry it at a slanted angle, the screen will \"topple\" or \"slide\" down, if you understand what I mean. 0.0 (neutral)\n",
      "When I called Sony the Customer Service was Great.--------------- 0.6249 (positive)\n",
      "I also did not like the loud noises it made or how the bottom of the computer would get really hot. -0.2755 (negative)\n",
      "I also did not like the loud noises it made or how the bottom of the computer would get really hot. -0.2755 (negative)\n",
      "Also, one of the users mentioned how the edges on the macbook is sharp, if you have money to spend on one of the incase shells, it doesn't seem to be a problem. -0.4019 (negative)\n",
      "Also, one of the users mentioned how the edges on the macbook is sharp, if you have money to spend on one of the incase shells, it doesn't seem to be a problem. -0.4019 (negative)\n"
     ]
    }
   ],
   "source": [
    "def vader_asc(sentence_lst):\n",
    "    \"\"\"\n",
    "    For every sentence in the list, tag it as a positive/negative sentiment based on the sum of the words.\n",
    "    \"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    pos_neg_tag_lst = []\n",
    "    for ind,sentence in enumerate(sentence_lst):\n",
    "        vs = analyzer.polarity_scores(sentence)\n",
    "        pos_neg_tag = 'negative' if vs['compound'] <= -0.05 else 'positive' if vs['compound'] >= 0.05 else 'neutral' \n",
    "        # print first 10 examples\n",
    "        if ind <10: print(\"{:-<65} {} ({})\".format(sentence, str(vs['compound']),pos_neg_tag))\n",
    "        pos_neg_tag_lst.append(pos_neg_tag)\n",
    "    return(pos_neg_tag_lst)\n",
    "\n",
    "asc_laptop_dev_df['predictions'] = vader_asc(asc_laptop_dev_df.sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore ASC evaluation - accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>term</th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1113_0</th>\n",
       "      <td>negative</td>\n",
       "      <td>safe mode</td>\n",
       "      <td>1113_0</td>\n",
       "      <td>Not even safe mode boots.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595_0</th>\n",
       "      <td>positive</td>\n",
       "      <td>Keyboard</td>\n",
       "      <td>2595_0</td>\n",
       "      <td>Keyboard was also very nice and had a solid feel.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039_0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Keyboard</td>\n",
       "      <td>1039_0</td>\n",
       "      <td>Keyboard is plastic and spongey feeling.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315_0</th>\n",
       "      <td>positive</td>\n",
       "      <td>quality</td>\n",
       "      <td>315_0</td>\n",
       "      <td>I would recommend this laptop to anyone lookin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284_0</th>\n",
       "      <td>negative</td>\n",
       "      <td>screen</td>\n",
       "      <td>1284_0</td>\n",
       "      <td>Thus, when you carry it at a slanted angle, th...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        polarity       term      id  \\\n",
       "1113_0  negative  safe mode  1113_0   \n",
       "2595_0  positive   Keyboard  2595_0   \n",
       "1039_0  negative   Keyboard  1039_0   \n",
       "315_0   positive    quality   315_0   \n",
       "1284_0  negative     screen  1284_0   \n",
       "\n",
       "                                                 sentence predictions  \n",
       "1113_0                          Not even safe mode boots.    negative  \n",
       "2595_0  Keyboard was also very nice and had a solid feel.    positive  \n",
       "1039_0           Keyboard is plastic and spongey feeling.    positive  \n",
       "315_0   I would recommend this laptop to anyone lookin...    positive  \n",
       "1284_0  Thus, when you carry it at a slanted angle, th...     neutral  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True     0.613333\n",
       "False    0.386667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6133333333333333"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asc_laptop_dev_df.head()\n",
    "(asc_laptop_dev_df.polarity == asc_laptop_dev_df.predictions).value_counts(normalize=True)\n",
    "accuracy_score(asc_laptop_dev_df.polarity,asc_laptop_dev_df.predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore ASC evaluation - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40 14 12]\n",
      " [ 5 12 10]\n",
      " [ 7 10 40]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(asc_laptop_dev_df.polarity,asc_laptop_dev_df.predictions,labels=['negative','neutral','positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore ASC evaluation - Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.61      0.68        66\n",
      "     neutral       0.33      0.44      0.38        27\n",
      "    positive       0.65      0.70      0.67        57\n",
      "\n",
      "    accuracy                           0.61       150\n",
      "   macro avg       0.58      0.58      0.58       150\n",
      "weighted avg       0.64      0.61      0.62       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(asc_laptop_dev_df.polarity,asc_laptop_dev_df.predictions,labels=['negative','neutral','positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine ASC evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_asc_eval(y_true, y_pred):\n",
    "    print(confusion_matrix(y_true,y_pred,labels=['negative','neutral','positive']))\n",
    "    print(classification_report(y_true,asc_laptop_dev_df.predictions,labels=['negative','neutral','positive']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
