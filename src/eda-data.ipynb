{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data\n",
    "**Author:** Jane Hung  \n",
    "**Date:** 1 Mar 2020  \n",
    "**Citations:**  \n",
    "@inproceedings{xu_bert2019,\n",
    "    title = \"BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis\",\n",
    "    author = \"Xu, Hu and Liu, Bing and Shu, Lei and Yu, Philip S.\",\n",
    "    booktitle = \"Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics\",\n",
    "    year = \"2019\",\n",
    "}  \n",
    "https://drive.google.com/file/d/1NGH5bqzEx6aDlYJ7O3hepZF4i_p4iMR8/view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pprint\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import io\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "\n",
    "import pickle\n",
    "from csv import reader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.backend import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(filename):\n",
    "    f = open(filename,'r')\n",
    "    data = json.loads(f.read())\n",
    "    print('\\n',filename)\n",
    "    pprint.pprint(dict(list(data.items())[:1]))\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ../data/hu-data/ae/laptop/train.json\n",
      "{'0': {'label': ['B',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'B',\n",
      "                 'I',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O'],\n",
      "       'sentence': ['Keyboard',\n",
      "                    'is',\n",
      "                    'great',\n",
      "                    'but',\n",
      "                    'primary',\n",
      "                    'and',\n",
      "                    'secondary',\n",
      "                    'control',\n",
      "                    'buttons',\n",
      "                    'could',\n",
      "                    'be',\n",
      "                    'more',\n",
      "                    'durable',\n",
      "                    '.']}}\n",
      "\n",
      " ../data/hu-data/ae/rest/train.json\n",
      "{'0': {'label': ['O', 'O', 'O', 'B'],\n",
      "       'sentence': ['I', 'LOVE', 'their', 'Thai']}}\n",
      "\n",
      " ../data/hu-data/asc/laptop/train.json\n",
      "{'327_0': {'id': '327_0',\n",
      "           'polarity': 'positive',\n",
      "           'sentence': 'Also it is very good for college students who just '\n",
      "                       'need a reliable, easy to use computer.',\n",
      "           'term': 'use'}}\n",
      "\n",
      " ../data/hu-data/asc/rest/train.json\n",
      "{'1592_0': {'id': '1592_0',\n",
      "            'polarity': 'positive',\n",
      "            'sentence': 'Our server was very helpful and friendly.',\n",
      "            'term': 'server'}}\n"
     ]
    }
   ],
   "source": [
    "ae_laptop_train = read_json('../data/hu-data/ae/laptop/train.json')\n",
    "ae_rest_train = read_json('../data/hu-data/ae/rest/train.json')\n",
    "\n",
    "\n",
    "asc_laptop_train = read_json('../data/hu-data/asc/laptop/train.json')\n",
    "asc_rest_train = read_json('../data/hu-data/asc/rest/train.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ../data/hu-data/ae/laptop/dev.json\n",
      "{'0': {'label': ['O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O'],\n",
      "       'sentence': ['I',\n",
      "                    'have',\n",
      "                    'had',\n",
      "                    'this',\n",
      "                    'laptop',\n",
      "                    'for',\n",
      "                    'a',\n",
      "                    'few',\n",
      "                    'months',\n",
      "                    'now',\n",
      "                    'and',\n",
      "                    'i',\n",
      "                    'would',\n",
      "                    'say',\n",
      "                    'im',\n",
      "                    'pretty',\n",
      "                    'satisfied',\n",
      "                    '.']}}\n",
      "\n",
      " ../data/hu-data/ae/rest/dev.json\n",
      "{'0': {'label': ['O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'B',\n",
      "                 'I',\n",
      "                 'I',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O',\n",
      "                 'O'],\n",
      "       'sentence': ['In',\n",
      "                    'the',\n",
      "                    'summer',\n",
      "                    'months',\n",
      "                    ',',\n",
      "                    'the',\n",
      "                    'back',\n",
      "                    'garden',\n",
      "                    'area',\n",
      "                    'is',\n",
      "                    'really',\n",
      "                    'nice',\n",
      "                    '.']}}\n",
      "\n",
      " ../data/hu-data/asc/laptop/dev.json\n",
      "{'1113_0': {'id': '1113_0',\n",
      "            'polarity': 'negative',\n",
      "            'sentence': 'Not even safe mode boots.',\n",
      "            'term': 'safe mode'}}\n",
      "\n",
      " ../data/hu-data/asc/rest/dev.json\n",
      "{'2516_0': {'id': '2516_0',\n",
      "            'polarity': 'positive',\n",
      "            'sentence': \"This is the only Thai place I go too in NYC, it's \"\n",
      "                        'wonderful, and live relaxed Jazz on certain nights.',\n",
      "            'term': 'Jazz'}}\n"
     ]
    }
   ],
   "source": [
    "ae_laptop_dev  = read_json('../data/hu-data/ae/laptop/dev.json')\n",
    "ae_rest_dev = read_json('../data/hu-data/ae/rest/dev.json')\n",
    "\n",
    "\n",
    "asc_laptop_dev = read_json('../data/hu-data/asc/laptop/dev.json')\n",
    "asc_rest_dev = read_json('../data/hu-data/asc/rest/dev.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: How do we get from the ASC data back to the AE data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'polarity': 'positive',\n",
       " 'term': 'use',\n",
       " 'id': '327_0',\n",
       " 'sentence': 'Also it is very good for college students who just need a reliable, easy to use computer.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'label': ['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O'],\n",
       " 'sentence': ['If',\n",
       "  'you',\n",
       "  'could',\n",
       "  'stretch',\n",
       "  'by',\n",
       "  'a',\n",
       "  'few',\n",
       "  '100',\n",
       "  'dollars',\n",
       "  'I',\n",
       "  'highly',\n",
       "  'recommend',\n",
       "  'you',\n",
       "  'should',\n",
       "  'replace',\n",
       "  'your',\n",
       "  'Windows',\n",
       "  'laptop',\n",
       "  'with',\n",
       "  'this',\n",
       "  'one',\n",
       "  '.']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asc_laptop_train['327_0']\n",
    "ae_laptop_train['400']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Also',\n",
       " 'it',\n",
       " 'is',\n",
       " 'very',\n",
       " 'good',\n",
       " 'for',\n",
       " 'college',\n",
       " 'students',\n",
       " 'who',\n",
       " 'just',\n",
       " 'need',\n",
       " 'a',\n",
       " 'reliable',\n",
       " ',',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'use',\n",
       " 'computer',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(asc_laptop_train['327_0']['sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with AE baseline - NN+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Keyboard', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('great', 'ADJ'),\n",
       " ('but', 'CONJ'),\n",
       " ('primary', 'ADJ'),\n",
       " ('and', 'CONJ'),\n",
       " ('secondary', 'ADJ'),\n",
       " ('control', 'NOUN'),\n",
       " ('buttons', 'NOUN'),\n",
       " ('could', 'VERB'),\n",
       " ('be', 'VERB'),\n",
       " ('more', 'ADV'),\n",
       " ('durable', 'ADJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag with universal POS. Especially for nouns\n",
    "nltk.pos_tag(ae_laptop_train['0']['sentence'],tagset='universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[I, have, had, this, laptop, for, a, few, mont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...</td>\n",
       "      <td>[Additional, caveat, :, the, base, installatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...</td>\n",
       "      <td>[it, is, of, high, quality, ,, has, a, killer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[O, B, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[The, screen, gets, smeary, and, dusty, very, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[I, previously, owned, an, HP, desktop, and, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>[O, O, O, O, O]</td>\n",
       "      <td>[The, benefits, were, immediate, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[All-, in-, all, ,, I, would, definitely, reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>[O, O, O, O, O]</td>\n",
       "      <td>[just, chill, and, enjoy, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[My, son, and, his, family, have, a, hard, tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[This, is, what, they, told, me, :, It, heats,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 label  \\\n",
       "0    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1    [O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...   \n",
       "2    [O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...   \n",
       "3           [O, B, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                    [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "..                                                 ...   \n",
       "145                                    [O, O, O, O, O]   \n",
       "146         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "147                                    [O, O, O, O, O]   \n",
       "148  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "149  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                              sentence  \n",
       "0    [I, have, had, this, laptop, for, a, few, mont...  \n",
       "1    [Additional, caveat, :, the, base, installatio...  \n",
       "2    [it, is, of, high, quality, ,, has, a, killer,...  \n",
       "3    [The, screen, gets, smeary, and, dusty, very, ...  \n",
       "4    [I, previously, owned, an, HP, desktop, and, a...  \n",
       "..                                                 ...  \n",
       "145                [The, benefits, were, immediate, !]  \n",
       "146  [All-, in-, all, ,, I, would, definitely, reco...  \n",
       "147                       [just, chill, and, enjoy, .]  \n",
       "148  [My, son, and, his, family, have, a, hard, tim...  \n",
       "149  [This, is, what, they, told, me, :, It, heats,...  \n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_laptop_dev_df = pd.DataFrame.from_dict(ae_laptop_dev,orient='index')\n",
    "ae_laptop_dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[I, have, had, this, laptop, for, a, few, mont...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, B, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...</td>\n",
       "      <td>[Additional, caveat, :, the, base, installatio...</td>\n",
       "      <td>[O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...</td>\n",
       "      <td>[it, is, of, high, quality, ,, has, a, killer,...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, B, I, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[O, B, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[The, screen, gets, smeary, and, dusty, very, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[I, previously, owned, an, HP, desktop, and, a...</td>\n",
       "      <td>[O, O, O, O, B, I, O, O, B, I, O]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               label  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1  [O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...   \n",
       "2  [O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...   \n",
       "3         [O, B, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                  [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [I, have, had, this, laptop, for, a, few, mont...   \n",
       "1  [Additional, caveat, :, the, base, installatio...   \n",
       "2  [it, is, of, high, quality, ,, has, a, killer,...   \n",
       "3  [The, screen, gets, smeary, and, dusty, very, ...   \n",
       "4  [I, previously, owned, an, HP, desktop, and, a...   \n",
       "\n",
       "                                         predictions  \n",
       "0  [O, O, O, O, B, O, O, O, B, O, O, O, O, O, O, ...  \n",
       "1  [O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...  \n",
       "2  [O, O, O, O, B, O, O, O, B, I, O, O, O, O, O, ...  \n",
       "3         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
       "4                  [O, O, O, O, B, I, O, O, B, I, O]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0      [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...\n",
       "1      [0, 1, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, ...\n",
       "2      [0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, ...\n",
       "3             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       "4                      [0, 0, 0, 0, 1, 2, 0, 0, 1, 2, 0]\n",
       "                             ...                        \n",
       "145                                      [0, 1, 0, 0, 0]\n",
       "146           [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
       "147                                      [0, 1, 0, 1, 0]\n",
       "148    [0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, ...\n",
       "149    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Name: predictions, Length: 150, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pos_ae(tokenized_sentence):\n",
    "    \"\"\"\n",
    "    Tag sentences using POS tagger\n",
    "    \"\"\"\n",
    "    pos_sent = tokenized_sentence.apply(lambda sent:nltk.pos_tag(sent,tagset='universal'))\n",
    "    \n",
    "    \n",
    "    # tag with IOB terminology\n",
    "    ae_tag = lambda sent:['O' if token[1] != 'NOUN' \n",
    "                          else 'B' if ((token[1]=='NOUN') & (sent[ind-1][1]!='NOUN')) \n",
    "                          else 'I' for ind,token in enumerate(sent)]\n",
    "\n",
    "    return(pos_sent.apply(ae_tag))\n",
    "\n",
    "# since the POS tagger is based on the words themselves and not context.\n",
    "ae_laptop_dev_df['predictions'] = pos_ae(ae_laptop_dev_df['sentence'])\n",
    "ae_laptop_dev_df.head()\n",
    "\n",
    "def convert_int(tagged_tokens):\n",
    "    \"\"\"\n",
    "    Convert B,I,O tags to integers\n",
    "    \"\"\"\n",
    "    return(tagged_tokens.apply(lambda sent: [0 if token=='O' else 1 if token=='B' else 2 for token in sent]))\n",
    "\n",
    "convert_int(ae_laptop_dev_df['predictions'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore AE Regex Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Toshiba',\n",
       " 'is',\n",
       " 'aware',\n",
       " 'of',\n",
       " 'the',\n",
       " 'issue',\n",
       " 'but',\n",
       " 'unless',\n",
       " 'the',\n",
       " 'extended',\n",
       " 'warrenty',\n",
       " 'is',\n",
       " 'bought',\n",
       " 'Toshiba',\n",
       " 'will',\n",
       " 'do',\n",
       " 'nothing',\n",
       " 'about',\n",
       " 'it',\n",
       " '.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['B',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cover', 'for', 'the', 'DVD', 'drive']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['B', 'I', 'I', 'I', 'I']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>predictions</th>\n",
       "      <th>predictions_1</th>\n",
       "      <th>iob_gold_tree</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[I, have, had, this, laptop, for, a, few, mont...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, B, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[(I, PRP, O), (have, VBP, O), (had, VBN, O), (...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...</td>\n",
       "      <td>[Additional, caveat, :, the, base, installatio...</td>\n",
       "      <td>[O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B, O, O, O, O, O, ...</td>\n",
       "      <td>[(Additional, JJ, O), (caveat, NN, O), (:, :, ...</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...</td>\n",
       "      <td>[it, is, of, high, quality, ,, has, a, killer,...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, B, I, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B, O, O, O, O, O, ...</td>\n",
       "      <td>[(it, PRP, O), (is, VBZ, O), (of, IN, O), (hig...</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[O, B, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[The, screen, gets, smeary, and, dusty, very, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[(The, DT, O), (screen, JJ, B-NP), (gets, VBZ,...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[I, previously, owned, an, HP, desktop, and, a...</td>\n",
       "      <td>[O, O, O, O, B, I, O, O, B, I, O]</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, B, O, O]</td>\n",
       "      <td>[(I, PRP, O), (previously, RB, O), (owned, VBD...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               label  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1  [O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...   \n",
       "2  [O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...   \n",
       "3         [O, B, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                  [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [I, have, had, this, laptop, for, a, few, mont...   \n",
       "1  [Additional, caveat, :, the, base, installatio...   \n",
       "2  [it, is, of, high, quality, ,, has, a, killer,...   \n",
       "3  [The, screen, gets, smeary, and, dusty, very, ...   \n",
       "4  [I, previously, owned, an, HP, desktop, and, a...   \n",
       "\n",
       "                                         predictions  \\\n",
       "0  [O, O, O, O, B, O, O, O, B, O, O, O, O, O, O, ...   \n",
       "1  [O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...   \n",
       "2  [O, O, O, O, B, O, O, O, B, I, O, O, O, O, O, ...   \n",
       "3         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                  [O, O, O, O, B, I, O, O, B, I, O]   \n",
       "\n",
       "                                       predictions_1  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1  [O, O, O, O, O, O, O, O, O, B, O, O, O, O, O, ...   \n",
       "2  [O, O, O, O, O, O, O, O, O, B, O, O, O, O, O, ...   \n",
       "3         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                  [O, O, O, O, B, O, O, O, B, O, O]   \n",
       "\n",
       "                                       iob_gold_tree  accuracy  accuracy_1  \n",
       "0  [(I, PRP, O), (have, VBP, O), (had, VBN, O), (...  0.888889    0.888889  \n",
       "1  [(Additional, JJ, O), (caveat, NN, O), (:, :, ...  0.840000    0.560000  \n",
       "2  [(it, PRP, O), (is, VBZ, O), (of, IN, O), (hig...  0.894737    0.842105  \n",
       "3  [(The, DT, O), (screen, JJ, B-NP), (gets, VBZ,...  0.928571    0.928571  \n",
       "4  [(I, PRP, O), (previously, RB, O), (owned, VBD...  0.636364    0.636364  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try a more sophisticated method for chunking\n",
    "def regex_parser(tokenized_sentence):\n",
    "    \"\"\"\n",
    "    Use a Regex Parser to provide some context around noun phrases\n",
    "    \"\"\"\n",
    "    pos_sent = nltk.pos_tag(tokenized_sentence)\n",
    "#     print(pos_sent)\n",
    "#     grammar = r\"\"\"\n",
    "#       NP: {<DT|PP\\$>?<JJ>*<NN>}   # chunk determiner/possessive, adjectives and noun\n",
    "#           {<NNP>+}                # chunk sequences of proper nouns\n",
    "#     \"\"\"\n",
    "    \n",
    "    # Update Grammar Regex to include prepositional phrases ala Semeval annotation guidelines\n",
    "    grammar = r\"\"\"\n",
    "    NP: {<NN><IN><DT><NN|NNP>+}\n",
    "        {<NNP>+}\n",
    "    \"\"\"\n",
    "    \n",
    "    cp = nltk.RegexpParser(grammar)\n",
    "\n",
    "    tree = cp.parse(pos_sent)\n",
    "    \n",
    "    iob = [el[2][0] for el in nltk.chunk.util.tree2conlltags(tree)]\n",
    "    return(iob)\n",
    "\n",
    "# print example\n",
    "ae_laptop_train['15']['sentence']\n",
    "regex_parser(ae_laptop_train['15']['sentence'])\n",
    "\n",
    "print(['cover','for','the','DVD','drive'])\n",
    "regex_parser(['cover','for','the','DVD','drive'])\n",
    "\n",
    "# since the POS tagger is based on the words themselves and not context.\n",
    "ae_laptop_dev_df['predictions_1'] = ae_laptop_dev_df['sentence'].apply(lambda x: regex_parser(x))\n",
    "ae_laptop_dev_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore AE evaluation - CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.837730665815654"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only using 0,1 because there aren't many very large token phrases\n",
    "log_loss(convert_int(pd.DataFrame(ae_laptop_dev_df.iloc[0]['label'])),convert_int(pd.DataFrame(ae_laptop_dev_df.iloc[0]['predictions'])),labels=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore AE evaluation - SemEval14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO need to explore how we want to move forward with all sentences rather than just 1.\n",
    "# Should try to implement the SemEval14 evaluation criteria bc this is best practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore AE evaluation - ChunkScore\n",
    "https://stackoverflow.com/questions/17325554/difference-between-iob-accuracy-and-precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      "(S\n",
      "  (NP Toshiba/NNP)\n",
      "  is/VBZ\n",
      "  aware/JJ\n",
      "  of/IN\n",
      "  (NP the/DT issue/NN)\n",
      "  but/CC\n",
      "  unless/IN\n",
      "  (NP the/DT extended/JJ warrenty/NN)\n",
      "  is/VBZ\n",
      "  bought/VBN\n",
      "  (NP Toshiba/NNP)\n",
      "  will/MD\n",
      "  do/VB\n",
      "  (NP nothing/NN)\n",
      "  about/IN\n",
      "  it/PRP\n",
      "  ./.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Toshiba', 'NNP', 'B-NP'),\n",
       " ('is', 'VBZ', 'O'),\n",
       " ('aware', 'JJ', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('the', 'DT', 'B-NP'),\n",
       " ('issue', 'NN', 'I-NP'),\n",
       " ('but', 'CC', 'O'),\n",
       " ('unless', 'IN', 'O'),\n",
       " ('the', 'DT', 'B-NP'),\n",
       " ('extended', 'JJ', 'I-NP'),\n",
       " ('warrenty', 'NN', 'I-NP'),\n",
       " ('is', 'VBZ', 'O'),\n",
       " ('bought', 'VBN', 'O'),\n",
       " ('Toshiba', 'NNP', 'B-NP'),\n",
       " ('will', 'MD', 'O'),\n",
       " ('do', 'VB', 'O'),\n",
       " ('nothing', 'NN', 'B-NP'),\n",
       " ('about', 'IN', 'O'),\n",
       " ('it', 'PRP', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['B',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B',\n",
       " 'I',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B',\n",
       " 'I',\n",
       " 'I',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gold Standard:\n",
      "(S\n",
      "  Toshiba/NNP\n",
      "  is/VBZ\n",
      "  aware/JJ\n",
      "  of/IN\n",
      "  the/DT\n",
      "  issue/NN\n",
      "  but/CC\n",
      "  unless/IN\n",
      "  the/DT\n",
      "  (NP extended/JJ warrenty/NN)\n",
      "  is/VBZ\n",
      "  bought/VBN\n",
      "  Toshiba/NNP\n",
      "  will/MD\n",
      "  do/VB\n",
      "  nothing/NN\n",
      "  about/IN\n",
      "  it/PRP\n",
      "  ./.)\n",
      "ChunkParse score:\n",
      "    IOB Accuracy:  60.0%%\n",
      "    Precision:      0.0%%\n",
      "    Recall:         0.0%%\n",
      "    F-Measure:      0.0%%\n"
     ]
    }
   ],
   "source": [
    "# TODO get ChunkScore to work\n",
    "tokenized_sentence = ae_laptop_train['15']['sentence']\n",
    "pos_sent = nltk.pos_tag(tokenized_sentence)\n",
    "\n",
    "##\n",
    "grammar = r\"\"\"\n",
    "  NP: {<DT|PP\\$>?<JJ>*<NN>}   # chunk determiner/possessive, adjectives and noun\n",
    "      {<NNP>+}                # chunk sequences of proper nouns\n",
    "\"\"\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "\n",
    "tree = cp.parse(pos_sent)\n",
    "\n",
    "iob = [el[2][0] for el in nltk.chunk.util.tree2conlltags(tree)]\n",
    "\n",
    "print('Prediction:')\n",
    "print(tree)\n",
    "nltk.chunk.util.tree2conlltags(tree)\n",
    "regex_parser(ae_laptop_train['15']['sentence'])\n",
    "##\n",
    "\n",
    "gold_tree = pos_sent\n",
    "print('\\nGold Standard:')\n",
    "# create the tree with IOB input\n",
    "iob_gold_tree = nltk.Tree('S',[(el[0], el[1], ae_laptop_train['15']['label'][ind]) if ae_laptop_train['15']['label'][ind]=='O' \n",
    "                               else (el[0], el[1], ae_laptop_train['15']['label'][ind] + '-NP')for ind,el in enumerate(gold_tree)])\n",
    "print(nltk.chunk.util.conlltags2tree(iob_gold_tree))\n",
    "# print(nltk.chunk.util.conlltags2tree([(el[0], el[1], ae_laptop_train['15']['label'][ind])for ind,el in enumerate(gold_tree)]))\n",
    "# print(nltk.chunk.util.conlltags2tree())\n",
    "print(cp.evaluate([iob_gold_tree]))\n",
    "\n",
    "# nltk.chunk.util.tagstr2tree(' '.join(tokenized_sentence), chunk_label='NP', root_label='S', sep='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gold Standard:\n",
      "0      [(I, PRP), (have, VBP), (had, VBN), (this, DT)...\n",
      "1      [(Additional, JJ), (caveat, NN), (:, :), (the,...\n",
      "2      [(it, PRP), (is, VBZ), (of, IN), (high, JJ), (...\n",
      "3      [(The, DT), (screen, JJ), (gets, VBZ), (smeary...\n",
      "4      [(I, PRP), (previously, RB), (owned, VBD), (an...\n",
      "                             ...                        \n",
      "145    [(The, DT), (benefits, NNS), (were, VBD), (imm...\n",
      "146    [(All-, JJ), (in-, JJ), (all, DT), (,, ,), (I,...\n",
      "147    [(just, RB), (chill, NN), (and, CC), (enjoy, N...\n",
      "148    [(My, PRP$), (son, NN), (and, CC), (his, PRP$)...\n",
      "149    [(This, DT), (is, VBZ), (what, WP), (they, PRP...\n",
      "Name: sentence, Length: 150, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>predictions</th>\n",
       "      <th>predictions_1</th>\n",
       "      <th>iob_gold_tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[I, have, had, this, laptop, for, a, few, mont...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, B, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, B, I, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[(I, PRP, O), (have, VBP, O), (had, VBN, O), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...</td>\n",
       "      <td>[Additional, caveat, :, the, base, installatio...</td>\n",
       "      <td>[O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...</td>\n",
       "      <td>[B, I, O, B, I, B, O, O, O, B, O, B, I, O, O, ...</td>\n",
       "      <td>[(Additional, JJ, O), (caveat, NN, O), (:, :, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...</td>\n",
       "      <td>[it, is, of, high, quality, ,, has, a, killer,...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, B, I, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, B, I, O, O, B, I, B, O, O, O, O, O, ...</td>\n",
       "      <td>[(it, PRP, O), (is, VBZ, O), (of, IN, O), (hig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[O, B, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[The, screen, gets, smeary, and, dusty, very, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[(The, DT, O), (screen, JJ, B-NP), (gets, VBZ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[I, previously, owned, an, HP, desktop, and, a...</td>\n",
       "      <td>[O, O, O, O, B, I, O, O, B, I, O]</td>\n",
       "      <td>[O, O, O, O, B, B, O, O, B, B, O]</td>\n",
       "      <td>[(I, PRP, O), (previously, RB, O), (owned, VBD...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               label  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1  [O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...   \n",
       "2  [O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...   \n",
       "3         [O, B, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                  [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [I, have, had, this, laptop, for, a, few, mont...   \n",
       "1  [Additional, caveat, :, the, base, installatio...   \n",
       "2  [it, is, of, high, quality, ,, has, a, killer,...   \n",
       "3  [The, screen, gets, smeary, and, dusty, very, ...   \n",
       "4  [I, previously, owned, an, HP, desktop, and, a...   \n",
       "\n",
       "                                         predictions  \\\n",
       "0  [O, O, O, O, B, O, O, O, B, O, O, O, O, O, O, ...   \n",
       "1  [O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...   \n",
       "2  [O, O, O, O, B, O, O, O, B, I, O, O, O, O, O, ...   \n",
       "3         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                  [O, O, O, O, B, I, O, O, B, I, O]   \n",
       "\n",
       "                                       predictions_1  \\\n",
       "0  [O, O, O, B, I, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1  [B, I, O, B, I, B, O, O, O, B, O, B, I, O, O, ...   \n",
       "2  [O, O, O, B, I, O, O, B, I, B, O, O, O, O, O, ...   \n",
       "3         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                  [O, O, O, O, B, B, O, O, B, B, O]   \n",
       "\n",
       "                                       iob_gold_tree  \n",
       "0  [(I, PRP, O), (have, VBP, O), (had, VBN, O), (...  \n",
       "1  [(Additional, JJ, O), (caveat, NN, O), (:, :, ...  \n",
       "2  [(it, PRP, O), (is, VBZ, O), (of, IN, O), (hig...  \n",
       "3  [(The, DT, O), (screen, JJ, B-NP), (gets, VBZ,...  \n",
       "4  [(I, PRP, O), (previously, RB, O), (owned, VBD...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  74.3%%\n",
      "    Precision:      0.0%%\n",
      "    Recall:         0.0%%\n",
      "    F-Measure:      0.0%%\n"
     ]
    }
   ],
   "source": [
    "# TODO get ChunkScore to work on all dev\n",
    "##\n",
    "grammar = r\"\"\"\n",
    "  NP: {<DT|PP\\$>?<JJ>*<NN>}   # chunk determiner/possessive, adjectives and noun\n",
    "      {<NNP>+}                # chunk sequences of proper nouns\n",
    "\"\"\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "\n",
    "# tree = cp.parse(pos_sent)\n",
    "\n",
    "# iob = [el[2][0] for el in nltk.chunk.util.tree2conlltags(tree)]\n",
    "\n",
    "# print('Prediction:')\n",
    "# print(tree)\n",
    "# nltk.chunk.util.tree2conlltags(tree)\n",
    "# regex_parser(ae_laptop_train['15']['sentence'])\n",
    "##\n",
    "\n",
    "\n",
    "\n",
    "print('\\nGold Standard:')\n",
    "# tag every sentence with the pos\n",
    "gold_tree = ae_laptop_dev_df['sentence'].apply(lambda x: nltk.pos_tag(x))\n",
    "print(gold_tree)\n",
    "# create the tree with IOB input\n",
    "# for tree_ind, tree in enumerate(gold_tree):\n",
    "#     print(nltk.Tree('S',[\n",
    "#         (el[0], el[1], ae_laptop_dev_df.iloc[tree_ind]['label'][ind]) if ae_laptop_dev_df.iloc[tree_ind]['label'][ind]=='O' \n",
    "#         else (el[0], el[1], ae_laptop_dev_df.iloc[tree_ind]['label'][ind] + '-NP')for ind,el in enumerate(tree)]))\n",
    "# iob_gold_tree = [nltk.Tree('S',[(el[0], el[1], ae_laptop_dev_df.iloc[tree_ind,'label'][ind]) if ae_laptop_dev_df.iloc[tree_ind,'label'][ind]=='O' \n",
    "#                                else (el[0], el[1], ae_laptop_dev_df.iloc[tree_ind,'label'][ind] + '-NP')for ind,el in enumerate(tree)]) for tree_ind,tree in enumerate(gold_tree)]\n",
    "\n",
    "iob_gold_tree = [nltk.Tree('S',\n",
    "                           [(el[0], el[1], ae_laptop_dev_df.iloc[tree_ind]['label'][ind])\n",
    "                            if ae_laptop_dev_df.iloc[tree_ind]['label'][ind]=='O'\n",
    "                            else (el[0], el[1], ae_laptop_dev_df.iloc[tree_ind]['label'][ind] + '-NP')\n",
    "                            for ind,el in enumerate(tree)])\n",
    "                for tree_ind, tree in enumerate(gold_tree)]\n",
    "ae_laptop_dev_df['iob_gold_tree'] = iob_gold_tree\n",
    "ae_laptop_dev_df.head()\n",
    "# print(iob_gold_tree)\n",
    "\n",
    "# print(nltk.chunk.util.conlltags2tree(iob_gold_tree[5]))\n",
    "print(cp.evaluate(iob_gold_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-4bdd9ab689e8>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-4bdd9ab689e8>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    chunkscore.\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "chunkscore = nltk.chunk.util.ChunkScore()\n",
    "chunkscore.score(ae_laptop_dev_df['iob_gold_tree'], ae_laptop_dev_df['predictions'])\n",
    "chunkscore._updateMeasures()\n",
    "\n",
    "# Our rule-based chunker says these are chunks.\n",
    "chunkscore.guessed()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore AE evaluation - Token Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>predictions</th>\n",
       "      <th>predictions_1</th>\n",
       "      <th>iob_gold_tree</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[I, have, had, this, laptop, for, a, few, mont...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, B, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[(I, PRP, O), (have, VBP, O), (had, VBN, O), (...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...</td>\n",
       "      <td>[Additional, caveat, :, the, base, installatio...</td>\n",
       "      <td>[O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B, O, O, O, O, O, ...</td>\n",
       "      <td>[(Additional, JJ, O), (caveat, NN, O), (:, :, ...</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...</td>\n",
       "      <td>[it, is, of, high, quality, ,, has, a, killer,...</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, B, I, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B, O, O, O, O, O, ...</td>\n",
       "      <td>[(it, PRP, O), (is, VBZ, O), (of, IN, O), (hig...</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[O, B, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[The, screen, gets, smeary, and, dusty, very, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[(The, DT, O), (screen, JJ, B-NP), (gets, VBZ,...</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[I, previously, owned, an, HP, desktop, and, a...</td>\n",
       "      <td>[O, O, O, O, B, I, O, O, B, I, O]</td>\n",
       "      <td>[O, O, O, O, B, O, O, O, B, O, O]</td>\n",
       "      <td>[(I, PRP, O), (previously, RB, O), (owned, VBD...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               label  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1  [O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...   \n",
       "2  [O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...   \n",
       "3         [O, B, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                  [O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  [I, have, had, this, laptop, for, a, few, mont...   \n",
       "1  [Additional, caveat, :, the, base, installatio...   \n",
       "2  [it, is, of, high, quality, ,, has, a, killer,...   \n",
       "3  [The, screen, gets, smeary, and, dusty, very, ...   \n",
       "4  [I, previously, owned, an, HP, desktop, and, a...   \n",
       "\n",
       "                                         predictions  \\\n",
       "0  [O, O, O, O, B, O, O, O, B, O, O, O, O, O, O, ...   \n",
       "1  [O, B, O, O, B, I, O, O, O, B, O, O, B, O, O, ...   \n",
       "2  [O, O, O, O, B, O, O, O, B, I, O, O, O, O, O, ...   \n",
       "3         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                  [O, O, O, O, B, I, O, O, B, I, O]   \n",
       "\n",
       "                                       predictions_1  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1  [O, O, O, O, O, O, O, O, O, B, O, O, O, O, O, ...   \n",
       "2  [O, O, O, O, O, O, O, O, O, B, O, O, O, O, O, ...   \n",
       "3         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "4                  [O, O, O, O, B, O, O, O, B, O, O]   \n",
       "\n",
       "                                       iob_gold_tree  accuracy  accuracy_1  \n",
       "0  [(I, PRP, O), (have, VBP, O), (had, VBN, O), (...  0.888889    1.000000  \n",
       "1  [(Additional, JJ, O), (caveat, NN, O), (:, :, ...  0.840000    0.840000  \n",
       "2  [(it, PRP, O), (is, VBZ, O), (of, IN, O), (hig...  0.894737    0.921053  \n",
       "3  [(The, DT, O), (screen, JJ, B-NP), (gets, VBZ,...  0.928571    0.928571  \n",
       "4  [(I, PRP, O), (previously, RB, O), (owned, VBD...  0.636364    0.818182  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.845546</td>\n",
       "      <td>0.884802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.094523</td>\n",
       "      <td>0.111703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         accuracy  accuracy_1\n",
       "count  150.000000  150.000000\n",
       "mean     0.845546    0.884802\n",
       "std      0.094523    0.111703\n",
       "min      0.571429    0.555556\n",
       "25%      0.777778    0.818182\n",
       "50%      0.846154    0.909091\n",
       "75%      0.909091    1.000000\n",
       "max      1.000000    1.000000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_accuracy(true,predictions):\n",
    "    accuracy = []\n",
    "    for true_el, predict_el in zip(true,predictions):\n",
    "        accuracy.append((np.array(predict_el) == np.array(true_el)).sum() / (len(true_el)))\n",
    "    return(accuracy)\n",
    "\n",
    "ae_laptop_dev_df['accuracy'] = get_accuracy(ae_laptop_dev_df.label,ae_laptop_dev_df.predictions)\n",
    "ae_laptop_dev_df['accuracy_1'] = get_accuracy(ae_laptop_dev_df.label,ae_laptop_dev_df.predictions_1)\n",
    "ae_laptop_dev_df.head()\n",
    "ae_laptop_dev_df[['accuracy','accuracy_1']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export samples that are well / poorly extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                               [O, B, I, I, I, O, O, O, O, O]\n",
       "sentence         [The, resolution, on, the, screen, is, almost,...\n",
       "predictions                         [O, B, O, O, B, O, O, O, B, O]\n",
       "predictions_1                       [B, I, O, B, I, O, O, O, B, O]\n",
       "iob_gold_tree    [(The, DT, O), (resolution, NN, B-NP), (on, IN...\n",
       "accuracy                                                       0.6\n",
       "accuracy_1                                                     0.5\n",
       "Name: 8, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'The resolution on the screen is almost pure HD .'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'I got what I paid for .'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_example = ae_laptop_dev_df.iloc[np.argmin(ae_laptop_dev_df.accuracy + ae_laptop_dev_df.accuracy_1)]\n",
    "bad_example\n",
    "' '.join(bad_example.sentence)\n",
    "good_example = ae_laptop_dev_df.iloc[np.argmax(ae_laptop_dev_df.accuracy + ae_laptop_dev_df.accuracy_1)]\n",
    "' '.join(good_example.sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with ASC baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asc_laptop_dev_df = pd.DataFrame.from_dict(asc_laptop_dev,orient='index')\n",
    "asc_laptop_dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "pos_neg_tag_lst = []\n",
    "for ind,sentence in enumerate(asc_laptop_dev_df.sentence):\n",
    "    vs = analyzer.polarity_scores(sentence)\n",
    "    pos_neg_tag = 'negative' if vs['compound'] <= -0.05 else 'positive' if vs['compound'] >= 0.05 else 'neutral' \n",
    "    if ind <10: print(\"{:-<65} {} ({})\".format(sentence, str(vs['compound']),pos_neg_tag))\n",
    "    pos_neg_tag_lst.append(pos_neg_tag)\n",
    "asc_laptop_dev_df['predictions'] = pos_neg_tag_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore ASC evaluation - accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asc_laptop_dev_df.head()\n",
    "(asc_laptop_dev_df.polarity == asc_laptop_dev_df.predictions).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(asc_laptop_dev_df.polarity,asc_laptop_dev_df.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
