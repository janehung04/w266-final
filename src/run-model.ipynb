{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "run-model.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a35855c7b19c4bbda0e75eac4ee79135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_141028fbb0bd46f1b872362e6ba31cff",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ec5320a3c9284ef197d8beda2a4d2282",
              "IPY_MODEL_e6fd3f1f25c647a3a971448d8d1ffe38"
            ]
          }
        },
        "141028fbb0bd46f1b872362e6ba31cff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec5320a3c9284ef197d8beda2a4d2282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_19755be40d454987a08cd7c22cdf4617",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f732c2914976420986d1550b894273a6"
          }
        },
        "e6fd3f1f25c647a3a971448d8d1ffe38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1c3367d1e13d488db50952799dbd16f5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.08MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f27214776f3e4c0db147ad5b36dd4d14"
          }
        },
        "19755be40d454987a08cd7c22cdf4617": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f732c2914976420986d1550b894273a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c3367d1e13d488db50952799dbd16f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f27214776f3e4c0db147ad5b36dd4d14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b11e7e2fb006449ea8a4777e5d65f3de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cee9adc149944d1b9a7c0c5c77fa63ed",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_924ad2867cfb4141b9c623d8b2a1730c",
              "IPY_MODEL_d34346618fe648fc81729e5ecd6613c4"
            ]
          }
        },
        "cee9adc149944d1b9a7c0c5c77fa63ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "924ad2867cfb4141b9c623d8b2a1730c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5d47e578180e467fa1b5514cb42d7da1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53b27ac21cd14611bf07704ae13783d9"
          }
        },
        "d34346618fe648fc81729e5ecd6613c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_55e6ef319c1242d79ef972e415e5932f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 141B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b142987d92e4393a580da4e0972195a"
          }
        },
        "5d47e578180e467fa1b5514cb42d7da1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53b27ac21cd14611bf07704ae13783d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55e6ef319c1242d79ef972e415e5932f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b142987d92e4393a580da4e0972195a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62190c66b70d42da92492402e1b8d69f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8eb1e2a6bafc4085ba34b06c3e446b0f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1929f2e62c084b218a5e5ae845541717",
              "IPY_MODEL_0ae8fb4122de46dc8d7c96050dff0114"
            ]
          }
        },
        "8eb1e2a6bafc4085ba34b06c3e446b0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1929f2e62c084b218a5e5ae845541717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b665757b4b1d478683168fa77e28cc1f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a0b5c0933fbc453b80d613da69797304"
          }
        },
        "0ae8fb4122de46dc8d7c96050dff0114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e5e9766a8bff49cb9e993e65f3c3b7e8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 5.18MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_482a7c439f224dfcaea2cd1fb328918a"
          }
        },
        "b665757b4b1d478683168fa77e28cc1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a0b5c0933fbc453b80d613da69797304": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5e9766a8bff49cb9e993e65f3c3b7e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "482a7c439f224dfcaea2cd1fb328918a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir-egNirWntl"
      },
      "source": [
        "# Explore Data\n",
        "**Author:** Jane Hung  \n",
        "**Date:** 1 Mar 2020  \n",
        "**Citations:**  \n",
        "@inproceedings{xu_bert2019,\n",
        "    title = \"BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis\",\n",
        "    author = \"Xu, Hu and Liu, Bing and Shu, Lei and Yu, Philip S.\",\n",
        "    booktitle = \"Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics\",\n",
        "    year = \"2019\",\n",
        "}  \n",
        "https://drive.google.com/file/d/1NGH5bqzEx6aDlYJ7O3hepZF4i_p4iMR8/view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF3S4i1hWnts"
      },
      "source": [
        "## Initialize environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR-0mzoMYTB_",
        "outputId": "a3a48e7f-aa53-449b-bfc7-a68d2b363786"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install vaderSentiment"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.44)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.7/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOD9GsI-Wntt"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import pprint\n",
        "import tensorflow as tf\n",
        "from time import time\n",
        "import io\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "\n",
        "import pickle\n",
        "from csv import reader\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.backend import sparse_categorical_crossentropy, int_shape\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from transformers import BertTokenizer, TFBertModel,TFBertForSequenceClassification\n",
        "\n",
        "from collections import Counter\n",
        "import random\n",
        "\n",
        "from sklearn.metrics import log_loss, confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5fbW8zxQaGB",
        "outputId": "1b98a4d8-cd1c-4140-af3d-32f2874a642a"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26ebrcS5Wntu"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1OLUMwXWntu"
      },
      "source": [
        "def read_json(filename):\n",
        "    f = open(filename,'r')\n",
        "    data = json.loads(f.read())\n",
        "    print('\\n',filename)\n",
        "    pprint.pprint(dict(list(data.items())[:1]))\n",
        "    return(data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZKxgHfEWntv"
      },
      "source": [
        "## Import data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5-M4q-AWntv"
      },
      "source": [
        "### Training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvVpxXPiYgvx",
        "outputId": "9fbcc8e9-93f4-4d32-9aa9-1d12769566f1"
      },
      "source": [
        "\n",
        "!pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75TRUUHOWntv",
        "outputId": "559d4dee-2f55-480a-e68f-13f6e99d4319"
      },
      "source": [
        "ae_laptop_train = read_json('../data/hu-data/ae/laptop/train.json')\n",
        "\n",
        "\n",
        "asc_laptop_train = read_json('../data/hu-data/asc/laptop/train.json')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " ../data/hu-data/ae/laptop/train.json\n",
            "{'0': {'label': ['B',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'B',\n",
            "                 'I',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O'],\n",
            "       'sentence': ['Keyboard',\n",
            "                    'is',\n",
            "                    'great',\n",
            "                    'but',\n",
            "                    'primary',\n",
            "                    'and',\n",
            "                    'secondary',\n",
            "                    'control',\n",
            "                    'buttons',\n",
            "                    'could',\n",
            "                    'be',\n",
            "                    'more',\n",
            "                    'durable',\n",
            "                    '.']}}\n",
            "\n",
            " ../data/hu-data/asc/laptop/train.json\n",
            "{'327_0': {'id': '327_0',\n",
            "           'polarity': 'positive',\n",
            "           'sentence': 'Also it is very good for college students who just '\n",
            "                       'need a reliable, easy to use computer.',\n",
            "           'term': 'use'}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGUKJLvrWntw"
      },
      "source": [
        "### Dev data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pmG1iPZWntx",
        "outputId": "29ddfc20-e0f3-466c-8555-4978dac43555"
      },
      "source": [
        "ae_laptop_dev  = read_json('../data/hu-data/ae/laptop/dev.json')\n",
        "\n",
        "\n",
        "asc_laptop_dev = read_json('../data/hu-data/asc/laptop/dev.json')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " ../data/hu-data/ae/laptop/dev.json\n",
            "{'0': {'label': ['O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O'],\n",
            "       'sentence': ['I',\n",
            "                    'have',\n",
            "                    'had',\n",
            "                    'this',\n",
            "                    'laptop',\n",
            "                    'for',\n",
            "                    'a',\n",
            "                    'few',\n",
            "                    'months',\n",
            "                    'now',\n",
            "                    'and',\n",
            "                    'i',\n",
            "                    'would',\n",
            "                    'say',\n",
            "                    'im',\n",
            "                    'pretty',\n",
            "                    'satisfied',\n",
            "                    '.']}}\n",
            "\n",
            " ../data/hu-data/asc/laptop/dev.json\n",
            "{'1113_0': {'id': '1113_0',\n",
            "            'polarity': 'negative',\n",
            "            'sentence': 'Not even safe mode boots.',\n",
            "            'term': 'safe mode'}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_qex8X-Wntx"
      },
      "source": [
        "### Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHd4bZ6LWntx",
        "outputId": "bdf14e7f-d9eb-4cfb-da48-fb0afdcd13a8"
      },
      "source": [
        "ae_laptop_test  = read_json('../data/hu-data/ae/laptop/test.json')\n",
        "\n",
        "\n",
        "asc_laptop_test = read_json('../data/hu-data/asc/laptop/test.json')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " ../data/hu-data/ae/laptop/test.json\n",
            "{'0': {'label': ['B',\n",
            "                 'I',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O',\n",
            "                 'O'],\n",
            "       'sentence': ['Boot',\n",
            "                    'time',\n",
            "                    'is',\n",
            "                    'super',\n",
            "                    'fast',\n",
            "                    ',',\n",
            "                    'around',\n",
            "                    'anywhere',\n",
            "                    'from',\n",
            "                    '35',\n",
            "                    'seconds',\n",
            "                    'to',\n",
            "                    '1',\n",
            "                    'minute',\n",
            "                    '.']}}\n",
            "\n",
            " ../data/hu-data/asc/laptop/test.json\n",
            "{'718:1_0': {'id': '718:1_0',\n",
            "             'polarity': 'positive',\n",
            "             'sentence': 'the retina display display make pictures i took '\n",
            "                         'years ago jaw dropping.',\n",
            "             'term': 'retina display display'}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx42-tmPWnty"
      },
      "source": [
        "### Convert to df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "id": "JxruPHnaWnty",
        "outputId": "4a9c51b2-66e3-4cef-9a70-72c716421919"
      },
      "source": [
        "ae_laptop_train_df = pd.DataFrame.from_dict(ae_laptop_train,orient='index')\n",
        "ae_laptop_train_df.head()\n",
        "\n",
        "ae_laptop_dev_df = pd.DataFrame.from_dict(ae_laptop_dev,orient='index')\n",
        "ae_laptop_dev_df.head()\n",
        "\n",
        "ae_laptop_test_df = pd.DataFrame.from_dict(ae_laptop_test,orient='index')\n",
        "ae_laptop_test_df"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[B, O, O, O, O, O, O, B, I, O, O, O, O, O]</td>\n",
              "      <td>[Keyboard, is, great, but, primary, and, secon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[I, bought, this, laptop, about, a, month, ago...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[I, am, however, pleased, that, it, is, still,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[I, went, to, my, local, Best, Buy, looking, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[The, Apple, MC371LL/, A, 2.4Ghz, 15.4-, inch,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               label                                           sentence\n",
              "0         [B, O, O, O, O, O, O, B, I, O, O, O, O, O]  [Keyboard, is, great, but, primary, and, secon...\n",
              "1         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]  [I, bought, this, laptop, about, a, month, ago...\n",
              "2               [O, O, O, O, O, O, O, O, O, O, O, O]  [I, am, however, pleased, that, it, is, still,...\n",
              "3   [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]  [I, went, to, my, local, Best, Buy, looking, f...\n",
              "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  [The, Apple, MC371LL/, A, 2.4Ghz, 15.4-, inch,..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[I, have, had, this, laptop, for, a, few, mont...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...</td>\n",
              "      <td>[Additional, caveat, :, the, base, installatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...</td>\n",
              "      <td>[it, is, of, high, quality, ,, has, a, killer,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[O, B, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[The, screen, gets, smeary, and, dusty, very, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[I, previously, owned, an, HP, desktop, and, a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               label                                           sentence\n",
              "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  [I, have, had, this, laptop, for, a, few, mont...\n",
              "1  [O, O, O, O, B, I, O, O, O, O, O, O, B, O, O, ...  [Additional, caveat, :, the, base, installatio...\n",
              "2  [O, O, O, O, B, O, O, O, O, B, O, O, O, O, O, ...  [it, is, of, high, quality, ,, has, a, killer,...\n",
              "3         [O, B, O, O, O, O, O, O, O, O, O, O, O, O]  [The, screen, gets, smeary, and, dusty, very, ...\n",
              "4                  [O, O, O, O, O, O, O, O, O, O, O]  [I, previously, owned, an, HP, desktop, and, a..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[Boot, time, is, super, fast, ,, around, anywh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[tech, support, would, not, fix, the, problem,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[O, O, O, O, O, O, O]</td>\n",
              "      <td>[but, in, resume, this, computer, rocks, !]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[B, I, O, O, O]</td>\n",
              "      <td>[Set, up, was, easy, .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[O, O, O, O, O, B, I, O, B, I, O]</td>\n",
              "      <td>[Did, not, enjoy, the, new, Windows, 8, and, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795</th>\n",
              "      <td>[O, B, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[This, hardware, seems, to, be, better, than, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>796</th>\n",
              "      <td>[O, O, O, O, O, O, O]</td>\n",
              "      <td>[I, 'm, done, with, WinDoze, computers, .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, B, ...</td>\n",
              "      <td>[I, 've, had, it, for, about, 2, months, now, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>[O, O, O, O, O, O, O, B, I, O]</td>\n",
              "      <td>[the, latest, version, does, not, have, a, dis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>[B, O, O, O, O, O, O, O, O, B, O, O, O, O, O, O]</td>\n",
              "      <td>[Screen, -, although, some, people, might, com...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 label                                           sentence\n",
              "0        [B, I, O, O, O, O, O, O, O, O, O, O, O, O, O]  [Boot, time, is, super, fast, ,, around, anywh...\n",
              "1    [B, I, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  [tech, support, would, not, fix, the, problem,...\n",
              "2                                [O, O, O, O, O, O, O]        [but, in, resume, this, computer, rocks, !]\n",
              "3                                      [B, I, O, O, O]                            [Set, up, was, easy, .]\n",
              "4                    [O, O, O, O, O, B, I, O, B, I, O]  [Did, not, enjoy, the, new, Windows, 8, and, t...\n",
              "..                                                 ...                                                ...\n",
              "795  [O, B, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  [This, hardware, seems, to, be, better, than, ...\n",
              "796                              [O, O, O, O, O, O, O]         [I, 'm, done, with, WinDoze, computers, .]\n",
              "797  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, B, ...  [I, 've, had, it, for, about, 2, months, now, ...\n",
              "798                     [O, O, O, O, O, O, O, B, I, O]  [the, latest, version, does, not, have, a, dis...\n",
              "799   [B, O, O, O, O, O, O, O, O, B, O, O, O, O, O, O]  [Screen, -, although, some, people, might, com...\n",
              "\n",
              "[800 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "CxXe21u7Wntz",
        "outputId": "28758634-20ad-4788-cbb8-9f5293a679e4"
      },
      "source": [
        "asc_laptop_train_df = pd.DataFrame.from_dict(asc_laptop_train,orient='index')\n",
        "asc_laptop_train_df.head()\n",
        "asc_laptop_dev_df = pd.DataFrame.from_dict(asc_laptop_dev,orient='index')\n",
        "asc_laptop_dev_df.head()\n",
        "asc_laptop_test_df = pd.DataFrame.from_dict(asc_laptop_test,orient='index')\n",
        "asc_laptop_test_df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>term</th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>327_0</th>\n",
              "      <td>positive</td>\n",
              "      <td>use</td>\n",
              "      <td>327_0</td>\n",
              "      <td>Also it is very good for college students who ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3077_0</th>\n",
              "      <td>positive</td>\n",
              "      <td>noise</td>\n",
              "      <td>3077_0</td>\n",
              "      <td>For those that care about noise this thing doe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1592_1</th>\n",
              "      <td>positive</td>\n",
              "      <td>force</td>\n",
              "      <td>1592_1</td>\n",
              "      <td>Enjoy that Toshib force and durability unparal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329_0</th>\n",
              "      <td>negative</td>\n",
              "      <td>expense</td>\n",
              "      <td>329_0</td>\n",
              "      <td>I know that everyone thinks Macs are overprice...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1184_0</th>\n",
              "      <td>negative</td>\n",
              "      <td>word processor</td>\n",
              "      <td>1184_0</td>\n",
              "      <td>) And printing from either word processor is a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        polarity  ...                                           sentence\n",
              "327_0   positive  ...  Also it is very good for college students who ...\n",
              "3077_0  positive  ...  For those that care about noise this thing doe...\n",
              "1592_1  positive  ...  Enjoy that Toshib force and durability unparal...\n",
              "329_0   negative  ...  I know that everyone thinks Macs are overprice...\n",
              "1184_0  negative  ...  ) And printing from either word processor is a...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>term</th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1113_0</th>\n",
              "      <td>negative</td>\n",
              "      <td>safe mode</td>\n",
              "      <td>1113_0</td>\n",
              "      <td>Not even safe mode boots.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2595_0</th>\n",
              "      <td>positive</td>\n",
              "      <td>Keyboard</td>\n",
              "      <td>2595_0</td>\n",
              "      <td>Keyboard was also very nice and had a solid feel.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1039_0</th>\n",
              "      <td>negative</td>\n",
              "      <td>Keyboard</td>\n",
              "      <td>1039_0</td>\n",
              "      <td>Keyboard is plastic and spongey feeling.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315_0</th>\n",
              "      <td>positive</td>\n",
              "      <td>quality</td>\n",
              "      <td>315_0</td>\n",
              "      <td>I would recommend this laptop to anyone lookin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1284_0</th>\n",
              "      <td>negative</td>\n",
              "      <td>screen</td>\n",
              "      <td>1284_0</td>\n",
              "      <td>Thus, when you carry it at a slanted angle, th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        polarity  ...                                           sentence\n",
              "1113_0  negative  ...                          Not even safe mode boots.\n",
              "2595_0  positive  ...  Keyboard was also very nice and had a solid feel.\n",
              "1039_0  negative  ...           Keyboard is plastic and spongey feeling.\n",
              "315_0   positive  ...  I would recommend this laptop to anyone lookin...\n",
              "1284_0  negative  ...  Thus, when you carry it at a slanted angle, th...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>term</th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>718:1_0</th>\n",
              "      <td>positive</td>\n",
              "      <td>retina display display</td>\n",
              "      <td>718:1_0</td>\n",
              "      <td>the retina display display make pictures i too...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217:1_1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>CD/DVD drive</td>\n",
              "      <td>217:1_1</td>\n",
              "      <td>Needs a CD/DVD drive and a bigger power switch.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217:1_0</th>\n",
              "      <td>negative</td>\n",
              "      <td>power switch</td>\n",
              "      <td>217:1_0</td>\n",
              "      <td>Needs a CD/DVD drive and a bigger power switch.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1044:1_0</th>\n",
              "      <td>negative</td>\n",
              "      <td>battery</td>\n",
              "      <td>1044:1_0</td>\n",
              "      <td>The battery is not as shown in the product pho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1040:1_0</th>\n",
              "      <td>negative</td>\n",
              "      <td>keyboard</td>\n",
              "      <td>1040:1_0</td>\n",
              "      <td>It feels cheap, the keyboard is not very sensi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          polarity  ...                                           sentence\n",
              "718:1_0   positive  ...  the retina display display make pictures i too...\n",
              "217:1_1    neutral  ...    Needs a CD/DVD drive and a bigger power switch.\n",
              "217:1_0   negative  ...    Needs a CD/DVD drive and a bigger power switch.\n",
              "1044:1_0  negative  ...  The battery is not as shown in the product pho...\n",
              "1040:1_0  negative  ...  It feels cheap, the keyboard is not very sensi...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X5neuqGFZuh"
      },
      "source": [
        "# AE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q97dA-oNWntz"
      },
      "source": [
        "## AE baseline - NN+"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "T068QDzsWntz",
        "outputId": "d227bcda-4d20-49a0-a7d2-ac185ccdfcec"
      },
      "source": [
        "def pos_ae(tokenized_sentence):\n",
        "    \"\"\"\n",
        "    Tag sentences using POS tagger and identify consecutive nouns as entities\n",
        "    \"\"\"\n",
        "    pos_sent = tokenized_sentence.apply(lambda sent:nltk.pos_tag(sent,tagset='universal'))\n",
        "    \n",
        "    \n",
        "    # tag with IOB terminology\n",
        "    ae_tag = lambda sent:['O' if token[1] != 'NOUN' \n",
        "                          else 'B' if ((token[1]=='NOUN') & ((sent[ind-1][1]!='NOUN') | (ind==0))) \n",
        "                          else 'I' for ind,token in enumerate(sent)]\n",
        "\n",
        "    return(pos_sent.apply(ae_tag))\n",
        "\n",
        "# since the POS tagger is based on the words themselves and not context.\n",
        "ae_laptop_test_df['predictions'] = pos_ae(ae_laptop_test_df['sentence'])\n",
        "ae_laptop_test_df.head()\n",
        "\n",
        "def convert_int(tagged_tokens):\n",
        "    \"\"\"\n",
        "    Convert B,I,O tags to integers\n",
        "    \"\"\"\n",
        "    return(tagged_tokens.apply(lambda sent: [0 if token=='O' else 1 if token=='B' else 2 for token in sent]))\n",
        "\n",
        "convert_int(ae_laptop_test_df['predictions'])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[Boot, time, is, super, fast, ,, around, anywh...</td>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, B, O, O, B, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[tech, support, would, not, fix, the, problem,...</td>\n",
              "      <td>[O, B, O, O, O, O, B, O, O, O, O, B, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[O, O, O, O, O, O, O]</td>\n",
              "      <td>[but, in, resume, this, computer, rocks, !]</td>\n",
              "      <td>[O, O, B, O, B, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[B, I, O, O, O]</td>\n",
              "      <td>[Set, up, was, easy, .]</td>\n",
              "      <td>[B, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[O, O, O, O, O, B, I, O, B, I, O]</td>\n",
              "      <td>[Did, not, enjoy, the, new, Windows, 8, and, t...</td>\n",
              "      <td>[B, O, O, O, O, B, O, O, O, B, O]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               label  ...                                        predictions\n",
              "0      [B, I, O, O, O, O, O, O, O, O, O, O, O, O, O]  ...      [B, I, O, O, O, O, O, O, O, O, B, O, O, B, O]\n",
              "1  [B, I, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  ...  [O, B, O, O, O, O, B, O, O, O, O, B, O, O, O, ...\n",
              "2                              [O, O, O, O, O, O, O]  ...                              [O, O, B, O, B, O, O]\n",
              "3                                    [B, I, O, O, O]  ...                                    [B, O, O, O, O]\n",
              "4                  [O, O, O, O, O, B, I, O, B, I, O]  ...                  [B, O, O, O, O, B, O, O, O, B, O]\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
              "1      [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, ...\n",
              "2                                  [0, 0, 1, 0, 1, 0, 0]\n",
              "3                                        [1, 0, 0, 0, 0]\n",
              "4                      [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0]\n",
              "                             ...                        \n",
              "795    [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...\n",
              "796                                [0, 0, 0, 0, 1, 2, 0]\n",
              "797    [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, ...\n",
              "798                       [0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
              "799     [1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
              "Name: predictions, Length: 800, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d67h2o_MWnt0"
      },
      "source": [
        "## AE Regex Parser - business rules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "XJK1PwSdWnt0",
        "outputId": "9c05abb0-0c1c-40bc-ddc3-538699a3ae53"
      },
      "source": [
        "# try a more sophisticated method for chunking\n",
        "def regex_parser(tokenized_sentence,verbose=False):\n",
        "    \"\"\"\n",
        "    Use a Regex Parser to provide some context around noun phrases\n",
        "    \"\"\"\n",
        "    pos_sent = nltk.pos_tag(tokenized_sentence)\n",
        "#     print(pos_sent)\n",
        "#     grammar = r\"\"\"\n",
        "#       NP: {<DT|PP\\$>?<JJ>*<NN>}   # chunk determiner/possessive, adjectives and noun\n",
        "#           {<NNP>+}                # chunk sequences of proper nouns\n",
        "#     \"\"\"\n",
        "    \n",
        "    # Update Grammar Regex to include prepositional phrases ala Semeval annotation guidelines\n",
        "    grammar = r\"\"\"\n",
        "    NP: {<NN><IN><DT><NN|NNP>+}\n",
        "        {<NNP><NN>}\n",
        "        {<NNP>+}\n",
        "        {<NN>+}\n",
        "        \n",
        "    \"\"\"\n",
        "    \n",
        "    cp = nltk.RegexpParser(grammar)\n",
        "\n",
        "    tree = cp.parse(pos_sent)\n",
        "    \n",
        "    if verbose: print(tree)\n",
        "    \n",
        "    iob = [el[2][0] for el in nltk.chunk.util.tree2conlltags(tree)]\n",
        "    return(iob)\n",
        "\n",
        "# since the POS tagger is based on the words themselves and not context.\n",
        "ae_laptop_test_df['predictions_1'] = ae_laptop_test_df['sentence'].apply(lambda x: regex_parser(x))\n",
        "ae_laptop_test_df.head()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "      <th>predictions</th>\n",
              "      <th>predictions_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[Boot, time, is, super, fast, ,, around, anywh...</td>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, B, O, O, B, O]</td>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, B, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[tech, support, would, not, fix, the, problem,...</td>\n",
              "      <td>[O, B, O, O, O, O, B, O, O, O, O, B, O, O, O, ...</td>\n",
              "      <td>[O, B, O, O, O, O, B, O, O, O, O, B, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[O, O, O, O, O, O, O]</td>\n",
              "      <td>[but, in, resume, this, computer, rocks, !]</td>\n",
              "      <td>[O, O, B, O, B, O, O]</td>\n",
              "      <td>[O, O, B, O, B, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[B, I, O, O, O]</td>\n",
              "      <td>[Set, up, was, easy, .]</td>\n",
              "      <td>[B, O, O, O, O]</td>\n",
              "      <td>[B, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[O, O, O, O, O, B, I, O, B, I, O]</td>\n",
              "      <td>[Did, not, enjoy, the, new, Windows, 8, and, t...</td>\n",
              "      <td>[B, O, O, O, O, B, O, O, O, B, O]</td>\n",
              "      <td>[B, O, O, O, O, B, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               label  ...                                      predictions_1\n",
              "0      [B, I, O, O, O, O, O, O, O, O, O, O, O, O, O]  ...      [B, I, O, O, O, O, O, O, O, O, O, O, O, B, O]\n",
              "1  [B, I, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  ...  [O, B, O, O, O, O, B, O, O, O, O, B, O, O, O, ...\n",
              "2                              [O, O, O, O, O, O, O]  ...                              [O, O, B, O, B, O, O]\n",
              "3                                    [B, I, O, O, O]  ...                                    [B, O, O, O, O]\n",
              "4                  [O, O, O, O, O, B, I, O, B, I, O]  ...                  [B, O, O, O, O, B, O, O, O, O, O]\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-yMQLF6PGw3"
      },
      "source": [
        "## AE BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJP4NqXxPJMA"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyKk9x7cPSiA",
        "outputId": "fdb50c43-041c-41ee-a648-368a54c53fb9"
      },
      "source": [
        "batch_sentences = [val['sentence'] for key, val in ae_laptop_train.items()]*5\n",
        "batch_sentences.extend([val['sentence'] for key, val in ae_laptop_dev.items()])\n",
        "batch_sentences.extend([val['sentence'] for key, val in ae_laptop_test.items()])\n",
        "train_size = len(ae_laptop_train)*5\n",
        "dev_size = len(ae_laptop_dev)\n",
        "test_size = len(ae_laptop_test)\n",
        "print(train_size)\n",
        "print(dev_size)\n",
        "print(test_size)\n",
        "assert len(batch_sentences) == train_size+dev_size+test_size"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14475\n",
            "150\n",
            "800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksjOg6R_PUuw",
        "outputId": "1718ce5c-a5e5-4001-c01b-4c13ba9e99a5"
      },
      "source": [
        "batch_label = [val['label'] for key, val in ae_laptop_train.items()]*5\n",
        "batch_label.extend([val['label'] for key, val in ae_laptop_dev.items()])\n",
        "batch_label.extend([val['label'] for key, val in ae_laptop_test.items()])\n",
        "\n",
        "len(batch_label)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15425"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhOESEdrPZLw"
      },
      "source": [
        "def addWord(word, ner):\n",
        "    \"\"\"\n",
        "    Convert a word into a word token and add supplied NER labels. Note that the word can be  \n",
        "    tokenized to two or more tokens. Correspondingly, we add - for now - custom 'X' tokens to the labels in order to \n",
        "    maintain the 1:1 mappings between word tokens and labels.\n",
        "    \n",
        "    arguments: word, ner label\n",
        "    returns: dictionary with tokens and labels\n",
        "    \"\"\"\n",
        "    # the dataset contains various '\"\"\"' combinations which we choose to truncate to '\"', etc. \n",
        "    if word == '\"\"\"\"':\n",
        "        word = '\"'\n",
        "    elif word == '``':\n",
        "        word = '`'\n",
        "        \n",
        "    tokens = tokenizer.tokenize(word)\n",
        "    tokenLength = len(tokens)      # find number of tokens corresponfing to word to later add 'X' tokens to labels\n",
        "    \n",
        "    addDict = dict()\n",
        "    \n",
        "    addDict['wordToken'] = tokens\n",
        "    addDict['nerToken'] = [ner] + ['nerX'] * (tokenLength - 1)\n",
        "    addDict['tokenLength'] = tokenLength\n",
        "    \n",
        "    return addDict"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoVdijd8PbIo"
      },
      "source": [
        "max_length = 50"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quJUle9pPeB4"
      },
      "source": [
        "# lists for sentences, tokens, labels, etc.  \n",
        "sentenceList = []\n",
        "sentenceTokenList = []\n",
        "nerTokenList = []\n",
        "sentLengthList = []\n",
        "\n",
        "# lists for BERT input\n",
        "bertSentenceIDs = []\n",
        "bertMasks = []\n",
        "bertSequenceIDs = []\n",
        "\n",
        "sentence = ''\n",
        "\n",
        "# always start with [CLS] tokens\n",
        "sentenceTokens = ['[CLS]']\n",
        "nerTokens = ['[nerCLS]']\n",
        "\n",
        "for sentence,label in zip(batch_sentences,batch_label):\n",
        "    for ind,token in enumerate(sentence):\n",
        "        word, ner = token,label[ind]\n",
        "\n",
        "        # if new sentence starts\n",
        "        if (ind == 0):            \n",
        "\n",
        "            sentenceLength = min(max_length -1, len(sentenceTokens))\n",
        "            sentLengthList.append(sentenceLength)\n",
        "\n",
        "            # Create space for at least a final '[SEP]' token\n",
        "            if sentenceLength >= max_length - 1: \n",
        "                sentenceTokens = sentenceTokens[:max_length - 2]\n",
        "                nerTokens = nerTokens[:max_length - 2]\n",
        "\n",
        "            # add a ['SEP'] token and padding\n",
        "\n",
        "            sentenceTokens += ['[SEP]'] + ['[PAD]'] * (max_length -1 - len(sentenceTokens))\n",
        "            nerTokens += ['[nerSEP]'] + ['[nerPAD]'] * (max_length - 1 - len(nerTokens) )\n",
        "\n",
        "            sentenceList.append(sentence)\n",
        "\n",
        "            sentenceTokenList.append(sentenceTokens)\n",
        "\n",
        "            bertSentenceIDs.append(tokenizer.convert_tokens_to_ids(sentenceTokens))\n",
        "            bertMasks.append([1] * (sentenceLength + 1) + [0] * (max_length -1 - sentenceLength ))\n",
        "            bertSequenceIDs.append([0] * (max_length))\n",
        "\n",
        "            nerTokenList.append(nerTokens)\n",
        "\n",
        "            sentence = ''\n",
        "            sentenceTokens = ['[CLS]']\n",
        "            nerTokens = ['[nerCLS]']\n",
        "\n",
        "            sentence += ' ' + word\n",
        "\n",
        "        addDict = addWord(word, ner)\n",
        "\n",
        "        sentenceTokens += addDict['wordToken']\n",
        "        nerTokens += addDict['nerToken']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpNSU87OPghJ",
        "outputId": "c3983726-140b-4c89-d2df-cc98dad1b396"
      },
      "source": [
        "print(sentenceTokenList[1])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'keyboard', 'is', 'great', 'but', 'primary', 'and', 'secondary', 'control', 'buttons', 'could', 'be', 'more', 'durable', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hNOmEFlPh2U",
        "outputId": "3b3b5e3e-07cd-407e-cc79-80c1b093237f"
      },
      "source": [
        "print(nerTokenList[1])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[nerCLS]', 'B', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'I', 'O', 'O', 'O', 'O', 'O', '[nerSEP]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yby3HEBZPkUQ",
        "outputId": "cbd1faef-a725-4c9a-c129-da6b3baa3c6c"
      },
      "source": [
        "print(bertMasks[1])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxGwK42IPmBl",
        "outputId": "c3dfe179-25cc-48d1-e6bb-f87e82d71a0a"
      },
      "source": [
        "print(bertSequenceIDs[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "DabVF8jEPoBF",
        "outputId": "ecf95c53-ca37-4fc1-d4be-35155b5cec45"
      },
      "source": [
        "sentenceLengths= [l for l in sentLengthList]\n",
        "\n",
        "plt.hist(np.array(sentenceLengths), bins=(max_length-2))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  1.,   0.,  10., 187., 240., 358., 543., 500., 685., 686., 618.,\n",
              "        721., 743., 825., 761., 728., 714., 556., 565., 533., 462., 521.,\n",
              "        372., 387., 372., 433., 294., 295., 212., 179., 202., 165., 151.,\n",
              "        145., 140., 109., 105.,  77.,  73.,  87.,  68.,  64.,  60.,  55.,\n",
              "         36.,  50.,  41., 296.]),\n",
              " array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
              "        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.,\n",
              "        27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39.,\n",
              "        40., 41., 42., 43., 44., 45., 46., 47., 48., 49.]),\n",
              " <a list of 48 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0-7ApM5Pp7s"
      },
      "source": [
        "numSentences = len(bertSentenceIDs)\n",
        "\n",
        "nerClasses = pd.DataFrame(np.array(nerTokenList).reshape(-1))\n",
        "nerClasses.columns = ['tag']\n",
        "nerClasses.tag = pd.Categorical(nerClasses.tag)\n",
        "nerClasses['cat'] = nerClasses.tag.cat.codes\n",
        "nerClasses['sym'] = nerClasses.tag.cat.codes\n",
        "nerLabels = np.array(nerClasses.cat).reshape(numSentences, -1)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_YIhO2LPshy"
      },
      "source": [
        "bert_inputs = np.array([bertSentenceIDs, bertMasks, bertSequenceIDs])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RItX8wIxPuXF",
        "outputId": "07db1937-b262-451c-8766-4a1daa21566f"
      },
      "source": [
        "bert_inputs.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 15425, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgGx-ukYPxGn"
      },
      "source": [
        "trainSentence_ids = bert_inputs[0][:train_size]\n",
        "trainMasks = bert_inputs[1][:train_size]\n",
        "trainSequence_ids = bert_inputs[2][:train_size]\n",
        "\n",
        "devSentence_ids = bert_inputs[0][train_size:train_size+dev_size]\n",
        "devMasks = bert_inputs[1][train_size:train_size+dev_size]\n",
        "devSequence_ids = bert_inputs[2][train_size:train_size+dev_size]\n",
        "\n",
        "testSentence_ids = bert_inputs[0][train_size+dev_size:]\n",
        "testMasks = bert_inputs[1][train_size+dev_size:]\n",
        "testSequence_ids = bert_inputs[2][train_size+dev_size:]\n",
        "\n",
        "nerLabels_train = nerLabels[:train_size]\n",
        "nerLabels_dev = nerLabels[train_size:train_size+dev_size]\n",
        "nerLabels_test = nerLabels[train_size+dev_size:]\n",
        "\n",
        "X_train = np.array([trainSentence_ids,trainMasks,trainSequence_ids])\n",
        "X_dev = np.array([devSentence_ids,devMasks,devSequence_ids])\n",
        "X_test = np.array([testSentence_ids,testMasks,testSequence_ids])\n",
        "\n",
        "nerLabels_train = np.array(nerLabels_train)\n",
        "nerLabels_dev = np.array(nerLabels_dev)\n",
        "nerLabels_test = np.array(nerLabels_test)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72K5zOxqPynf",
        "outputId": "8f42841a-d9e9-410e-d3ef-3112fa618ac8"
      },
      "source": [
        "trainSentence_ids.shape\n",
        "devSentence_ids.shape\n",
        "testSentence_ids.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14475, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tRAKKP5P0z6"
      },
      "source": [
        "# Use a parameter pair k_start, k_end to look at slices. This helps with quick tests.\n",
        "\n",
        "k_start = 0\n",
        "k_end = -1\n",
        "\n",
        "if k_end == -1:\n",
        "    k_end_train = X_train[0].shape[0]\n",
        "    k_end_dev = X_dev[0].shape[0]\n",
        "    k_end_test = X_test[0].shape[0]\n",
        "else:\n",
        "    k_end_train = k_end_test = k_end_dev = k_end\n",
        "    \n",
        "\n",
        "\n",
        "bert_inputs_train_k = [X_train[0][k_start:k_end_train], X_train[1][k_start:k_end_train], \n",
        "                       X_train[2][k_start:k_end_train]]\n",
        "bert_inputs_dev_k = [X_dev[0][k_start:k_end_dev], X_dev[1][k_start:k_end_dev], \n",
        "                      X_dev[2][k_start:k_end_dev]]\n",
        "bert_inputs_test_k = [X_test[0][k_start:k_end_test], X_test[1][k_start:k_end_test], \n",
        "                      X_test[2][k_start:k_end_test]]\n",
        "\n",
        "\n",
        "labels_train_k = nerLabels_train[k_start:k_end_train]\n",
        "labels_dev_k = nerLabels_dev[k_start:k_end_dev]\n",
        "labels_test_k = nerLabels_test[k_start:k_end_test]"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAX8WnV3P48s"
      },
      "source": [
        "train_all = [bert_inputs_train_k, labels_train_k]\n",
        "dev_all = [bert_inputs_dev_k, labels_dev_k]\n",
        "test_all = [bert_inputs_test_k, labels_test_k]"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIAht7YuP7GL"
      },
      "source": [
        "numNerClasses = 7"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydgzC-NGP-Px"
      },
      "source": [
        "def custom_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    calculate loss function explicitly, filtering out 'extra inserted labels'\n",
        "    \n",
        "    y_true: Shape: (batch x (max_length + 1) )\n",
        "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
        "    \n",
        "    returns:  cost\n",
        "    \"\"\"\n",
        "\n",
        "    #get labels and predictions\n",
        "    \n",
        "    y_label = tf.reshape(Flatten()(tf.cast(y_true, tf.int32)),[-1])\n",
        "    \n",
        "    mask = (y_label < 3)   # This mask is used to remove all tokens that do not correspond to the original base text.\n",
        "\n",
        "    y_label_masked = tf.boolean_mask(y_label, mask)  # mask the labels\n",
        "    \n",
        "    y_flat_pred = tf.reshape(Flatten()(tf.cast(y_pred, tf.float32)),[-1, numNerClasses])\n",
        "    \n",
        "    y_flat_pred_masked = tf.boolean_mask(y_flat_pred, mask) # mask the predictions\n",
        "    \n",
        "    return tf.reduce_mean(sparse_categorical_crossentropy(y_label_masked, y_flat_pred_masked,from_logits=False ))"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzzVPQgMQBPW"
      },
      "source": [
        "def custom_acc_orig_tokens(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    calculate loss dfunction filtering out also the newly inserted labels\n",
        "    \n",
        "    y_true: Shape: (batch x (max_length) )\n",
        "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
        "    \n",
        "    returns: accuracy\n",
        "    \"\"\"\n",
        "\n",
        "    #get labels and predictions\n",
        "    \n",
        "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
        "    \n",
        "    mask = (y_label < 3)\n",
        "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
        "    \n",
        "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
        "                                                    [-1, numNerClasses]), axis=1)\n",
        "    \n",
        "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
        "\n",
        "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv1KbNgPQDY7"
      },
      "source": [
        "def custom_acc_orig_non_other_tokens(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    calculate loss dfunction explicitly filtering out also the 'Other'- labels\n",
        "    \n",
        "    y_true: Shape: (batch x (max_length) )\n",
        "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
        "    \n",
        "    returns: accuracy\n",
        "    \"\"\"\n",
        "\n",
        "    #get labels and predictions\n",
        "    \n",
        "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
        "    \n",
        "    mask = (y_label < 2)\n",
        "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
        "    \n",
        "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
        "                                                    [-1, numNerClasses]), axis=1)\n",
        "    \n",
        "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
        "\n",
        "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOatdRHXQFS3"
      },
      "source": [
        "adam_customized = tf.keras.optimizers.Adam(lr=0.0000005) #, beta_1=0.91, beta_2=0.999, epsilon=None, decay=0.1, amsgrad=False"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVSifTaIQIO6"
      },
      "source": [
        "def ner_model(max_input_length, train_layers, optimizer):\n",
        "    \"\"\"\n",
        "    Implementation of NER model\n",
        "    \n",
        "    variables:\n",
        "        max_input_length: number of tokens (max_length + 1)\n",
        "        train_layers: number of layers to be retrained\n",
        "        optimizer: optimizer to be used\n",
        "    \n",
        "    returns: model\n",
        "    \"\"\"\n",
        "    \n",
        "    in_id = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_ids\")\n",
        "    in_mask = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_masks\")\n",
        "    in_segment = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"segment_ids\")\n",
        "    \n",
        "    \n",
        "    bert_inputs = [in_id, in_mask, in_segment]\n",
        "    \n",
        "    \n",
        "    \n",
        "    # Note: Bert layer from Hugging Face returns two values: sequence ouput, and pooled output. Here, we only want\n",
        "    # the former. (See https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel) \n",
        "    \n",
        "    bert_layer = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "    \n",
        "    # Freeze layers, i.e. only train number of layers specified, starting from the top\n",
        "    \n",
        "    if not train_layers == -1:\n",
        "        \n",
        "        retrain_layers = []\n",
        "    \n",
        "        for retrain_layer_number in range(train_layers):\n",
        "\n",
        "            layer_code = '_' + str(11 - retrain_layer_number)\n",
        "            retrain_layers.append(layer_code)\n",
        "\n",
        "        for w in bert_layer.weights:\n",
        "            if not any([x in w.name for x in retrain_layers]):\n",
        "                w._trainable = False\n",
        "\n",
        "        # End of freezing section\n",
        "    \n",
        "    bert_sequence = bert_layer(bert_inputs)[0]\n",
        "    \n",
        "    print('Let us check the shape of the BERT layer output:', bert_sequence)\n",
        "    \n",
        "    dense = tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l=0.1), name='dense')(bert_sequence)\n",
        "    \n",
        "    dense = tf.keras.layers.Dropout(rate=0.1)(dense)\n",
        "    \n",
        "    pred = tf.keras.layers.Dense(numNerClasses, activation='softmax', name='ner')(dense)\n",
        "     \n",
        "    print('pred: ', pred)\n",
        "    \n",
        "    ## Prepare for multipe loss functions, although not used here\n",
        "    \n",
        "    losses = {\n",
        "        \"ner\": custom_loss,\n",
        "        }\n",
        "    lossWeights = {\"ner\": 1.0\n",
        "                  }\n",
        "    \n",
        "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
        "\n",
        "    model.compile(loss=losses, optimizer=optimizer, metrics=[custom_acc_orig_tokens])#,custom_acc_orig_non_other_tokens])\n",
        "    \n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0J8htWOQQLNP",
        "outputId": "158a1dca-ee9f-4c90-80ac-9cf65175b046"
      },
      "source": [
        "print(bert_inputs_train_k[0][1])\n",
        "print(labels_train_k[1])"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  101  9019  2003  2307  2021  3078  1998  3905  2491 11287  2071  2022\n",
            "  2062 25634  1012   102     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0]\n",
            "[3 0 2 2 2 2 2 2 0 1 2 2 2 2 2 5 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7uY-xjLQN-t",
        "outputId": "c0f76038-fa91-4751-d972-8bdefdf353be"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "# retrain all layers\n",
        "model = ner_model(max_length + 1, train_layers=-1, optimizer = adam_customized)\n",
        "\n",
        "model.fit(\n",
        "    bert_inputs_train_k, \n",
        "    {\"ner\": labels_train_k },\n",
        "    validation_data=(bert_inputs_dev_k, {\"ner\": labels_dev_k }),\n",
        "    epochs=5,\n",
        "    batch_size=8,\n",
        "    shuffle = True #since we have 5 duplicates of each\n",
        ")"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Let us check the shape of the BERT layer output: KerasTensor(type_spec=TensorSpec(shape=(None, 50, 768), dtype=tf.float32, name=None), name='tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0', description=\"created by layer 'tf_bert_model'\")\n",
            "pred:  KerasTensor(type_spec=TensorSpec(shape=(None, 50, 7), dtype=tf.float32, name=None), name='ner/truediv:0', description=\"created by layer 'ner'\")\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_ids[0][0]                  \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 50, 256)      196864      tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 50, 256)      0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "ner (Dense)                     (None, 50, 7)        1799        dropout_37[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 109,680,903\n",
            "Trainable params: 109,680,903\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "1810/1810 [==============================] - 235s 122ms/step - loss: 38.8966 - custom_acc_orig_tokens: 0.7582 - val_loss: 37.1986 - val_custom_acc_orig_tokens: 0.9600\n",
            "Epoch 2/10\n",
            "1810/1810 [==============================] - 217s 120ms/step - loss: 36.8625 - custom_acc_orig_tokens: 0.9657 - val_loss: 35.8446 - val_custom_acc_orig_tokens: 0.9830\n",
            "Epoch 3/10\n",
            "1810/1810 [==============================] - 218s 120ms/step - loss: 35.5226 - custom_acc_orig_tokens: 0.9828 - val_loss: 34.5630 - val_custom_acc_orig_tokens: 0.9871\n",
            "Epoch 4/10\n",
            "1810/1810 [==============================] - 219s 121ms/step - loss: 34.2472 - custom_acc_orig_tokens: 0.9873 - val_loss: 33.3196 - val_custom_acc_orig_tokens: 0.9879\n",
            "Epoch 5/10\n",
            "1810/1810 [==============================] - 219s 121ms/step - loss: 33.0075 - custom_acc_orig_tokens: 0.9903 - val_loss: 32.1085 - val_custom_acc_orig_tokens: 0.9882\n",
            "Epoch 6/10\n",
            "1810/1810 [==============================] - 218s 121ms/step - loss: 31.8002 - custom_acc_orig_tokens: 0.9921 - val_loss: 30.9281 - val_custom_acc_orig_tokens: 0.9886\n",
            "Epoch 7/10\n",
            "1810/1810 [==============================] - 218s 120ms/step - loss: 30.6249 - custom_acc_orig_tokens: 0.9931 - val_loss: 29.7776 - val_custom_acc_orig_tokens: 0.9886\n",
            "Epoch 8/10\n",
            "1810/1810 [==============================] - 219s 121ms/step - loss: 29.4778 - custom_acc_orig_tokens: 0.9944 - val_loss: 28.6566 - val_custom_acc_orig_tokens: 0.9895\n",
            "Epoch 9/10\n",
            "1810/1810 [==============================] - 219s 121ms/step - loss: 28.3605 - custom_acc_orig_tokens: 0.9954 - val_loss: 27.5646 - val_custom_acc_orig_tokens: 0.9893\n",
            "Epoch 10/10\n",
            "1810/1810 [==============================] - 218s 120ms/step - loss: 27.2718 - custom_acc_orig_tokens: 0.9963 - val_loss: 26.5008 - val_custom_acc_orig_tokens: 0.9896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd0547bbc10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6jN1NCWQQCp"
      },
      "source": [
        "bert_inputs_infer = [X_test[0], X_test[1], X_test[2]]\n",
        "result = model.predict(\n",
        "    bert_inputs_infer, \n",
        "    batch_size=16\n",
        ")"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOcPX6LnSnvx",
        "outputId": "31486fee-0b86-467a-c348-42d205745da6"
      },
      "source": [
        "print(np.argmax(result, axis=2)[8])"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3 2 2 2 2 2 5 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEpkOKJxSr2j",
        "outputId": "d7060228-a65b-4b45-91ba-2464ff176ab4"
      },
      "source": [
        "print(nerLabels_test[8])"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3 2 2 2 2 2 5 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek6sksX1StcY",
        "outputId": "dd4d2790-a46c-4d13-afe6-fd34d92c6520"
      },
      "source": [
        "# build a dataframe that we can index\n",
        "nerClassDict = nerClasses[['tag','cat']].drop_duplicates().sort_values('cat')\n",
        "nerClassDict = list(nerClassDict.tag.values.tolist())\n",
        "nerClassDict"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B', 'I', 'O', '[nerCLS]', '[nerPAD]', '[nerSEP]', 'nerX']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UR8i9zSFSwIB",
        "outputId": "55fe7b41-743d-4a4f-98d1-9dab142ae711"
      },
      "source": [
        "# index categorical label dataframe for the predicted tag\n",
        "format_result = []\n",
        "for sample in np.argmax(result, axis=2):\n",
        "    format_result.append([nerClassDict[label] for label in sample])\n",
        "    \n",
        "len(format_result)"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GbGb9-1vbSN",
        "outputId": "0b0a6ded-d465-4949-b729-217d47d0b398"
      },
      "source": [
        "# index categorical label dataframe for the true tag\n",
        "format_label = []\n",
        "for sample in nerLabels_test:\n",
        "    format_label.append([nerClassDict[label] for label in sample])\n",
        "    \n",
        "len(format_label)"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2i4-U529jNV"
      },
      "source": [
        "# get real tokens back\n",
        "format_sent = [tokenizer.convert_ids_to_tokens(sample) for sample in X_test[0]]"
      ],
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzxuLbqTs-Xh",
        "outputId": "a8544b2b-7481-4ccd-dc22-40ffc4f54db7"
      },
      "source": [
        "predictions_flat = [pred for preds in format_result for pred in preds]\n",
        "labels_flat = [label for labels in format_label for label in labels]\n",
        "sentence_flat = [token for sample in X_test[0] for token in tokenizer.convert_ids_to_tokens(sample)]\n",
        "\n",
        "clean_preds = []\n",
        "clean_labels = []\n",
        "\n",
        "for pred, label in zip(predictions_flat, labels_flat):\n",
        "    if label in ['O','B','I','nerX']:\n",
        "        clean_preds.append(pred)\n",
        "        clean_labels.append(label)\n",
        "print(Counter(clean_preds))\n",
        "print(confusion_matrix(clean_labels,clean_preds))"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'O': 10813, 'nerX': 874, 'B': 653, 'I': 355})\n",
            "[[  546    10    92     0]\n",
            " [   46   324    77     0]\n",
            " [   61    19 10620    22]\n",
            " [    0     2    24   852]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZKGgVBRz2gV"
      },
      "source": [
        "def bert_entities(sentence_list,label_list):\n",
        "  all_entities = []\n",
        "  for full_sentence, full_label in zip(sentence_list,label_list):\n",
        "    entities = []\n",
        "    for sentence, label in zip(full_sentence,full_label):\n",
        "      if label == 'B': \n",
        "        entities.append(sentence)\n",
        "      elif label == 'I':\n",
        "        try:\n",
        "          last_entry = entities.pop()\n",
        "        except:\n",
        "          last_entry = ''\n",
        "        entities.append(last_entry + '_' + sentence)\n",
        "      elif (label == 'nerX') & (len(entities) !=0):\n",
        "        last_entry = entities.pop()\n",
        "        entities.append(last_entry+sentence)\n",
        "    all_entities.append(entities)\n",
        "  return(all_entities)\n",
        "\n",
        "true_entities = bert_entities(format_sent,format_label)\n",
        "pred_entities = bert_entities(format_sent,format_result)"
      ],
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "pOj8Cfpv1yww",
        "outputId": "cdcd5932-359d-4edf-ccde-ac6270843456"
      },
      "source": [
        "get_ae_eval_features(true_entities,pred_entities)\n"
      ],
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>entity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>boot_time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>tech_support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>set_up</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>windows_8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>touch##screen_functions</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sample_index                   entity\n",
              "0             1                boot_time\n",
              "1             2             tech_support\n",
              "2             4                   set_up\n",
              "3             5                windows_8\n",
              "4             5  touch##screen_functions"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Pred\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>entity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>boot_time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>tech_support</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>set_up</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>windows_8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>touch##screen_functions</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sample_index                   entity\n",
              "0             1                boot_time\n",
              "1             2             tech_support\n",
              "2             4                   set_up\n",
              "3             5                windows_8\n",
              "4             5  touch##screen_functions"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Correct: 478\n",
            "Partial: 124\n",
            "Missed: 68\n",
            "Spurious: 72\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(478, 124, 68, 72, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muVXehuBSzfi"
      },
      "source": [
        "# # add the nerX back to either IOB. Remove padding, class, and sep tokens\n",
        "# def clean_IOB_result(sample):\n",
        "#     clean = []\n",
        "#     for ind,label in enumerate(sample):\n",
        "#         # if label in ['I','O','B']:\n",
        "#         #     clean.append(label)\n",
        "#         # elif label == 'nerX':\n",
        "#         #     clean.append(sample[ind-1])\n",
        "#         if label == 'O':\n",
        "#           clean.append(label)\n",
        "#         elif label == 'B':\n",
        "#           if (ind!=0) & (sample[ind-1] == 'B'): clean.append('I') \n",
        "#           elif (ind!=0) & (sample[ind-1] == 'I'): clean.append('I')\n",
        "#           else: clean.append(label)\n",
        "#         elif label == 'I':\n",
        "#           if (ind==0): clean.append('B')\n",
        "#           else: clean.append(label)\n",
        "#         elif label == 'nerX':\n",
        "#             clean.append(sample[ind-1])\n",
        "#     return(clean)"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "1hSlTVwMS9Hv",
        "outputId": "76016f1b-00a6-4285-9691-5adf6fae8db2"
      },
      "source": [
        "# ae_laptop_test_df['predictions_3'] = [clean_IOB_result(sample) for sample in format_result]\n",
        "# # chop off any predictions that are longer than the sentence because it's not picking up the padding and class tokens\n",
        "# sentence_len = ae_laptop_test_df['sentence'].apply(len)\n",
        "# ae_laptop_test_df['predictions_3'] = [sample[:sentence_len[ind]] for ind,sample in enumerate(ae_laptop_test_df['predictions_3'])]\n",
        "# # fill in any missing tokens at the end with \"O\"\n",
        "# for idx in range(ae_laptop_test_df.shape[0]):\n",
        "#   pred = ae_laptop_test_df.iloc[idx]['predictions_3']\n",
        "#   sentence = ae_laptop_test_df.iloc[idx]['sentence']\n",
        "#   if len(pred) < len(sentence ):\n",
        "#     pred.extend(['O'] * (len(sentence) - len(pred)))\n",
        "# ae_laptop_test_df.head()"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "      <th>predictions</th>\n",
              "      <th>predictions_1</th>\n",
              "      <th>predictions_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[Boot, time, is, super, fast, ,, around, anywh...</td>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, B, O, O, B, O]</td>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, B, O]</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[tech, support, would, not, fix, the, problem,...</td>\n",
              "      <td>[O, B, O, O, O, O, B, O, O, O, O, B, O, O, O, ...</td>\n",
              "      <td>[O, B, O, O, O, O, B, O, O, O, O, B, O, O, O, ...</td>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, B, O, O, O, O, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[O, O, O, O, O, O, O]</td>\n",
              "      <td>[but, in, resume, this, computer, rocks, !]</td>\n",
              "      <td>[O, O, B, O, B, O, O]</td>\n",
              "      <td>[O, O, B, O, B, O, O]</td>\n",
              "      <td>[B, I, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[B, I, O, O, O]</td>\n",
              "      <td>[Set, up, was, easy, .]</td>\n",
              "      <td>[B, O, O, O, O]</td>\n",
              "      <td>[B, O, O, O, O]</td>\n",
              "      <td>[O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[O, O, O, O, O, B, I, O, B, I, O]</td>\n",
              "      <td>[Did, not, enjoy, the, new, Windows, 8, and, t...</td>\n",
              "      <td>[B, O, O, O, O, B, O, O, O, B, O]</td>\n",
              "      <td>[B, O, O, O, O, B, O, O, O, O, O]</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               label  ...                                      predictions_3\n",
              "0      [B, I, O, O, O, O, O, O, O, O, O, O, O, O, O]  ...      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]\n",
              "1  [B, I, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  ...  [B, I, O, O, O, O, O, O, O, O, B, O, O, O, O, ...\n",
              "2                              [O, O, O, O, O, O, O]  ...                              [B, I, O, O, O, O, O]\n",
              "3                                    [B, I, O, O, O]  ...                                    [O, O, O, O, O]\n",
              "4                  [O, O, O, O, O, B, I, O, B, I, O]  ...                  [O, O, O, O, O, O, O, O, O, O, O]\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1qlE1ppTFok",
        "outputId": "0e89a6ea-a7cf-491c-aca6-880eb0d0bdec"
      },
      "source": [
        "results_flatten = [token for result in format_result for token in result]\n",
        "print(Counter(results_flatten))\n",
        "unf_results_flatten = [token for result in np.argmax(result, axis=2) for token in result]\n",
        "print(Counter(unf_results_flatten))"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'[nerPAD]': 25708, 'O': 11610, '[nerSEP]': 802, '[nerCLS]': 800, 'nerX': 579, 'B': 469, 'I': 32})\n",
            "Counter({4: 25708, 2: 11610, 5: 802, 3: 800, 6: 579, 0: 469, 1: 32})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3WSn8ezWnt1"
      },
      "source": [
        "## AE evaluation - SemEval14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oUpSyKIWnt2"
      },
      "source": [
        "http://www.davidsbatista.net/blog/2018/05/09/Named_Entity_Evaluation/  \n",
        "- partial boundary match over the surface string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVdh5PJIWnt2",
        "outputId": "512ff5c6-7d1c-4c00-e4a0-6c1268df9631"
      },
      "source": [
        "# TODO amend this tree structure for all predictions as well\n",
        "print('\\nGold Standard:')\n",
        "# tag every sentence with the pos\n",
        "gold_tree = ae_laptop_test_df['sentence'].apply(lambda x: nltk.pos_tag(x))\n",
        "print(gold_tree)\n",
        "iob_gold_tree = [nltk.Tree('S',\n",
        "                           [(el[0], el[1], ae_laptop_test_df.iloc[tree_ind]['label'][ind])\n",
        "                            if ae_laptop_test_df.iloc[tree_ind]['label'][ind]=='O'\n",
        "                            else (el[0], el[1], ae_laptop_test_df.iloc[tree_ind]['label'][ind] + '-NP')\n",
        "                            for ind,el in enumerate(tree)])\n",
        "                for tree_ind, tree in enumerate(gold_tree)]\n",
        "ae_laptop_test_df['iob_gold_tree'] = iob_gold_tree\n",
        "ae_laptop_test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Gold Standard:\n",
            "0      [(Boot, NNP), (time, NN), (is, VBZ), (super, J...\n",
            "1      [(tech, JJ), (support, NN), (would, MD), (not,...\n",
            "2      [(but, CC), (in, IN), (resume, NN), (this, DT)...\n",
            "3      [(Set, NNP), (up, RP), (was, VBD), (easy, JJ),...\n",
            "4      [(Did, NNP), (not, RB), (enjoy, VB), (the, DT)...\n",
            "                             ...                        \n",
            "795    [(This, DT), (hardware, NN), (seems, VBZ), (to...\n",
            "796    [(I, PRP), ('m, VBP), (done, VBN), (with, IN),...\n",
            "797    [(I, PRP), ('ve, VBP), (had, VBD), (it, PRP), ...\n",
            "798    [(the, DT), (latest, JJS), (version, NN), (doe...\n",
            "799    [(Screen, NNP), (-, :), (although, IN), (some,...\n",
            "Name: sentence, Length: 800, dtype: object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "      <th>predictions</th>\n",
              "      <th>predictions_1</th>\n",
              "      <th>iob_gold_tree</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[Boot, time, is, super, fast, ,, around, anywh...</td>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, B, O, O, B, O]</td>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, B, O]</td>\n",
              "      <td>[(Boot, NNP, B-NP), (time, NN, I-NP), (is, VBZ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[tech, support, would, not, fix, the, problem,...</td>\n",
              "      <td>[O, B, O, O, O, O, B, O, O, O, O, B, O, O, O, ...</td>\n",
              "      <td>[O, B, O, O, O, O, B, O, O, O, O, B, O, O, O, ...</td>\n",
              "      <td>[(tech, JJ, B-NP), (support, NN, I-NP), (would...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[O, O, O, O, O, O, O]</td>\n",
              "      <td>[but, in, resume, this, computer, rocks, !]</td>\n",
              "      <td>[O, O, B, O, B, O, O]</td>\n",
              "      <td>[O, O, B, O, B, O, O]</td>\n",
              "      <td>[(but, CC, O), (in, IN, O), (resume, NN, O), (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[B, I, O, O, O]</td>\n",
              "      <td>[Set, up, was, easy, .]</td>\n",
              "      <td>[B, O, O, O, O]</td>\n",
              "      <td>[B, O, O, O, O]</td>\n",
              "      <td>[(Set, NNP, B-NP), (up, RP, I-NP), (was, VBD, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[O, O, O, O, O, B, I, O, B, I, O]</td>\n",
              "      <td>[Did, not, enjoy, the, new, Windows, 8, and, t...</td>\n",
              "      <td>[B, O, O, O, O, B, O, O, O, B, O]</td>\n",
              "      <td>[B, O, O, O, O, B, O, O, O, O, O]</td>\n",
              "      <td>[(Did, NNP, O), (not, RB, O), (enjoy, VB, O), ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               label  \\\n",
              "0      [B, I, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
              "1  [B, I, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "2                              [O, O, O, O, O, O, O]   \n",
              "3                                    [B, I, O, O, O]   \n",
              "4                  [O, O, O, O, O, B, I, O, B, I, O]   \n",
              "\n",
              "                                            sentence  \\\n",
              "0  [Boot, time, is, super, fast, ,, around, anywh...   \n",
              "1  [tech, support, would, not, fix, the, problem,...   \n",
              "2        [but, in, resume, this, computer, rocks, !]   \n",
              "3                            [Set, up, was, easy, .]   \n",
              "4  [Did, not, enjoy, the, new, Windows, 8, and, t...   \n",
              "\n",
              "                                         predictions  \\\n",
              "0      [B, I, O, O, O, O, O, O, O, O, B, O, O, B, O]   \n",
              "1  [O, B, O, O, O, O, B, O, O, O, O, B, O, O, O, ...   \n",
              "2                              [O, O, B, O, B, O, O]   \n",
              "3                                    [B, O, O, O, O]   \n",
              "4                  [B, O, O, O, O, B, O, O, O, B, O]   \n",
              "\n",
              "                                       predictions_1  \\\n",
              "0      [B, I, O, O, O, O, O, O, O, O, O, O, O, B, O]   \n",
              "1  [O, B, O, O, O, O, B, O, O, O, O, B, O, O, O, ...   \n",
              "2                              [O, O, B, O, B, O, O]   \n",
              "3                                    [B, O, O, O, O]   \n",
              "4                  [B, O, O, O, O, B, O, O, O, O, O]   \n",
              "\n",
              "                                       iob_gold_tree  \n",
              "0  [(Boot, NNP, B-NP), (time, NN, I-NP), (is, VBZ...  \n",
              "1  [(tech, JJ, B-NP), (support, NN, I-NP), (would...  \n",
              "2  [(but, CC, O), (in, IN, O), (resume, NN, O), (...  \n",
              "3  [(Set, NNP, B-NP), (up, RP, I-NP), (was, VBD, ...  \n",
              "4  [(Did, NNP, O), (not, RB, O), (enjoy, VB, O), ...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkm4xxALWnt2"
      },
      "source": [
        "def get_entities(sentence_lst, predictions_lst):\n",
        "    \"\"\"\n",
        "    Reformat the IOB structure to get the actual entities from the sentence\n",
        "    \"\"\"\n",
        "    \n",
        "    # for every sentence, iterate through\n",
        "    all_entities = []\n",
        "    for sample in range(len(predictions_lst)):\n",
        "    \n",
        "        # chop off the last words because we max out at 50 for BERT\n",
        "    \n",
        "        # get indices where entities are identified\n",
        "        predictions = np.array(predictions_lst[sample])\n",
        "        # predictions = predictions[:50]\n",
        "        ind = (predictions == 'B') | (predictions == 'I')\n",
        "        \n",
        "        # create list of numerical indices and boolean indices. ex. [(4, True), (10, True), (11, True), (15, True)]\n",
        "        ind_tuple = [num_ind for num_ind in list(enumerate(ind)) if num_ind[1]==True]\n",
        "        \n",
        "        # get the sentence of interest. identify what these entities are\n",
        "        sentence = np.array(sentence_lst[sample])\n",
        "        # sentence = sentence[:50]\n",
        "\n",
        "        # group the phrases together\n",
        "        entities = []\n",
        "        for subset,num_ind_tuple in zip(sentence[ind], ind_tuple): # [('price', (4, True)), ('netbook', (10, True)), ('*', (11, True)), ('machine', (15, True))]\n",
        "            # put the B in entities\n",
        "            if predictions[num_ind_tuple[0]][0] == 'B':\n",
        "                entities.append([subset])\n",
        "            # if the tag is I and it should have been a B. Fix in post processing.\n",
        "            elif (predictions[num_ind_tuple[0]][0] == 'I') & (len(entities)==0):\n",
        "                entities.append([subset])\n",
        "            # if the tag is I, add to the last item of the list\n",
        "            elif predictions[num_ind_tuple[0]][0] == 'I':\n",
        "                last_entry = entities.pop()\n",
        "                last_entry.append(subset)\n",
        "                entities.append(last_entry)\n",
        "            # there should not be any 'O' indices here\n",
        "            else:\n",
        "                print('Error')\n",
        "        all_entities.append(entities)\n",
        "    return(all_entities)"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqn3euJ0yvvo"
      },
      "source": [
        "# define how to get entities for BERT\n",
        "nerLabels_test\n"
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUvVcUdsWnt3"
      },
      "source": [
        "def get_ae_eval_features(gold_entities,prediction_entities,verbose=False):\n",
        "    # TODO may later need to update these calculations to encompass sentence location.\n",
        "    y_true_df = pd.DataFrame([[ind,sub_el] for ind,el in enumerate(gold_entities) for sub_el in el], columns=['sample_index','entity'])\n",
        "    y_pred_df = pd.DataFrame([[ind,sub_el] for ind,el in enumerate(prediction_entities) for sub_el in el], columns=['sample_index','entity'])\n",
        "    print('True')\n",
        "    display(y_true_df.head())\n",
        "    print('Pred')\n",
        "    display(y_pred_df.head())\n",
        "\n",
        "    cor = 0\n",
        "    inc = 0\n",
        "    par = 0\n",
        "    mis = 0\n",
        "    spu = 0\n",
        "\n",
        "    for el in range(len(gold_entities)):\n",
        "        if verbose:\n",
        "            print('\\n',el)\n",
        "        true_subset = y_true_df[y_true_df.sample_index == el]\n",
        "        pred_subset = y_pred_df[y_pred_df.sample_index == el]\n",
        "        true_entities = set(true_subset.entity.apply(lambda x: '_'.join(x)))\n",
        "        pred_entities = set(pred_subset.entity.apply(lambda x: '_'.join(x)))\n",
        "        if verbose:\n",
        "            print('True')\n",
        "            print(true_entities)\n",
        "            print('Pred')\n",
        "            print(pred_entities)\n",
        "\n",
        "        # get correct\n",
        "        cor_entities = true_entities & pred_entities\n",
        "        if verbose:\n",
        "            print(f'Correct entities: {cor_entities}')\n",
        "        cor += len(cor_entities)\n",
        "        true_entities = true_entities - cor_entities\n",
        "        pred_entities = pred_entities - cor_entities\n",
        "\n",
        "        # get partial and missed\n",
        "        for true in true_entities:\n",
        "            # Take into account if the prediction contains a portion of the correct and if correct contains a portion of the prediction\n",
        "            par_entities = set([pred for pred in pred_entities if (true in pred) | (pred in true)])\n",
        "            if len(par_entities) != 0:\n",
        "                if verbose:\n",
        "                    print(f'Partial entities: {set([true])}')\n",
        "                par += len(par_entities)\n",
        "                true_entities = true_entities - set([true])\n",
        "                pred_entities = pred_entities - par_entities\n",
        "            else:\n",
        "                if verbose:\n",
        "                    print(f'Missed entities: {set([true])}')\n",
        "                mis += 1\n",
        "                true_entities = true_entities - set([true])\n",
        "\n",
        "        if len(true_entities) == 0:\n",
        "            if verbose:\n",
        "                print(f'Spurious entities: {pred_entities}')\n",
        "            spu += len(pred_entities)\n",
        "        else:\n",
        "            print('Error')\n",
        "\n",
        "    print(f'\\nCorrect: {cor}')\n",
        "    print(f'Partial: {par}')\n",
        "    print(f'Missed: {mis}')\n",
        "    print(f'Spurious: {spu}')\n",
        "    return(cor,par,mis,spu,inc)"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ymn3-R9bWnt3"
      },
      "source": [
        "def get_ae_eval(sentence_lst, y_true, y_pred,bert= False, verbose=False):\n",
        "    \"\"\"\n",
        "    Get entity recognition evaluations accoridng to the partial match SemEval strategy\n",
        "    \"\"\"\n",
        "    if bert:\n",
        "      gold_entities = bert_entities(format_sent,format_label)\n",
        "      prediction_entities = bert_entities(format_sent,format_result)\n",
        "    else:\n",
        "      prediction_entities = get_entities(sentence_lst,y_pred)\n",
        "      gold_entities = get_entities(sentence_lst,y_true)\n",
        "    \n",
        "    cor,par,mis,spu,inc = get_ae_eval_features(gold_entities,prediction_entities,verbose=verbose)\n",
        "    \n",
        "    pos_eval = cor + inc + par + mis\n",
        "    act_eval = cor + inc + par + spu\n",
        "\n",
        "    precision = (cor + .5 * par) / act_eval\n",
        "    recall = (cor + .5 * par) / pos_eval\n",
        "    f1 = ( 2* precision * recall) / (precision + recall)\n",
        "    \n",
        "    print(f'\\nPrecision: \\t{precision}')\n",
        "    print(f'Recall: \\t{recall}')\n",
        "    print(f'F1-Score: \\t{f1}')\n",
        "    return(precision, recall, f1)"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "V5d6hvLJWnt4",
        "outputId": "a0e0192e-9fee-4aeb-aa3b-1f0751c0ad3f"
      },
      "source": [
        "get_ae_eval(ae_laptop_test_df.sentence,ae_laptop_test_df.label,ae_laptop_test_df.predictions_1)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>entity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[Boot, time]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[tech, support]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[Set, up]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>[Windows, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[touchscreen, functions]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sample_index                    entity\n",
              "0             0              [Boot, time]\n",
              "1             1           [tech, support]\n",
              "2             3                 [Set, up]\n",
              "3             4              [Windows, 8]\n",
              "4             4  [touchscreen, functions]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Pred\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>entity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[Boot, time]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>[minute]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>[support]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>[problem]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>[plan]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sample_index        entity\n",
              "0             0  [Boot, time]\n",
              "1             0      [minute]\n",
              "2             1     [support]\n",
              "3             1     [problem]\n",
              "4             1        [plan]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Correct: 326\n",
            "Partial: 220\n",
            "Missed: 142\n",
            "Spurious: 1092\n",
            "\n",
            "Precision: \t0.2661782661782662\n",
            "Recall: \t0.6337209302325582\n",
            "F1-Score: \t0.3748925193465176\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.2661782661782662, 0.6337209302325582, 0.3748925193465176)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "dfy0G2dJVFot",
        "outputId": "1053848c-2662-46a0-cb77-e20e6028d0da"
      },
      "source": [
        "get_ae_eval(format_sent,format_label,format_result)"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>entity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[boot, time]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>[tech, support]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>[set, up]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>[windows, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>[touch, functions]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sample_index              entity\n",
              "0             1        [boot, time]\n",
              "1             2     [tech, support]\n",
              "2             4           [set, up]\n",
              "3             5        [windows, 8]\n",
              "4             5  [touch, functions]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Pred\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_index</th>\n",
              "      <th>entity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[boot, time]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>[tech, support]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>[set, up]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>[windows, 8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>[touch, functions]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sample_index              entity\n",
              "0             1        [boot, time]\n",
              "1             2     [tech, support]\n",
              "2             4           [set, up]\n",
              "3             5        [windows, 8]\n",
              "4             5  [touch, functions]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Correct: 502\n",
            "Partial: 104\n",
            "Missed: 65\n",
            "Spurious: 66\n",
            "\n",
            "Precision: \t0.8244047619047619\n",
            "Recall: \t0.8256333830104322\n",
            "F1-Score: \t0.8250186150409531\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8244047619047619, 0.8256333830104322, 0.8250186150409531)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zthVMA6fWnt4"
      },
      "source": [
        "## AE evaluation - Token Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJtZqb4tWnt4",
        "outputId": "0f6cff77-d5d3-4468-829d-78a5d6cc5878"
      },
      "source": [
        "def get_accuracy(true,predictions):\n",
        "    accuracy = []\n",
        "    for true_el, predict_el in zip(true,predictions):\n",
        "        accuracy.append((np.array(predict_el) == np.array(true_el)).sum() / (len(true_el)))\n",
        "    return(accuracy)\n",
        "\n",
        "ae_laptop_test_df['accuracy'] = get_accuracy(ae_laptop_test_df.label,ae_laptop_test_df.predictions)\n",
        "ae_laptop_test_df['accuracy_1'] = get_accuracy(ae_laptop_test_df.label,ae_laptop_test_df.predictions_1)\n",
        "ae_laptop_test_df.head()\n",
        "ae_laptop_test_df[['accuracy','accuracy_1']].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "      <th>predictions</th>\n",
              "      <th>predictions_1</th>\n",
              "      <th>iob_gold_tree</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>accuracy_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[Boot, time, is, super, fast, ,, around, anywh...</td>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, B, O, O, B, O]</td>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, B, O]</td>\n",
              "      <td>[(Boot, NNP, B-NP), (time, NN, I-NP), (is, VBZ...</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.933333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[B, I, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
              "      <td>[tech, support, would, not, fix, the, problem,...</td>\n",
              "      <td>[O, B, O, O, O, O, B, O, O, O, O, B, O, O, O, ...</td>\n",
              "      <td>[O, B, O, O, O, O, B, O, O, O, O, B, O, O, O, ...</td>\n",
              "      <td>[(tech, JJ, B-NP), (support, NN, I-NP), (would...</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.764706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[O, O, O, O, O, O, O]</td>\n",
              "      <td>[but, in, resume, this, computer, rocks, !]</td>\n",
              "      <td>[O, O, B, O, B, O, O]</td>\n",
              "      <td>[O, O, B, O, B, O, O]</td>\n",
              "      <td>[(but, CC, O), (in, IN, O), (resume, NN, O), (...</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[B, I, O, O, O]</td>\n",
              "      <td>[Set, up, was, easy, .]</td>\n",
              "      <td>[B, O, O, O, O]</td>\n",
              "      <td>[B, O, O, O, O]</td>\n",
              "      <td>[(Set, NNP, B-NP), (up, RP, I-NP), (was, VBD, ...</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[O, O, O, O, O, B, I, O, B, I, O]</td>\n",
              "      <td>[Did, not, enjoy, the, new, Windows, 8, and, t...</td>\n",
              "      <td>[B, O, O, O, O, B, O, O, O, B, O]</td>\n",
              "      <td>[B, O, O, O, O, B, O, O, O, O, O]</td>\n",
              "      <td>[(Did, NNP, O), (not, RB, O), (enjoy, VB, O), ...</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.636364</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               label  \\\n",
              "0      [B, I, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
              "1  [B, I, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
              "2                              [O, O, O, O, O, O, O]   \n",
              "3                                    [B, I, O, O, O]   \n",
              "4                  [O, O, O, O, O, B, I, O, B, I, O]   \n",
              "\n",
              "                                            sentence  \\\n",
              "0  [Boot, time, is, super, fast, ,, around, anywh...   \n",
              "1  [tech, support, would, not, fix, the, problem,...   \n",
              "2        [but, in, resume, this, computer, rocks, !]   \n",
              "3                            [Set, up, was, easy, .]   \n",
              "4  [Did, not, enjoy, the, new, Windows, 8, and, t...   \n",
              "\n",
              "                                         predictions  \\\n",
              "0      [B, I, O, O, O, O, O, O, O, O, B, O, O, B, O]   \n",
              "1  [O, B, O, O, O, O, B, O, O, O, O, B, O, O, O, ...   \n",
              "2                              [O, O, B, O, B, O, O]   \n",
              "3                                    [B, O, O, O, O]   \n",
              "4                  [B, O, O, O, O, B, O, O, O, B, O]   \n",
              "\n",
              "                                       predictions_1  \\\n",
              "0      [B, I, O, O, O, O, O, O, O, O, O, O, O, B, O]   \n",
              "1  [O, B, O, O, O, O, B, O, O, O, O, B, O, O, O, ...   \n",
              "2                              [O, O, B, O, B, O, O]   \n",
              "3                                    [B, O, O, O, O]   \n",
              "4                  [B, O, O, O, O, B, O, O, O, O, O]   \n",
              "\n",
              "                                       iob_gold_tree  accuracy  accuracy_1  \n",
              "0  [(Boot, NNP, B-NP), (time, NN, I-NP), (is, VBZ...  0.866667    0.933333  \n",
              "1  [(tech, JJ, B-NP), (support, NN, I-NP), (would...  0.764706    0.764706  \n",
              "2  [(but, CC, O), (in, IN, O), (resume, NN, O), (...  0.714286    0.714286  \n",
              "3  [(Set, NNP, B-NP), (up, RP, I-NP), (was, VBD, ...  0.800000    0.800000  \n",
              "4  [(Did, NNP, O), (not, RB, O), (enjoy, VB, O), ...  0.636364    0.636364  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>accuracy_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>800.000000</td>\n",
              "      <td>800.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.827023</td>\n",
              "      <td>0.831191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.117612</td>\n",
              "      <td>0.127836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.756466</td>\n",
              "      <td>0.760000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.846154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.916667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         accuracy  accuracy_1\n",
              "count  800.000000  800.000000\n",
              "mean     0.827023    0.831191\n",
              "std      0.117612    0.127836\n",
              "min      0.200000    0.200000\n",
              "25%      0.756466    0.760000\n",
              "50%      0.833333    0.846154\n",
              "75%      0.909091    0.916667\n",
              "max      1.000000    1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMRpIoy_Wnt5"
      },
      "source": [
        "## Export samples that are well / poorly extracted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StYPgLaaWnt5",
        "outputId": "76679c31-fe48-4198-c9cf-a25a9afe2bdb"
      },
      "source": [
        "def get_bad_examples(n = 1):\n",
        "    ind = np.argpartition(ae_laptop_test_df.accuracy + ae_laptop_test_df.accuracy_1,n)[:n]\n",
        "    print(ind)\n",
        "    sort_ind = ind[np.argsort((ae_laptop_test_df.accuracy + ae_laptop_test_df.accuracy_1).iloc[ind])]\n",
        "    bad_example = ae_laptop_test_df.iloc[sort_ind]\n",
        "    \n",
        "    display(bad_example)\n",
        "    print(*[' '.join(sent) for sent in bad_example.sentence],sep='\\n')\n",
        "    \n",
        "get_bad_examples(3)\n",
        "\n",
        "def get_good_examples(n = 1):\n",
        "    ind = np.argpartition(ae_laptop_test_df.accuracy + ae_laptop_test_df.accuracy_1,-n)[-n:]\n",
        "    print(ind)\n",
        "    sort_ind = ind[np.argsort((ae_laptop_test_df.accuracy + ae_laptop_test_df.accuracy_1).iloc[ind])]\n",
        "    good_example = ae_laptop_test_df.iloc[sort_ind]\n",
        "    \n",
        "    display(good_example)\n",
        "    print(*[' '.join(sent) for sent in good_example.sentence],sep='\\n')\n",
        "# good_example = ae_laptop_test_df.iloc[np.argmax(ae_laptop_test_df.accuracy + ae_laptop_test_df.accuracy_1)]\n",
        "get_good_examples(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    165\n",
            "1    532\n",
            "2    632\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "      <th>predictions</th>\n",
              "      <th>predictions_1</th>\n",
              "      <th>iob_gold_tree</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>accuracy_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>[O, O, O, O, O]</td>\n",
              "      <td>[HUGE, Apple, MAC, Fan, !]</td>\n",
              "      <td>[B, I, I, I, O]</td>\n",
              "      <td>[B, I, I, I, O]</td>\n",
              "      <td>[(HUGE, NNP, O), (Apple, NNP, O), (MAC, NNP, O...</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[i, FINALLY, DID, IT, AND, THIS, MACHINE, IS, ...</td>\n",
              "      <td>[B, I, I, I, I, I, I, O, O, B, I, I, O]</td>\n",
              "      <td>[B, O, B, I, I, I, I, O, O, B, I, I, O]</td>\n",
              "      <td>[(i, NN, O), (FINALLY, NNPS, O), (DID, NNP, O)...</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.307692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>632</th>\n",
              "      <td>[O, B, O]</td>\n",
              "      <td>[Nice, packing, .]</td>\n",
              "      <td>[B, I, O]</td>\n",
              "      <td>[B, I, O]</td>\n",
              "      <td>[(Nice, NNP, O), (packing, NN, B-NP), (., ., O)]</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       label  \\\n",
              "165                          [O, O, O, O, O]   \n",
              "532  [O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
              "632                                [O, B, O]   \n",
              "\n",
              "                                              sentence  \\\n",
              "165                         [HUGE, Apple, MAC, Fan, !]   \n",
              "532  [i, FINALLY, DID, IT, AND, THIS, MACHINE, IS, ...   \n",
              "632                                 [Nice, packing, .]   \n",
              "\n",
              "                                 predictions  \\\n",
              "165                          [B, I, I, I, O]   \n",
              "532  [B, I, I, I, I, I, I, O, O, B, I, I, O]   \n",
              "632                                [B, I, O]   \n",
              "\n",
              "                               predictions_1  \\\n",
              "165                          [B, I, I, I, O]   \n",
              "532  [B, O, B, I, I, I, I, O, O, B, I, I, O]   \n",
              "632                                [B, I, O]   \n",
              "\n",
              "                                         iob_gold_tree  accuracy  accuracy_1  \n",
              "165  [(HUGE, NNP, O), (Apple, NNP, O), (MAC, NNP, O...  0.200000    0.200000  \n",
              "532  [(i, NN, O), (FINALLY, NNPS, O), (DID, NNP, O)...  0.230769    0.307692  \n",
              "632   [(Nice, NNP, O), (packing, NN, B-NP), (., ., O)]  0.333333    0.333333  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "HUGE Apple MAC Fan !\n",
            "i FINALLY DID IT AND THIS MACHINE IS THE WAY TO GO !\n",
            "Nice packing .\n",
            "797    346\n",
            "798    354\n",
            "799    321\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "      <th>predictions</th>\n",
              "      <th>predictions_1</th>\n",
              "      <th>iob_gold_tree</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>accuracy_1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>[O, O, B, O, B, O, B, O, B, I, O]</td>\n",
              "      <td>[!, Excelent, performance, ,, usability, ,, pr...</td>\n",
              "      <td>[O, O, B, O, B, O, B, O, B, I, O]</td>\n",
              "      <td>[O, O, B, O, B, O, B, O, B, I, O]</td>\n",
              "      <td>[(!, ., O), (Excelent, JJ, O), (performance, N...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>[O, O, O, B, I, O]</td>\n",
              "      <td>[I, love, the, form, factor, .]</td>\n",
              "      <td>[O, O, O, B, I, O]</td>\n",
              "      <td>[O, O, O, B, I, O]</td>\n",
              "      <td>[(I, PRP, O), (love, VBP, O), (the, DT, O), (f...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>[O, B, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[The, memory, was, gone, and, it, was, not, ab...</td>\n",
              "      <td>[O, B, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[O, B, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[(The, DT, O), (memory, NN, B-NP), (was, VBD, ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       label  \\\n",
              "346        [O, O, B, O, B, O, B, O, B, I, O]   \n",
              "354                       [O, O, O, B, I, O]   \n",
              "321  [O, B, O, O, O, O, O, O, O, O, O, O, O]   \n",
              "\n",
              "                                              sentence  \\\n",
              "346  [!, Excelent, performance, ,, usability, ,, pr...   \n",
              "354                    [I, love, the, form, factor, .]   \n",
              "321  [The, memory, was, gone, and, it, was, not, ab...   \n",
              "\n",
              "                                 predictions  \\\n",
              "346        [O, O, B, O, B, O, B, O, B, I, O]   \n",
              "354                       [O, O, O, B, I, O]   \n",
              "321  [O, B, O, O, O, O, O, O, O, O, O, O, O]   \n",
              "\n",
              "                               predictions_1  \\\n",
              "346        [O, O, B, O, B, O, B, O, B, I, O]   \n",
              "354                       [O, O, O, B, I, O]   \n",
              "321  [O, B, O, O, O, O, O, O, O, O, O, O, O]   \n",
              "\n",
              "                                         iob_gold_tree  accuracy  accuracy_1  \n",
              "346  [(!, ., O), (Excelent, JJ, O), (performance, N...       1.0         1.0  \n",
              "354  [(I, PRP, O), (love, VBP, O), (the, DT, O), (f...       1.0         1.0  \n",
              "321  [(The, DT, O), (memory, NN, B-NP), (was, VBD, ...       1.0         1.0  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "! Excelent performance , usability , presentation and time response .\n",
            "I love the form factor .\n",
            "The memory was gone and it was not able to be used .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3IcQNMOFV7m"
      },
      "source": [
        "# ASC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAZCXRYCWnt5"
      },
      "source": [
        "## ASC baseline - VADER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvrLoEZSWnt6",
        "outputId": "502aa388-8eaa-47b5-e2b4-d844d27d412e"
      },
      "source": [
        "def vader_asc(sentence_lst):\n",
        "    \"\"\"\n",
        "    For every sentence in the list, tag it as a positive/negative sentiment based on the sum of the words.\n",
        "    \"\"\"\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    pos_neg_tag_lst = []\n",
        "    for ind,sentence in enumerate(sentence_lst):\n",
        "        vs = analyzer.polarity_scores(sentence)\n",
        "        pos_neg_tag = 'negative' if vs['compound'] <= -0.05 else 'positive' if vs['compound'] >= 0.05 else 'neutral' \n",
        "        # print first 10 examples\n",
        "        if ind <10: print(\"{:-<65} {} ({})\".format(sentence, str(vs['compound']),pos_neg_tag))\n",
        "        pos_neg_tag_lst.append(pos_neg_tag)\n",
        "    return(pos_neg_tag_lst)\n",
        "\n",
        "asc_laptop_test_df['predictions'] = vader_asc(asc_laptop_test_df.sentence)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the retina display display make pictures i took years ago jaw dropping. 0.0 (neutral)\n",
            "Needs a CD/DVD drive and a bigger power switch.------------------ 0.0 (neutral)\n",
            "Needs a CD/DVD drive and a bigger power switch.------------------ 0.0 (neutral)\n",
            "The battery is not as shown in the product photos.--------------- 0.0 (neutral)\n",
            "It feels cheap, the keyboard is not very sensitive.-------------- 0.0 (neutral)\n",
            "Shipping was quick and product described was the product sent and so much more... 0.0 (neutral)\n",
            "I've had it for about 2 months now and found no issues with software or updates. -0.296 (negative)\n",
            "The only thing I miss is that my old Alienware laptop had backlit keys. -0.1531 (negative)\n",
            "Unfortunately, it runs XP and Microsoft is dropping support next April. 0.5622 (positive)\n",
            "Unfortunately, it runs XP and Microsoft is dropping support next April. 0.5622 (positive)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8mN94KbWnt6"
      },
      "source": [
        "## ASC BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "a35855c7b19c4bbda0e75eac4ee79135",
            "141028fbb0bd46f1b872362e6ba31cff",
            "ec5320a3c9284ef197d8beda2a4d2282",
            "e6fd3f1f25c647a3a971448d8d1ffe38",
            "19755be40d454987a08cd7c22cdf4617",
            "f732c2914976420986d1550b894273a6",
            "1c3367d1e13d488db50952799dbd16f5",
            "f27214776f3e4c0db147ad5b36dd4d14",
            "b11e7e2fb006449ea8a4777e5d65f3de",
            "cee9adc149944d1b9a7c0c5c77fa63ed",
            "924ad2867cfb4141b9c623d8b2a1730c",
            "d34346618fe648fc81729e5ecd6613c4",
            "5d47e578180e467fa1b5514cb42d7da1",
            "53b27ac21cd14611bf07704ae13783d9",
            "55e6ef319c1242d79ef972e415e5932f",
            "6b142987d92e4393a580da4e0972195a",
            "62190c66b70d42da92492402e1b8d69f",
            "8eb1e2a6bafc4085ba34b06c3e446b0f",
            "1929f2e62c084b218a5e5ae845541717",
            "0ae8fb4122de46dc8d7c96050dff0114",
            "b665757b4b1d478683168fa77e28cc1f",
            "a0b5c0933fbc453b80d613da69797304",
            "e5e9766a8bff49cb9e993e65f3c3b7e8",
            "482a7c439f224dfcaea2cd1fb328918a"
          ]
        },
        "id": "ZkyDDBpuWnt6",
        "outputId": "cd2a088c-2e41-4723-9df2-b16b9f779a1e"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a35855c7b19c4bbda0e75eac4ee79135",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b11e7e2fb006449ea8a4777e5d65f3de",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62190c66b70d42da92492402e1b8d69f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j6iV4kcWnt6",
        "outputId": "0845af41-22ff-4787-8348-3e28b3d13c24"
      },
      "source": [
        "batch_sentences = [val['sentence'] for key, val in asc_laptop_train.items()]*5\n",
        "batch_sentences.extend([val['sentence'] for key, val in asc_laptop_dev.items()])\n",
        "batch_sentences.extend([val['sentence'] for key, val in asc_laptop_test.items()])\n",
        "train_size = len(asc_laptop_train)*5\n",
        "dev_size = len(asc_laptop_dev)\n",
        "test_size = len(asc_laptop_test)\n",
        "print(train_size)\n",
        "print(dev_size)\n",
        "print(test_size)\n",
        "print(train_size+dev_size+test_size)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10815\n",
            "150\n",
            "638\n",
            "11603\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aWtQbFXabzz",
        "outputId": "204d9c5f-4055-4802-dfb2-8cf40cfc89b7"
      },
      "source": [
        "batch_terms = [val['term'] for key, val in asc_laptop_train.items()]*5\n",
        "batch_terms.extend([val['term'] for key, val in asc_laptop_dev.items()])\n",
        "batch_terms.extend([val['term'] for key, val in asc_laptop_test.items()])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['use', 'noise', 'force', 'expense', 'word processor']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlBImJOxWnt7"
      },
      "source": [
        "batch_label = [val['polarity'] for key, val in asc_laptop_train.items()]*5\n",
        "batch_label.extend([val['polarity'] for key, val in asc_laptop_dev.items()])\n",
        "batch_label.extend([val['polarity'] for key, val in asc_laptop_test.items()])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmPqP9c9Wnt7"
      },
      "source": [
        "max_length=50\n",
        "bert_inputs = tokenizer(batch_terms, batch_sentences, padding=True, truncation=True, max_length=max_length, return_tensors=\"tf\")"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9AX8exyWnt7",
        "outputId": "e3f4f4f9-1e9f-4282-9503-d597f49453d0"
      },
      "source": [
        "label_encoder = LabelEncoder().fit(batch_label)\n",
        "ascLabels = label_encoder.transform(batch_label)\n",
        "label_encoder.classes_\n",
        "batch_label[:5]\n",
        "ascLabels[:5]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['negative', 'neutral', 'positive'], dtype='<U8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['positive', 'positive', 'positive', 'negative', 'negative']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHwpY8UVWnt7",
        "outputId": "32733eb8-a682-473e-9ba0-208d8e18f847"
      },
      "source": [
        "bert_inputs"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(11603, 50), dtype=int32, numpy=\n",
              "array([[  101,  2224,   102, ...,     0,     0,     0],\n",
              "       [  101,  5005,   102, ...,     0,     0,     0],\n",
              "       [  101,  2486,   102, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  101,  3645,  1022, ...,     0,     0,     0],\n",
              "       [  101, 14743,   102, ...,     0,     0,     0],\n",
              "       [  101, 10453,   102, ...,     0,     0,     0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(11603, 50), dtype=int32, numpy=\n",
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(11603, 50), dtype=int32, numpy=\n",
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOV50s0MWnt7"
      },
      "source": [
        "trainSentence_ids = bert_inputs['input_ids'][:train_size]\n",
        "trainMasks = bert_inputs['attention_mask'][:train_size]\n",
        "trainSequence_ids = bert_inputs['token_type_ids'][:train_size]\n",
        "\n",
        "devSentence_ids = bert_inputs['input_ids'][train_size:train_size+dev_size]\n",
        "devMasks = bert_inputs['attention_mask'][train_size:train_size+dev_size]\n",
        "devSequence_ids = bert_inputs['token_type_ids'][train_size:train_size+dev_size]\n",
        "\n",
        "testSentence_ids = bert_inputs['input_ids'][train_size+dev_size:]\n",
        "testMasks = bert_inputs['attention_mask'][train_size+dev_size:]\n",
        "testSequence_ids = bert_inputs['token_type_ids'][train_size+dev_size:]\n",
        "\n",
        "ascLabels_train = ascLabels[:train_size]\n",
        "ascLabels_dev = ascLabels[train_size:train_size+dev_size]\n",
        "ascLabels_test = ascLabels[train_size+dev_size:]\n",
        "\n",
        "X_train = np.array([trainSentence_ids,trainMasks,trainSequence_ids])\n",
        "X_dev = np.array([devSentence_ids,devMasks,devSequence_ids])\n",
        "X_test = np.array([testSentence_ids,testMasks,testSequence_ids])\n",
        "\n",
        "ascLabels_train = np.array(ascLabels_train)\n",
        "ascLabels_dev = np.array(ascLabels_dev)\n",
        "ascLabels_test = np.array(ascLabels_test)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXYhK2wlWnt8"
      },
      "source": [
        "# Use a parameter pair k_start, k_end to look at slices. This helps with quick tests.\n",
        "\n",
        "k_start = 0\n",
        "k_end = -1\n",
        "\n",
        "if k_end == -1:\n",
        "    k_end_train = X_train[0].shape[0]\n",
        "    k_end_dev = X_dev[0].shape[0]\n",
        "    k_end_test = X_test[0].shape[0]\n",
        "else:\n",
        "    k_end_train = k_end_test = k_end_dev = k_end\n",
        "    \n",
        "\n",
        "\n",
        "bert_inputs_train_k = [X_train[0][k_start:k_end_train], X_train[1][k_start:k_end_train], \n",
        "                       X_train[2][k_start:k_end_train]]\n",
        "bert_inputs_dev_k = [X_dev[0][k_start:k_end_dev], X_dev[1][k_start:k_end_dev], \n",
        "                      X_dev[2][k_start:k_end_dev]]\n",
        "bert_inputs_test_k = [X_test[0][k_start:k_end_test], X_test[1][k_start:k_end_test], \n",
        "                      X_test[2][k_start:k_end_test]]\n",
        "\n",
        "\n",
        "labels_train_k = ascLabels_train[k_start:k_end_train]\n",
        "labels_dev_k = ascLabels_dev[k_start:k_end_dev]\n",
        "labels_test_k = ascLabels_test[k_start:k_end_test]"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRaDGyyxWnt8"
      },
      "source": [
        "train_all = [bert_inputs_train_k, labels_train_k]\n",
        "dev_all = [bert_inputs_dev_k, labels_dev_k]\n",
        "test_all = [bert_inputs_test_k, labels_test_k]"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfX-A2qAoULl"
      },
      "source": [
        "def custom_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    calculate loss function explicitly, filtering out 'extra inserted labels'\n",
        "    \n",
        "    y_true: Shape: (batch x (max_length + 1) )\n",
        "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
        "    \n",
        "    returns:  cost\n",
        "    \"\"\"\n",
        "\n",
        "    #get labels and predictions\n",
        "    \n",
        "    y_label = tf.reshape(Flatten()(tf.cast(y_true, tf.int32)),[-1])\n",
        "    \n",
        "    mask = (y_label == y_label)   # This mask is used to remove all tokens that do not correspond to the original base text.\n",
        "\n",
        "    y_label_masked = tf.boolean_mask(y_label, mask)  # mask the labels\n",
        "    \n",
        "    y_flat_pred = tf.reshape(Flatten()(tf.cast(y_pred, tf.float32)),[-1, 3])\n",
        "    \n",
        "    y_flat_pred_masked = tf.boolean_mask(y_flat_pred, mask) # mask the predictions\n",
        "    \n",
        "    return tf.reduce_mean(sparse_categorical_crossentropy(y_label_masked, y_flat_pred_masked,from_logits=False ))\n"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEnTY7l8etsj"
      },
      "source": [
        "def asc_model(max_input_length, train_layers, optimizer):\n",
        "    global bert_sequence\n",
        "    \"\"\"\n",
        "    Implementation of ASC model\n",
        "    \n",
        "    variables:\n",
        "        max_input_length: number of tokens (max_length + 1)\n",
        "        train_layers: number of layers to be retrained\n",
        "        optimizer: optimizer to be used\n",
        "    \n",
        "    returns: model\n",
        "    \"\"\"\n",
        "    \n",
        "    in_id = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_ids\")\n",
        "    in_mask = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_masks\")\n",
        "    in_segment = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"segment_ids\")\n",
        "    \n",
        "    \n",
        "    bert_inputs = [in_id, in_mask, in_segment]\n",
        "    \n",
        "    \n",
        "    \n",
        "    # Note: Bert layer from Hugging Face returns two values: sequence ouput, and pooled output. Here, we only want\n",
        "    # the former. (See https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel) \n",
        "    \n",
        "    bert_layer = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "    \n",
        "    # Freeze layers, i.e. only train number of layers specified, starting from the top\n",
        "    \n",
        "    if not train_layers == -1:\n",
        "        \n",
        "        retrain_layers = []\n",
        "    \n",
        "        for retrain_layer_number in range(train_layers):\n",
        "\n",
        "            layer_code = '_' + str(11 - retrain_layer_number)\n",
        "            retrain_layers.append(layer_code)\n",
        "\n",
        "        for w in bert_layer.weights:\n",
        "            if not any([x in w.name for x in retrain_layers]):\n",
        "                w._trainable = False\n",
        "\n",
        "        # End of freezing section\n",
        "    \n",
        "    bert_sequence = bert_layer(bert_inputs)[1] # take the pooled output here\n",
        "    \n",
        "    print('Let us check the shape of the BERT layer output:', bert_sequence)\n",
        "    \n",
        "    dense = tf.keras.layers.Dense(512, activation='relu', name='dense')(bert_sequence)\n",
        "    \n",
        "    dense = tf.keras.layers.Dropout(rate=0.1)(dense)\n",
        "\n",
        "    pred = tf.keras.layers.Dense(3, activation='softmax', name='asc')(dense)\n",
        "     \n",
        "    print('pred: ', pred)\n",
        "    \n",
        "    loss = custom_loss\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
        "\n",
        "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
        "    \n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkThK23UWnt8",
        "outputId": "74ae050d-dcd4-4b7e-bd24-1b26b318dedc"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "model = asc_model(max_length+1,train_layers=-1, optimizer=optimizer)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "model.fit(bert_inputs_train_k,labels_train_k ,validation_data=(bert_inputs_dev_k, labels_dev_k), epochs=5, batch_size=16)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Let us check the shape of the BERT layer output: KerasTensor(type_spec=TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), name='tf_bert_model/bert/pooler/dense/Tanh:0', description=\"created by layer 'tf_bert_model'\")\n",
            "pred:  KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name=None), name='asc/Softmax:0', description=\"created by layer 'asc'\")\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_ids[0][0]                  \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          393728      tf_bert_model[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 512)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "asc (Dense)                     (None, 3)            1539        dropout_37[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 109,877,507\n",
            "Trainable params: 109,877,507\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "676/676 [==============================] - 137s 183ms/step - loss: 0.6497 - accuracy: 0.7265 - val_loss: 0.8547 - val_accuracy: 0.7467\n",
            "Epoch 2/5\n",
            "676/676 [==============================] - 121s 179ms/step - loss: 0.1390 - accuracy: 0.9491 - val_loss: 1.0608 - val_accuracy: 0.7667\n",
            "Epoch 3/5\n",
            "676/676 [==============================] - 121s 179ms/step - loss: 0.0491 - accuracy: 0.9831 - val_loss: 1.2925 - val_accuracy: 0.7667\n",
            "Epoch 4/5\n",
            "676/676 [==============================] - 121s 178ms/step - loss: 0.0448 - accuracy: 0.9861 - val_loss: 1.3538 - val_accuracy: 0.7400\n",
            "Epoch 5/5\n",
            "676/676 [==============================] - 120s 178ms/step - loss: 0.0182 - accuracy: 0.9932 - val_loss: 1.0249 - val_accuracy: 0.7600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff0ea0334d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtxMV998g8hZ",
        "outputId": "1325d088-fade-449a-a1b9-4598b52b375c"
      },
      "source": [
        "Counter(labels_train_k)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 4000, 1: 2165, 2: 4650})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VFZjurCWnt8"
      },
      "source": [
        "results = model.predict([X_test[0],X_test[1],X_test[2]], batch_size=16)\n",
        "predictions = np.argmax(results,axis=1)\n",
        "asc_laptop_test_df['predictions_1'] = label_encoder.inverse_transform(predictions)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5fky2y-4kUP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VtQ1_jZ4kyR"
      },
      "source": [
        "## ASC BERT - Vary training data size = 1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqfBcM974_ak",
        "outputId": "1ad7a308-190a-4327-fbfb-0ec8c01f059b"
      },
      "source": [
        "print('starting training size',len(asc_laptop_train))\n",
        "print('total labeled data',len(asc_laptop_train)+len(asc_laptop_dev)+len(asc_laptop_test))\n",
        "var_size = 1000\n",
        "print('new starting training size',var_size)\n",
        "print('new total labeled data',var_size+len(asc_laptop_dev)+len(asc_laptop_test))\n",
        "var_asc_laptop_train = dict()\n",
        "for size in range(var_size):\n",
        "  # samples with replacement\n",
        "  key,val = random.choice(list(asc_laptop_train.items()))\n",
        "  var_asc_laptop_train[key] = val\n"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting training size 2163\n",
            "total labeled data 2951\n",
            "new starting training size 1000\n",
            "new total labeled data 1788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls0VmAi44kyU",
        "outputId": "aeb867fe-02c7-4910-eef2-210b49aeed8f"
      },
      "source": [
        "batch_sentences = [val['sentence'] for key, val in var_asc_laptop_train.items()]*5\n",
        "batch_sentences.extend([val['sentence'] for key, val in asc_laptop_dev.items()])\n",
        "batch_sentences.extend([val['sentence'] for key, val in asc_laptop_test.items()])\n",
        "train_size = len(var_asc_laptop_train)*5\n",
        "dev_size = len(asc_laptop_dev)\n",
        "test_size = len(asc_laptop_test)\n",
        "print(train_size)\n",
        "print(dev_size)\n",
        "print(test_size)\n",
        "print(train_size+dev_size+test_size)"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3960\n",
            "150\n",
            "638\n",
            "4748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZxpEovN4kyV"
      },
      "source": [
        "batch_terms = [val['term'] for key, val in var_asc_laptop_train.items()]*5\n",
        "batch_terms.extend([val['term'] for key, val in asc_laptop_dev.items()])\n",
        "batch_terms.extend([val['term'] for key, val in asc_laptop_test.items()])"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-Z3RYyF4kyV"
      },
      "source": [
        "batch_label = [val['polarity'] for key, val in var_asc_laptop_train.items()]*5\n",
        "batch_label.extend([val['polarity'] for key, val in asc_laptop_dev.items()])\n",
        "batch_label.extend([val['polarity'] for key, val in asc_laptop_test.items()])"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE1uRDmC4kyT"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtKzXn9o4kyV"
      },
      "source": [
        "max_length=50\n",
        "bert_inputs = tokenizer(batch_terms, batch_sentences, padding=True, truncation=True, max_length=max_length, return_tensors=\"tf\")"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUwLidAj4kyV",
        "outputId": "92a4f010-35d9-43ed-a516-338f4d287927"
      },
      "source": [
        "label_encoder = LabelEncoder().fit(batch_label)\n",
        "ascLabels = label_encoder.transform(batch_label)\n",
        "label_encoder.classes_\n",
        "batch_label[:5]\n",
        "ascLabels[:5]"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['negative', 'neutral', 'positive'], dtype='<U8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['positive', 'positive', 'neutral', 'positive', 'positive']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 1, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s19lFAvz4kyW",
        "outputId": "80111f0b-cd54-4f23-f5c5-b714acc76a9d"
      },
      "source": [
        "bert_inputs"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(4748, 50), dtype=int32, numpy=\n",
              "array([[  101,  2686,   102, ...,     0,     0,     0],\n",
              "       [  101, 13151,   102, ...,     0,     0,     0],\n",
              "       [  101,  6046,   102, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  101,  3645,  1022, ...,     0,     0,     0],\n",
              "       [  101, 14743,   102, ...,     0,     0,     0],\n",
              "       [  101, 10453,   102, ...,     0,     0,     0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(4748, 50), dtype=int32, numpy=\n",
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(4748, 50), dtype=int32, numpy=\n",
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHx5z4CZ4kyW"
      },
      "source": [
        "trainSentence_ids = bert_inputs['input_ids'][:train_size]\n",
        "trainMasks = bert_inputs['attention_mask'][:train_size]\n",
        "trainSequence_ids = bert_inputs['token_type_ids'][:train_size]\n",
        "\n",
        "devSentence_ids = bert_inputs['input_ids'][train_size:train_size+dev_size]\n",
        "devMasks = bert_inputs['attention_mask'][train_size:train_size+dev_size]\n",
        "devSequence_ids = bert_inputs['token_type_ids'][train_size:train_size+dev_size]\n",
        "\n",
        "testSentence_ids = bert_inputs['input_ids'][train_size+dev_size:]\n",
        "testMasks = bert_inputs['attention_mask'][train_size+dev_size:]\n",
        "testSequence_ids = bert_inputs['token_type_ids'][train_size+dev_size:]\n",
        "\n",
        "ascLabels_train = ascLabels[:train_size]\n",
        "ascLabels_dev = ascLabels[train_size:train_size+dev_size]\n",
        "ascLabels_test = ascLabels[train_size+dev_size:]\n",
        "\n",
        "X_train = np.array([trainSentence_ids,trainMasks,trainSequence_ids])\n",
        "X_dev = np.array([devSentence_ids,devMasks,devSequence_ids])\n",
        "X_test = np.array([testSentence_ids,testMasks,testSequence_ids])\n",
        "\n",
        "ascLabels_train = np.array(ascLabels_train)\n",
        "ascLabels_dev = np.array(ascLabels_dev)\n",
        "ascLabels_test = np.array(ascLabels_test)"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ_0oHso4kyW"
      },
      "source": [
        "# Use a parameter pair k_start, k_end to look at slices. This helps with quick tests.\n",
        "\n",
        "k_start = 0\n",
        "k_end = -1\n",
        "\n",
        "if k_end == -1:\n",
        "    k_end_train = X_train[0].shape[0]\n",
        "    k_end_dev = X_dev[0].shape[0]\n",
        "    k_end_test = X_test[0].shape[0]\n",
        "else:\n",
        "    k_end_train = k_end_test = k_end_dev = k_end\n",
        "    \n",
        "\n",
        "\n",
        "bert_inputs_train_k = [X_train[0][k_start:k_end_train], X_train[1][k_start:k_end_train], \n",
        "                       X_train[2][k_start:k_end_train]]\n",
        "bert_inputs_dev_k = [X_dev[0][k_start:k_end_dev], X_dev[1][k_start:k_end_dev], \n",
        "                      X_dev[2][k_start:k_end_dev]]\n",
        "bert_inputs_test_k = [X_test[0][k_start:k_end_test], X_test[1][k_start:k_end_test], \n",
        "                      X_test[2][k_start:k_end_test]]\n",
        "\n",
        "\n",
        "labels_train_k = ascLabels_train[k_start:k_end_train]\n",
        "labels_dev_k = ascLabels_dev[k_start:k_end_dev]\n",
        "labels_test_k = ascLabels_test[k_start:k_end_test]"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ggsgCy44kyX"
      },
      "source": [
        "train_all = [bert_inputs_train_k, labels_train_k]\n",
        "dev_all = [bert_inputs_dev_k, labels_dev_k]\n",
        "test_all = [bert_inputs_test_k, labels_test_k]"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-v-D_484kyX",
        "outputId": "74a6e8c2-f745-4203-9d39-bf732b0fb5d0"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "model = asc_model(max_length+1,train_layers=-1, optimizer=optimizer)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "model.fit(bert_inputs_train_k,labels_train_k ,validation_data=(bert_inputs_dev_k, labels_dev_k), epochs=5, batch_size=16)"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Let us check the shape of the BERT layer output: KerasTensor(type_spec=TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), name='tf_bert_model/bert/pooler/dense/Tanh:0', description=\"created by layer 'tf_bert_model'\")\n",
            "pred:  KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name=None), name='asc/Softmax:0', description=\"created by layer 'asc'\")\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_ids[0][0]                  \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          393728      tf_bert_model[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 512)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "asc (Dense)                     (None, 3)            1539        dropout_37[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 109,877,507\n",
            "Trainable params: 109,877,507\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "248/248 [==============================] - 61s 191ms/step - loss: 0.7307 - accuracy: 0.6781 - val_loss: 0.9240 - val_accuracy: 0.6800\n",
            "Epoch 2/5\n",
            "248/248 [==============================] - 45s 182ms/step - loss: 0.1122 - accuracy: 0.9641 - val_loss: 1.2181 - val_accuracy: 0.7733\n",
            "Epoch 3/5\n",
            "248/248 [==============================] - 45s 180ms/step - loss: 0.0470 - accuracy: 0.9889 - val_loss: 1.2008 - val_accuracy: 0.7667\n",
            "Epoch 4/5\n",
            "248/248 [==============================] - 45s 180ms/step - loss: 0.0517 - accuracy: 0.9840 - val_loss: 1.4079 - val_accuracy: 0.7200\n",
            "Epoch 5/5\n",
            "248/248 [==============================] - 45s 180ms/step - loss: 0.0226 - accuracy: 0.9924 - val_loss: 1.4726 - val_accuracy: 0.7533\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff36f32c410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDpT3Fpo4kyY",
        "outputId": "147f3ecf-7b0c-4311-8f6e-ee5241e900cd"
      },
      "source": [
        "Counter(labels_train_k)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 1520, 1: 780, 2: 1660})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXBZUymm4kyY"
      },
      "source": [
        "results = model.predict([X_test[0],X_test[1],X_test[2]], batch_size=16)\n",
        "predictions = np.argmax(results,axis=1)\n",
        "asc_laptop_test_df['predictions_2_1000'] = label_encoder.inverse_transform(predictions)\n"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XMV6-ZQAe9w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGtb3BmiAgrB"
      },
      "source": [
        "## ASC BERT - Vary training data size = 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrRxM9mBAgrC",
        "outputId": "c082f58b-d3e8-4239-92f0-f37cdef72ebf"
      },
      "source": [
        "print('starting training size',len(asc_laptop_train))\n",
        "print('total labeled data',len(asc_laptop_train)+len(asc_laptop_dev)+len(asc_laptop_test))\n",
        "var_size = 100\n",
        "print('new starting training size',var_size)\n",
        "print('new total labeled data',var_size+len(asc_laptop_dev)+len(asc_laptop_test))\n",
        "var_asc_laptop_train = dict()\n",
        "for size in range(var_size):\n",
        "  # samples with replacement\n",
        "  key,val = random.choice(list(asc_laptop_train.items()))\n",
        "  var_asc_laptop_train[key] = val\n"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting training size 2163\n",
            "total labeled data 2951\n",
            "new starting training size 100\n",
            "new total labeled data 888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYmV_p5bAgrC",
        "outputId": "3345b253-3251-4962-926c-823443a70e4c"
      },
      "source": [
        "batch_sentences = [val['sentence'] for key, val in var_asc_laptop_train.items()]*5\n",
        "batch_sentences.extend([val['sentence'] for key, val in asc_laptop_dev.items()])\n",
        "batch_sentences.extend([val['sentence'] for key, val in asc_laptop_test.items()])\n",
        "train_size = len(var_asc_laptop_train)*5\n",
        "dev_size = len(asc_laptop_dev)\n",
        "test_size = len(asc_laptop_test)\n",
        "print(train_size)\n",
        "print(dev_size)\n",
        "print(test_size)\n",
        "print(train_size+dev_size+test_size)"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3980\n",
            "150\n",
            "638\n",
            "4768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_atc1iuAgrD"
      },
      "source": [
        "batch_terms = [val['term'] for key, val in var_asc_laptop_train.items()]*5\n",
        "batch_terms.extend([val['term'] for key, val in asc_laptop_dev.items()])\n",
        "batch_terms.extend([val['term'] for key, val in asc_laptop_test.items()])"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W9v1GbsAgrD"
      },
      "source": [
        "batch_label = [val['polarity'] for key, val in var_asc_laptop_train.items()]*5\n",
        "batch_label.extend([val['polarity'] for key, val in asc_laptop_dev.items()])\n",
        "batch_label.extend([val['polarity'] for key, val in asc_laptop_test.items()])"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79fBDherAgrD"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArB3pdiLAgrD"
      },
      "source": [
        "max_length=50\n",
        "bert_inputs = tokenizer(batch_terms, batch_sentences, padding=True, truncation=True, max_length=max_length, return_tensors=\"tf\")"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLrSpxF6AgrD",
        "outputId": "37c816a4-2341-467c-a544-ee56e0752643"
      },
      "source": [
        "label_encoder = LabelEncoder().fit(batch_label)\n",
        "ascLabels = label_encoder.transform(batch_label)\n",
        "label_encoder.classes_\n",
        "batch_label[:5]\n",
        "ascLabels[:5]"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['negative', 'neutral', 'positive'], dtype='<U8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['positive', 'neutral', 'positive', 'neutral', 'positive']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 2, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a14q6kr5AgrE",
        "outputId": "b7a35848-343b-4348-8503-250e233cbafd"
      },
      "source": [
        "bert_inputs"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(4768, 50), dtype=int32, numpy=\n",
              "array([[  101,  3177,   102, ...,     0,     0,     0],\n",
              "       [  101,  3898,   102, ...,     0,     0,     0],\n",
              "       [  101,  4586, 16240, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  101,  3645,  1022, ...,     0,     0,     0],\n",
              "       [  101, 14743,   102, ...,     0,     0,     0],\n",
              "       [  101, 10453,   102, ...,     0,     0,     0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(4768, 50), dtype=int32, numpy=\n",
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(4768, 50), dtype=int32, numpy=\n",
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRwBidIbAgrE"
      },
      "source": [
        "trainSentence_ids = bert_inputs['input_ids'][:train_size]\n",
        "trainMasks = bert_inputs['attention_mask'][:train_size]\n",
        "trainSequence_ids = bert_inputs['token_type_ids'][:train_size]\n",
        "\n",
        "devSentence_ids = bert_inputs['input_ids'][train_size:train_size+dev_size]\n",
        "devMasks = bert_inputs['attention_mask'][train_size:train_size+dev_size]\n",
        "devSequence_ids = bert_inputs['token_type_ids'][train_size:train_size+dev_size]\n",
        "\n",
        "testSentence_ids = bert_inputs['input_ids'][train_size+dev_size:]\n",
        "testMasks = bert_inputs['attention_mask'][train_size+dev_size:]\n",
        "testSequence_ids = bert_inputs['token_type_ids'][train_size+dev_size:]\n",
        "\n",
        "ascLabels_train = ascLabels[:train_size]\n",
        "ascLabels_dev = ascLabels[train_size:train_size+dev_size]\n",
        "ascLabels_test = ascLabels[train_size+dev_size:]\n",
        "\n",
        "X_train = np.array([trainSentence_ids,trainMasks,trainSequence_ids])\n",
        "X_dev = np.array([devSentence_ids,devMasks,devSequence_ids])\n",
        "X_test = np.array([testSentence_ids,testMasks,testSequence_ids])\n",
        "\n",
        "ascLabels_train = np.array(ascLabels_train)\n",
        "ascLabels_dev = np.array(ascLabels_dev)\n",
        "ascLabels_test = np.array(ascLabels_test)"
      ],
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eVUbfzhAgrE"
      },
      "source": [
        "# Use a parameter pair k_start, k_end to look at slices. This helps with quick tests.\n",
        "\n",
        "k_start = 0\n",
        "k_end = -1\n",
        "\n",
        "if k_end == -1:\n",
        "    k_end_train = X_train[0].shape[0]\n",
        "    k_end_dev = X_dev[0].shape[0]\n",
        "    k_end_test = X_test[0].shape[0]\n",
        "else:\n",
        "    k_end_train = k_end_test = k_end_dev = k_end\n",
        "    \n",
        "\n",
        "\n",
        "bert_inputs_train_k = [X_train[0][k_start:k_end_train], X_train[1][k_start:k_end_train], \n",
        "                       X_train[2][k_start:k_end_train]]\n",
        "bert_inputs_dev_k = [X_dev[0][k_start:k_end_dev], X_dev[1][k_start:k_end_dev], \n",
        "                      X_dev[2][k_start:k_end_dev]]\n",
        "bert_inputs_test_k = [X_test[0][k_start:k_end_test], X_test[1][k_start:k_end_test], \n",
        "                      X_test[2][k_start:k_end_test]]\n",
        "\n",
        "\n",
        "labels_train_k = ascLabels_train[k_start:k_end_train]\n",
        "labels_dev_k = ascLabels_dev[k_start:k_end_dev]\n",
        "labels_test_k = ascLabels_test[k_start:k_end_test]"
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1AlHjDBAgrF"
      },
      "source": [
        "train_all = [bert_inputs_train_k, labels_train_k]\n",
        "dev_all = [bert_inputs_dev_k, labels_dev_k]\n",
        "test_all = [bert_inputs_test_k, labels_test_k]"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ldcbi48AgrF",
        "outputId": "b0ae5a6c-be37-4fb9-d200-bb418ea97743"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "model = asc_model(max_length+1,train_layers=-1, optimizer=optimizer)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "model.fit(bert_inputs_train_k,labels_train_k ,validation_data=(bert_inputs_dev_k, labels_dev_k), epochs=5, batch_size=16)"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Let us check the shape of the BERT layer output: KerasTensor(type_spec=TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), name='tf_bert_model/bert/pooler/dense/Tanh:0', description=\"created by layer 'tf_bert_model'\")\n",
            "pred:  KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name=None), name='asc/Softmax:0', description=\"created by layer 'asc'\")\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_ids[0][0]                  \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          393728      tf_bert_model[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 512)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "asc (Dense)                     (None, 3)            1539        dropout_37[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 109,877,507\n",
            "Trainable params: 109,877,507\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "249/249 [==============================] - 62s 192ms/step - loss: 0.8103 - accuracy: 0.6120 - val_loss: 0.8417 - val_accuracy: 0.7200\n",
            "Epoch 2/5\n",
            "249/249 [==============================] - 45s 181ms/step - loss: 0.1330 - accuracy: 0.9607 - val_loss: 0.9740 - val_accuracy: 0.7533\n",
            "Epoch 3/5\n",
            "249/249 [==============================] - 45s 181ms/step - loss: 0.0511 - accuracy: 0.9841 - val_loss: 1.2309 - val_accuracy: 0.7467\n",
            "Epoch 4/5\n",
            "249/249 [==============================] - 45s 181ms/step - loss: 0.0296 - accuracy: 0.9901 - val_loss: 1.5335 - val_accuracy: 0.6867\n",
            "Epoch 5/5\n",
            "249/249 [==============================] - 45s 180ms/step - loss: 0.0109 - accuracy: 0.9971 - val_loss: 1.6924 - val_accuracy: 0.7400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff265226c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6GEHCFCAgrF",
        "outputId": "ecffec20-13d6-449e-85c8-2d0afa683712"
      },
      "source": [
        "Counter(labels_train_k)"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 1415, 1: 820, 2: 1745})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpXXWCisAgrG"
      },
      "source": [
        "results = model.predict([X_test[0],X_test[1],X_test[2]], batch_size=16)\n",
        "predictions = np.argmax(results,axis=1)\n",
        "asc_laptop_test_df['predictions_3_100'] = label_encoder.inverse_transform(predictions)\n"
      ],
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK1ps1leC5Ug"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYflCWyZC6PQ"
      },
      "source": [
        "## ASC BERT - Vary training data size = 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1HxWLotC6PS",
        "outputId": "5a37ef8b-2a26-4e0b-f34e-12ca16b68772"
      },
      "source": [
        "print('starting training size',len(asc_laptop_train))\n",
        "print('total labeled data',len(asc_laptop_train)+len(asc_laptop_dev)+len(asc_laptop_test))\n",
        "var_size = 50\n",
        "print('new starting training size',var_size)\n",
        "print('new total labeled data',var_size+len(asc_laptop_dev)+len(asc_laptop_test))\n",
        "var_asc_laptop_train = dict()\n",
        "for size in range(var_size):\n",
        "  # samples with replacement\n",
        "  key,val = random.choice(list(asc_laptop_train.items()))\n",
        "  var_asc_laptop_train[key] = val\n"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting training size 2163\n",
            "total labeled data 2951\n",
            "new starting training size 50\n",
            "new total labeled data 838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KZyJ8jdC6PS",
        "outputId": "5a635781-823c-458f-d6a5-8591092b790c"
      },
      "source": [
        "batch_sentences = [val['sentence'] for key, val in var_asc_laptop_train.items()]*5\n",
        "batch_sentences.extend([val['sentence'] for key, val in asc_laptop_dev.items()])\n",
        "batch_sentences.extend([val['sentence'] for key, val in asc_laptop_test.items()])\n",
        "train_size = len(var_asc_laptop_train)*5\n",
        "dev_size = len(asc_laptop_dev)\n",
        "test_size = len(asc_laptop_test)\n",
        "print(train_size)\n",
        "print(dev_size)\n",
        "print(test_size)\n",
        "print(train_size+dev_size+test_size)"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250\n",
            "150\n",
            "638\n",
            "1038\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg7Jvu9xC6PT"
      },
      "source": [
        "batch_terms = [val['term'] for key, val in var_asc_laptop_train.items()]*5\n",
        "batch_terms.extend([val['term'] for key, val in asc_laptop_dev.items()])\n",
        "batch_terms.extend([val['term'] for key, val in asc_laptop_test.items()])"
      ],
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvIaMVIWC6PT"
      },
      "source": [
        "batch_label = [val['polarity'] for key, val in var_asc_laptop_train.items()]*5\n",
        "batch_label.extend([val['polarity'] for key, val in asc_laptop_dev.items()])\n",
        "batch_label.extend([val['polarity'] for key, val in asc_laptop_test.items()])"
      ],
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDH3YWygC6PT"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lW6IgRjC6PU"
      },
      "source": [
        "max_length=50\n",
        "bert_inputs = tokenizer(batch_terms, batch_sentences, padding=True, truncation=True, max_length=max_length, return_tensors=\"tf\")"
      ],
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MclZex1uC6PU",
        "outputId": "9d04d01f-a133-498e-df69-7fedacd857e9"
      },
      "source": [
        "label_encoder = LabelEncoder().fit(batch_label)\n",
        "ascLabels = label_encoder.transform(batch_label)\n",
        "label_encoder.classes_\n",
        "batch_label[:5]\n",
        "ascLabels[:5]"
      ],
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['negative', 'neutral', 'positive'], dtype='<U8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 269
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neutral', 'positive', 'negative', 'positive', 'positive']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 269
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 0, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icFqPtfJC6PU",
        "outputId": "60d19bce-9cb1-4eed-918c-a32471176f8f"
      },
      "source": [
        "bert_inputs"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(1038, 50), dtype=int32, numpy=\n",
              "array([[  101,  7829, 11122, ...,     0,     0,     0],\n",
              "       [  101,  3216,   102, ...,     0,     0,     0],\n",
              "       [  101,  2773,   102, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  101,  3645,  1022, ...,     0,     0,     0],\n",
              "       [  101, 14743,   102, ...,     0,     0,     0],\n",
              "       [  101, 10453,   102, ...,     0,     0,     0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1038, 50), dtype=int32, numpy=\n",
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1038, 50), dtype=int32, numpy=\n",
              "array([[1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0],\n",
              "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X6-dhmdC6PV"
      },
      "source": [
        "trainSentence_ids = bert_inputs['input_ids'][:train_size]\n",
        "trainMasks = bert_inputs['attention_mask'][:train_size]\n",
        "trainSequence_ids = bert_inputs['token_type_ids'][:train_size]\n",
        "\n",
        "devSentence_ids = bert_inputs['input_ids'][train_size:train_size+dev_size]\n",
        "devMasks = bert_inputs['attention_mask'][train_size:train_size+dev_size]\n",
        "devSequence_ids = bert_inputs['token_type_ids'][train_size:train_size+dev_size]\n",
        "\n",
        "testSentence_ids = bert_inputs['input_ids'][train_size+dev_size:]\n",
        "testMasks = bert_inputs['attention_mask'][train_size+dev_size:]\n",
        "testSequence_ids = bert_inputs['token_type_ids'][train_size+dev_size:]\n",
        "\n",
        "ascLabels_train = ascLabels[:train_size]\n",
        "ascLabels_dev = ascLabels[train_size:train_size+dev_size]\n",
        "ascLabels_test = ascLabels[train_size+dev_size:]\n",
        "\n",
        "X_train = np.array([trainSentence_ids,trainMasks,trainSequence_ids])\n",
        "X_dev = np.array([devSentence_ids,devMasks,devSequence_ids])\n",
        "X_test = np.array([testSentence_ids,testMasks,testSequence_ids])\n",
        "\n",
        "ascLabels_train = np.array(ascLabels_train)\n",
        "ascLabels_dev = np.array(ascLabels_dev)\n",
        "ascLabels_test = np.array(ascLabels_test)"
      ],
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGGEa1DTC6PV"
      },
      "source": [
        "# Use a parameter pair k_start, k_end to look at slices. This helps with quick tests.\n",
        "\n",
        "k_start = 0\n",
        "k_end = -1\n",
        "\n",
        "if k_end == -1:\n",
        "    k_end_train = X_train[0].shape[0]\n",
        "    k_end_dev = X_dev[0].shape[0]\n",
        "    k_end_test = X_test[0].shape[0]\n",
        "else:\n",
        "    k_end_train = k_end_test = k_end_dev = k_end\n",
        "    \n",
        "\n",
        "\n",
        "bert_inputs_train_k = [X_train[0][k_start:k_end_train], X_train[1][k_start:k_end_train], \n",
        "                       X_train[2][k_start:k_end_train]]\n",
        "bert_inputs_dev_k = [X_dev[0][k_start:k_end_dev], X_dev[1][k_start:k_end_dev], \n",
        "                      X_dev[2][k_start:k_end_dev]]\n",
        "bert_inputs_test_k = [X_test[0][k_start:k_end_test], X_test[1][k_start:k_end_test], \n",
        "                      X_test[2][k_start:k_end_test]]\n",
        "\n",
        "\n",
        "labels_train_k = ascLabels_train[k_start:k_end_train]\n",
        "labels_dev_k = ascLabels_dev[k_start:k_end_dev]\n",
        "labels_test_k = ascLabels_test[k_start:k_end_test]"
      ],
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV_c8DuBC6PV"
      },
      "source": [
        "train_all = [bert_inputs_train_k, labels_train_k]\n",
        "dev_all = [bert_inputs_dev_k, labels_dev_k]\n",
        "test_all = [bert_inputs_test_k, labels_test_k]"
      ],
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "MB9ATbq4C6PW",
        "outputId": "94e45fd5-5cb0-41b7-cbdf-516e1014c247"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "model = asc_model(max_length+1,train_layers=-1, optimizer=optimizer)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n",
        "model.fit(bert_inputs_train_k,labels_train_k ,validation_data=(bert_inputs_dev_k, labels_dev_k), epochs=5, batch_size=16)"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-276-52d6c417a22d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masc_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_inputs_train_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_train_k\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_inputs_dev_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_dev_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-275-0a05e778e256>\u001b[0m in \u001b[0;36masc_model\u001b[0;34m(max_input_length, train_layers, optimizer)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# the former. (See https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mbert_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Freeze layers, i.e. only train number of layers specified, starting from the top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1269\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdummy_inputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# build the network with dummy inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1271\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdummy_inputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# build the network with dummy inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Error retrieving file {resolved_archive_file}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_hidden_states\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m         )\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_tf_bert.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs_embeds\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m             \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m         )\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1006\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2708\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2709\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2710\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2711\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2712\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_tf_bert.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m             )\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         caching_device=caching_device)\n\u001b[0m\u001b[1;32m    640\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m       \u001b[0;31m# TODO(fchollet): in the future, this should be handled at the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m   def _variable_v2_call(cls,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                         shape=None):\n\u001b[1;32m    198\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2616\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2617\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2618\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2619\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2620\u001b[0m     return variables.RefVariable(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1583\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1585\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m   def _init_from_args(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1710\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m               \u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1713\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointInitialValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/initializers/initializers_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \"\"\"\n\u001b[1;32m    352\u001b[0m     return super(TruncatedNormal, self).__call__(\n\u001b[0;32m--> 353\u001b[0;31m         shape, dtype=_get_dtype(dtype), **kwargs)\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m       \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_PARTITION_SHAPE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m     return self._random_generator.truncated_normal(shape, self.mean,\n\u001b[0;32m--> 489\u001b[0;31m                                                    self.stddev, dtype)\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36mtruncated_normal\u001b[0;34m(self, shape, mean, stddev, dtype)\u001b[0m\n\u001b[1;32m   1089\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m     return op(\n\u001b[0;32m-> 1091\u001b[0;31m         shape=shape, mean=mean, stddev=stddev, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[0;31m# Compatibility aliases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mtruncated_normal\u001b[0;34m(shape, mean, stddev, dtype, seed, name)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0mseed1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     rnd = gen_random_ops.truncated_normal(\n\u001b[0;32m--> 197\u001b[0;31m         shape_tensor, dtype, seed=seed1, seed2=seed2)\n\u001b[0m\u001b[1;32m    198\u001b[0m     \u001b[0mmul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstddev_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_random_ops.py\u001b[0m in \u001b[0;36mtruncated_normal\u001b[0;34m(shape, dtype, seed, seed2, name)\u001b[0m\n\u001b[1;32m    895\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[30522,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:TruncatedNormal]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlcdwuXiC6PW"
      },
      "source": [
        "Counter(labels_train_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3brDo9QwC6PW"
      },
      "source": [
        "results = model.predict([X_test[0],X_test[1],X_test[2]], batch_size=16)\n",
        "predictions = np.argmax(results,axis=1)\n",
        "asc_laptop_test_df['predictions_4_10'] = label_encoder.inverse_transform(predictions)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMJXAQ6sWnt8"
      },
      "source": [
        "## ASC evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kbGX2Z1Wnt9",
        "outputId": "517086e9-d597-4446-e9d0-bea88c18253c"
      },
      "source": [
        "def get_asc_eval(y_true, y_pred):\n",
        "    print(confusion_matrix(y_true,y_pred,labels=['negative','neutral','positive']))\n",
        "    print(classification_report(y_true,y_pred,labels=['negative','neutral','positive']))\n",
        "get_asc_eval(asc_laptop_test_df.polarity,asc_laptop_test_df.predictions)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 61  45  22]\n",
            " [ 32  81  56]\n",
            " [ 18  66 257]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.55      0.48      0.51       128\n",
            "     neutral       0.42      0.48      0.45       169\n",
            "    positive       0.77      0.75      0.76       341\n",
            "\n",
            "    accuracy                           0.63       638\n",
            "   macro avg       0.58      0.57      0.57       638\n",
            "weighted avg       0.63      0.63      0.63       638\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l34PneCnWnt9",
        "outputId": "de4c4c34-d4ca-4342-c19e-232a968ab14b"
      },
      "source": [
        "get_asc_eval(asc_laptop_test_df.polarity,asc_laptop_test_df.predictions_1)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[102  14  12]\n",
            " [ 50  74  45]\n",
            " [ 18  21 302]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.60      0.80      0.68       128\n",
            "     neutral       0.68      0.44      0.53       169\n",
            "    positive       0.84      0.89      0.86       341\n",
            "\n",
            "    accuracy                           0.75       638\n",
            "   macro avg       0.71      0.71      0.69       638\n",
            "weighted avg       0.75      0.75      0.74       638\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLTb-Boz2obE",
        "outputId": "55a71168-3adc-4a58-b6b1-8227b5892dac"
      },
      "source": [
        "get_asc_eval(asc_laptop_test_df.polarity,asc_laptop_test_df['predictions_2_1000']) "
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[107  12   9]\n",
            " [ 55  73  41]\n",
            " [ 27  20 294]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.57      0.84      0.68       128\n",
            "     neutral       0.70      0.43      0.53       169\n",
            "    positive       0.85      0.86      0.86       341\n",
            "\n",
            "    accuracy                           0.74       638\n",
            "   macro avg       0.71      0.71      0.69       638\n",
            "weighted avg       0.75      0.74      0.74       638\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHzZF0TyAIok",
        "outputId": "ca82a4b3-a3a2-45c3-c11d-19d2d9df2724"
      },
      "source": [
        "get_asc_eval(asc_laptop_test_df.polarity,asc_laptop_test_df['predictions_3_100']) "
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[106   9  13]\n",
            " [ 53  73  43]\n",
            " [ 26  16 299]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.57      0.83      0.68       128\n",
            "     neutral       0.74      0.43      0.55       169\n",
            "    positive       0.84      0.88      0.86       341\n",
            "\n",
            "    accuracy                           0.75       638\n",
            "   macro avg       0.72      0.71      0.69       638\n",
            "weighted avg       0.76      0.75      0.74       638\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmn4GtIYB8dr"
      },
      "source": [
        "get_asc_eval(asc_laptop_test_df.polarity,asc_laptop_test_df['predictions_4_10']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv3a-jKtFIs4"
      },
      "source": [
        "## Evaluate samples that are well / poorly predicted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izt84rb1GXtY"
      },
      "source": [
        "def explore_asc(pred_col):\n",
        "  # do we have any that are wildly incorrect?\n",
        "  with pd.option_context('display.max_colwidth', None):\n",
        "    print('negative >> positive')\n",
        "    display(asc_laptop_test_df[(asc_laptop_test_df.polarity == 'negative') & (asc_laptop_test_df[pred_col] == 'positive')][['term','sentence']])\n",
        "    print('positive >> negative')\n",
        "    display(asc_laptop_test_df[(asc_laptop_test_df.polarity == 'positive') & (asc_laptop_test_df[pred_col] == 'negative')][['term','sentence']])\n",
        "  # give me back ones that are move in/out neutral\n",
        "  assess = asc_laptop_test_df[(asc_laptop_test_df.polarity!= asc_laptop_test_df[pred_col])]\n",
        "  display(assess.groupby(['polarity',pred_col]).size())\n",
        "  display(assess.groupby(['polarity',pred_col]).size() / assess.shape[0])\n"
      ],
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T3XX23MRGlhc",
        "outputId": "89d6bbcf-5f8f-4241-dd15-9c9ec4b2aad3"
      },
      "source": [
        "explore_asc('predictions')"
      ],
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>962:1_1</th>\n",
              "      <td>support</td>\n",
              "      <td>Unfortunately, it runs XP and Microsoft is dropping support next April.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>609:1_0</th>\n",
              "      <td>price</td>\n",
              "      <td>I had the same reasons as most PC users: the price, the overbearing restrictions of OSX and lack of support for games.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>477:1_0</th>\n",
              "      <td>function</td>\n",
              "      <td>My wife was so excited to open the box, but quickly came to see that it did not function as it should.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1009:1_2</th>\n",
              "      <td>pad</td>\n",
              "      <td>I had to buy a wireless mouse to go with it, as I am old school and hate the pad, but knew that before I bought it, now it works great, need to get adjusted to the key board, as I am used to a bigger one and pounding.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>609:1_2</th>\n",
              "      <td>OSX</td>\n",
              "      <td>I had the same reasons as most PC users: the price, the overbearing restrictions of OSX and lack of support for games.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>609:1_1</th>\n",
              "      <td>support for games</td>\n",
              "      <td>I had the same reasons as most PC users: the price, the overbearing restrictions of OSX and lack of support for games.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>834:1_1</th>\n",
              "      <td>USB3</td>\n",
              "      <td>A veryimportant feature is Firewire 800 which in my experience works better then USB3 (in PC enabled with USB3)I was not originally sold on the MAC OS I felt it was inferior in many ways To Windows 7.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181:1_0</th>\n",
              "      <td>OS</td>\n",
              "      <td>After fumbling around with the OS I started searching the internet for a fix and found a number of forums on fixing the issue.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160:19_0</th>\n",
              "      <td>Apple \"Help\"</td>\n",
              "      <td>Apple \"Help\" is a mixed bag.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>786:876_0</th>\n",
              "      <td>aluminum</td>\n",
              "      <td>Yes, that's a good thing, but it's made from aluminum that scratches easily.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>834:1_2</th>\n",
              "      <td>MAC OS</td>\n",
              "      <td>A veryimportant feature is Firewire 800 which in my experience works better then USB3 (in PC enabled with USB3)I was not originally sold on the MAC OS I felt it was inferior in many ways To Windows 7.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298:29_0</th>\n",
              "      <td>usb ports</td>\n",
              "      <td>Only 2 usb ports...seems kind of...limited.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>787:619_0</th>\n",
              "      <td>install Mountain Lion</td>\n",
              "      <td>I had to install Mountain Lion and it took a good two hours.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>928:1_1</th>\n",
              "      <td>speaker quality</td>\n",
              "      <td>I like coming back to Mac OS but this laptop is lacking in speaker quality compared to my $400  old HP laptop.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>469:1_1</th>\n",
              "      <td>Windows</td>\n",
              "      <td>From the speed to the multi touch gestures this operating system beats Windows easily.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1144:1_0</th>\n",
              "      <td>tech support</td>\n",
              "      <td>tech support would not fix the problem unless I bought your plan for $150 plus.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460:1_1</th>\n",
              "      <td>power down</td>\n",
              "      <td>Then the system would many times not power down without a forced power-off.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460:1_0</th>\n",
              "      <td>system</td>\n",
              "      <td>Then the system would many times not power down without a forced power-off.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>479:5_0</th>\n",
              "      <td>application</td>\n",
              "      <td>Having heard from friends and family about how reliable a Mac product is, I never expected to have an application crash within the first month, but I did.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7:21_0</th>\n",
              "      <td>logic board</td>\n",
              "      <td>More likely it will require replacing the logic board once they admit they have a problem and come up with a solution.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414:1_0</th>\n",
              "      <td>Mac OS</td>\n",
              "      <td>MAYBE The Mac OS improvement were not The product they Want to offer.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286:15_1</th>\n",
              "      <td>AppleCare</td>\n",
              "      <td>I opted for the SquareTrade 3-Year Computer Accidental Protection Warranty ($1500-2000) which also support \"accidents\" like drops and spills that are NOT covered by AppleCare.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            term                                                                                                                                                                                                                   sentence\n",
              "962:1_1                  support                                                                                                                                                    Unfortunately, it runs XP and Microsoft is dropping support next April.\n",
              "609:1_0                    price                                                                                                     I had the same reasons as most PC users: the price, the overbearing restrictions of OSX and lack of support for games.\n",
              "477:1_0                 function                                                                                                                     My wife was so excited to open the box, but quickly came to see that it did not function as it should.\n",
              "1009:1_2                     pad  I had to buy a wireless mouse to go with it, as I am old school and hate the pad, but knew that before I bought it, now it works great, need to get adjusted to the key board, as I am used to a bigger one and pounding.\n",
              "609:1_2                      OSX                                                                                                     I had the same reasons as most PC users: the price, the overbearing restrictions of OSX and lack of support for games.\n",
              "609:1_1        support for games                                                                                                     I had the same reasons as most PC users: the price, the overbearing restrictions of OSX and lack of support for games.\n",
              "834:1_1                     USB3                   A veryimportant feature is Firewire 800 which in my experience works better then USB3 (in PC enabled with USB3)I was not originally sold on the MAC OS I felt it was inferior in many ways To Windows 7.\n",
              "181:1_0                       OS                                                                                             After fumbling around with the OS I started searching the internet for a fix and found a number of forums on fixing the issue.\n",
              "160:19_0            Apple \"Help\"                                                                                                                                                                                               Apple \"Help\" is a mixed bag.\n",
              "786:876_0               aluminum                                                                                                                                               Yes, that's a good thing, but it's made from aluminum that scratches easily.\n",
              "834:1_2                   MAC OS                   A veryimportant feature is Firewire 800 which in my experience works better then USB3 (in PC enabled with USB3)I was not originally sold on the MAC OS I felt it was inferior in many ways To Windows 7.\n",
              "298:29_0               usb ports                                                                                                                                                                                Only 2 usb ports...seems kind of...limited.\n",
              "787:619_0  install Mountain Lion                                                                                                                                                               I had to install Mountain Lion and it took a good two hours.\n",
              "928:1_1          speaker quality                                                                                                             I like coming back to Mac OS but this laptop is lacking in speaker quality compared to my $400  old HP laptop.\n",
              "469:1_1                  Windows                                                                                                                                     From the speed to the multi touch gestures this operating system beats Windows easily.\n",
              "1144:1_0            tech support                                                                                                                                            tech support would not fix the problem unless I bought your plan for $150 plus.\n",
              "460:1_1               power down                                                                                                                                                Then the system would many times not power down without a forced power-off.\n",
              "460:1_0                   system                                                                                                                                                Then the system would many times not power down without a forced power-off.\n",
              "479:5_0              application                                                                 Having heard from friends and family about how reliable a Mac product is, I never expected to have an application crash within the first month, but I did.\n",
              "7:21_0               logic board                                                                                                     More likely it will require replacing the logic board once they admit they have a problem and come up with a solution.\n",
              "414:1_0                   Mac OS                                                                                                                                                      MAYBE The Mac OS improvement were not The product they Want to offer.\n",
              "286:15_1               AppleCare                                            I opted for the SquareTrade 3-Year Computer Accidental Protection Warranty ($1500-2000) which also support \"accidents\" like drops and spills that are NOT covered by AppleCare."
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>211:1_1</th>\n",
              "      <td>craftmanship</td>\n",
              "      <td>Apple is unmatched in product quality,aesthetics,craftmanship, and customer service.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211:1_0</th>\n",
              "      <td>aesthetics</td>\n",
              "      <td>Apple is unmatched in product quality,aesthetics,craftmanship, and customer service.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211:1_3</th>\n",
              "      <td>customer service</td>\n",
              "      <td>Apple is unmatched in product quality,aesthetics,craftmanship, and customer service.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211:1_2</th>\n",
              "      <td>product quality</td>\n",
              "      <td>Apple is unmatched in product quality,aesthetics,craftmanship, and customer service.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>843:1_0</th>\n",
              "      <td>number pad on the keyboard</td>\n",
              "      <td>The Dell Inspiron is fast and has a number pad on the keyboard, which I miss on my Apple laptops.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958:1_0</th>\n",
              "      <td>price tag</td>\n",
              "      <td>Other than not being a fan of click pads (industry standard these days) and the lousy internal speakers, it's hard for me to find things about this notebook I don't like, especially considering the $350 price tag.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280:11_1</th>\n",
              "      <td>res</td>\n",
              "      <td>Screen - although some people might complain about low res which I think is ridiculous.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280:11_0</th>\n",
              "      <td>Screen</td>\n",
              "      <td>Screen - although some people might complain about low res which I think is ridiculous.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500:1_2</th>\n",
              "      <td>windows</td>\n",
              "      <td>I was a little worry at first because I don't have a lot of experience with os.x and windows has always been second nature to me after many years of using windows.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62:1_0</th>\n",
              "      <td>windows</td>\n",
              "      <td>I switched to this because I wanted something different, even though I miss windows.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26:4_0</th>\n",
              "      <td>Logic board</td>\n",
              "      <td>Logic board utterly fried, cried, and laid down and died.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>959:1_0</th>\n",
              "      <td>performed</td>\n",
              "      <td>My last laptop was a 17\" ASUS gaming machine, which performed admirably, but having since built my own desktop and really settling into the college life, I found myself wanting something smaller and less cumbersome, not to mention that the ASUS had been slowly developing problems ever since I bought it about 4 years ago.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>900:1_0</th>\n",
              "      <td>boots up</td>\n",
              "      <td>I can't believe how quiet the hard drive is and how quick this thing boots up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>900:1_1</th>\n",
              "      <td>hard drive</td>\n",
              "      <td>I can't believe how quiet the hard drive is and how quick this thing boots up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>755:1_0</th>\n",
              "      <td>ssd drive</td>\n",
              "      <td>After replacing the spinning hard disk with an ssd drive, my mac is just flying.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>615:1_1</th>\n",
              "      <td>touch</td>\n",
              "      <td>Soft touch, anodized aluminum with laser cut precision and no flaws.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>615:1_0</th>\n",
              "      <td>anodized aluminum</td>\n",
              "      <td>Soft touch, anodized aluminum with laser cut precision and no flaws.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>842:1_0</th>\n",
              "      <td>warranty</td>\n",
              "      <td>And mine had broke but I sent it in under warranty-no problems.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                term                                                                                                                                                                                                                                                                                                                            sentence\n",
              "211:1_1                 craftmanship                                                                                                                                                                                                                                                Apple is unmatched in product quality,aesthetics,craftmanship, and customer service.\n",
              "211:1_0                   aesthetics                                                                                                                                                                                                                                                Apple is unmatched in product quality,aesthetics,craftmanship, and customer service.\n",
              "211:1_3             customer service                                                                                                                                                                                                                                                Apple is unmatched in product quality,aesthetics,craftmanship, and customer service.\n",
              "211:1_2              product quality                                                                                                                                                                                                                                                Apple is unmatched in product quality,aesthetics,craftmanship, and customer service.\n",
              "843:1_0   number pad on the keyboard                                                                                                                                                                                                                                   The Dell Inspiron is fast and has a number pad on the keyboard, which I miss on my Apple laptops.\n",
              "958:1_0                    price tag                                                                                                               Other than not being a fan of click pads (industry standard these days) and the lousy internal speakers, it's hard for me to find things about this notebook I don't like, especially considering the $350 price tag.\n",
              "280:11_1                         res                                                                                                                                                                                                                                             Screen - although some people might complain about low res which I think is ridiculous.\n",
              "280:11_0                      Screen                                                                                                                                                                                                                                             Screen - although some people might complain about low res which I think is ridiculous.\n",
              "500:1_2                      windows                                                                                                                                                                 I was a little worry at first because I don't have a lot of experience with os.x and windows has always been second nature to me after many years of using windows.\n",
              "62:1_0                       windows                                                                                                                                                                                                                                                I switched to this because I wanted something different, even though I miss windows.\n",
              "26:4_0                   Logic board                                                                                                                                                                                                                                                                           Logic board utterly fried, cried, and laid down and died.\n",
              "959:1_0                    performed  My last laptop was a 17\" ASUS gaming machine, which performed admirably, but having since built my own desktop and really settling into the college life, I found myself wanting something smaller and less cumbersome, not to mention that the ASUS had been slowly developing problems ever since I bought it about 4 years ago.\n",
              "900:1_0                     boots up                                                                                                                                                                                                                                                      I can't believe how quiet the hard drive is and how quick this thing boots up.\n",
              "900:1_1                   hard drive                                                                                                                                                                                                                                                      I can't believe how quiet the hard drive is and how quick this thing boots up.\n",
              "755:1_0                    ssd drive                                                                                                                                                                                                                                                    After replacing the spinning hard disk with an ssd drive, my mac is just flying.\n",
              "615:1_1                        touch                                                                                                                                                                                                                                                                Soft touch, anodized aluminum with laser cut precision and no flaws.\n",
              "615:1_0            anodized aluminum                                                                                                                                                                                                                                                                Soft touch, anodized aluminum with laser cut precision and no flaws.\n",
              "842:1_0                     warranty                                                                                                                                                                                                                                                                     And mine had broke but I sent it in under warranty-no problems."
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "polarity  predictions\n",
              "negative  neutral        45\n",
              "          positive       22\n",
              "neutral   negative       32\n",
              "          positive       56\n",
              "positive  negative       18\n",
              "          neutral        66\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "polarity  predictions\n",
              "negative  neutral        0.188285\n",
              "          positive       0.092050\n",
              "neutral   negative       0.133891\n",
              "          positive       0.234310\n",
              "positive  negative       0.075314\n",
              "          neutral        0.276151\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VElWpUS7LITm",
        "outputId": "a8539a45-eeaa-4ca9-c6d6-e7a97a0eaa93"
      },
      "source": [
        "explore_asc('predictions_1')"
      ],
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative >> positive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1040:1_0</th>\n",
              "      <td>keyboard</td>\n",
              "      <td>It feels cheap, the keyboard is not very sensitive.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>969:5_0</th>\n",
              "      <td>backlit keys</td>\n",
              "      <td>The only thing I miss is that my old Alienware laptop had backlit keys.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1141:1_0</th>\n",
              "      <td>Windows 8</td>\n",
              "      <td>I would have given it 5 starts was it not for the fact that it had Windows 8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1150:1_0</th>\n",
              "      <td>Windows 8</td>\n",
              "      <td>I do not like too much Windows 8.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562:1_0</th>\n",
              "      <td>Windows 8</td>\n",
              "      <td>Did not enjoy the new Windows 8 and touchscreen functions.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>968:5_0</th>\n",
              "      <td>voice recording</td>\n",
              "      <td>Also, in using the built-in camera, my voice recording for my vlog sounds like the interplanetary transmissions in the \"Star Wars\" saga.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1063:166_0</th>\n",
              "      <td>Windows 8</td>\n",
              "      <td>Lastly, Windows 8 is annoying.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75:1_2</th>\n",
              "      <td>Mac OS 10.9</td>\n",
              "      <td>this Mac Mini does not have a built-in mic, and it would seem that its Mac OS 10.9 does not handle external microphones properly.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>716:1_0</th>\n",
              "      <td>word program</td>\n",
              "      <td>It is very fast and has everything that I need except for a word program.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>786:31_0</th>\n",
              "      <td>Cost</td>\n",
              "      <td>Cost is more as compared to other brands.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17:4_0</th>\n",
              "      <td>OSX</td>\n",
              "      <td>However, I can refute that OSX is \"FAST\".</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1107:1_0</th>\n",
              "      <td>Windows 8</td>\n",
              "      <td>Biggest complaint is Windows 8 .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       term                                                                                                                                  sentence\n",
              "1040:1_0           keyboard                                                                                       It feels cheap, the keyboard is not very sensitive.\n",
              "969:5_0        backlit keys                                                                   The only thing I miss is that my old Alienware laptop had backlit keys.\n",
              "1141:1_0          Windows 8                                                              I would have given it 5 starts was it not for the fact that it had Windows 8\n",
              "1150:1_0          Windows 8                                                                                                         I do not like too much Windows 8.\n",
              "562:1_0           Windows 8                                                                                Did not enjoy the new Windows 8 and touchscreen functions.\n",
              "968:5_0     voice recording  Also, in using the built-in camera, my voice recording for my vlog sounds like the interplanetary transmissions in the \"Star Wars\" saga.\n",
              "1063:166_0        Windows 8                                                                                                            Lastly, Windows 8 is annoying.\n",
              "75:1_2          Mac OS 10.9         this Mac Mini does not have a built-in mic, and it would seem that its Mac OS 10.9 does not handle external microphones properly.\n",
              "716:1_0        word program                                                                 It is very fast and has everything that I need except for a word program.\n",
              "786:31_0               Cost                                                                                                 Cost is more as compared to other brands.\n",
              "17:4_0                  OSX                                                                                                 However, I can refute that OSX is \"FAST\".\n",
              "1107:1_0          Windows 8                                                                                                          Biggest complaint is Windows 8 ."
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "positive >> negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>202:1_1</th>\n",
              "      <td>fans</td>\n",
              "      <td>The Mac mini is about 8x smaller than my old computer which is a huge bonus and runs very quiet, actually the fans aren't audible unlike my old pc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>958:1_0</th>\n",
              "      <td>price tag</td>\n",
              "      <td>Other than not being a fan of click pads (industry standard these days) and the lousy internal speakers, it's hard for me to find things about this notebook I don't like, especially considering the $350 price tag.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29:172_0</th>\n",
              "      <td>Mac tutorials</td>\n",
              "      <td>Mac tutorials do help.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1009:1_0</th>\n",
              "      <td>works</td>\n",
              "      <td>I had to buy a wireless mouse to go with it, as I am old school and hate the pad, but knew that before I bought it, now it works great, need to get adjusted to the key board, as I am used to a bigger one and pounding.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280:11_1</th>\n",
              "      <td>res</td>\n",
              "      <td>Screen - although some people might complain about low res which I think is ridiculous.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26:4_0</th>\n",
              "      <td>Logic board</td>\n",
              "      <td>Logic board utterly fried, cried, and laid down and died.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>908:1_0</th>\n",
              "      <td>battery cycle count</td>\n",
              "      <td>However, it did not have any scratches, ZERO battery cycle count (pretty surprised), and all the hardware seemed to be working perfectly.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>787:444_0</th>\n",
              "      <td>portable computing</td>\n",
              "      <td>The criticism has waned, and now I'd be the first to recommend an Air for truly portable computing.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25:1_0</th>\n",
              "      <td>footprint</td>\n",
              "      <td>It's silent and has a very small footprint on my desk.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29:1027_1</th>\n",
              "      <td>heat output</td>\n",
              "      <td>The nicest  part is the low heat output and ultra quiet operation.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>928:1_0</th>\n",
              "      <td>Mac OS</td>\n",
              "      <td>I like coming back to Mac OS but this laptop is lacking in speaker quality compared to my $400  old HP laptop.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568:1_0</th>\n",
              "      <td>price</td>\n",
              "      <td>The price is 200 dollars down.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>792:2_0</th>\n",
              "      <td>baterry</td>\n",
              "      <td>The baterry is very longer.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>842:1_0</th>\n",
              "      <td>warranty</td>\n",
              "      <td>And mine had broke but I sent it in under warranty-no problems.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>671:1_1</th>\n",
              "      <td>price</td>\n",
              "      <td>Price was higher when purchased on MAC when compared to price showing on PC when I bought this product.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48:1_0</th>\n",
              "      <td>Hardware performance</td>\n",
              "      <td>It's not inexpensive but the Hardware performance is impressive for a computer this small.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294:0_0</th>\n",
              "      <td>functionality</td>\n",
              "      <td>You just cannot beat the functionality of an Apple device.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29:319_0</th>\n",
              "      <td>USB3 Peripherals</td>\n",
              "      <td>USB3 Peripherals are noticably less expensive than the ThunderBolt ones.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           term                                                                                                                                                                                                                   sentence\n",
              "202:1_1                    fans                                                                         The Mac mini is about 8x smaller than my old computer which is a huge bonus and runs very quiet, actually the fans aren't audible unlike my old pc\n",
              "958:1_0               price tag      Other than not being a fan of click pads (industry standard these days) and the lousy internal speakers, it's hard for me to find things about this notebook I don't like, especially considering the $350 price tag.\n",
              "29:172_0          Mac tutorials                                                                                                                                                                                                     Mac tutorials do help.\n",
              "1009:1_0                  works  I had to buy a wireless mouse to go with it, as I am old school and hate the pad, but knew that before I bought it, now it works great, need to get adjusted to the key board, as I am used to a bigger one and pounding.\n",
              "280:11_1                    res                                                                                                                                    Screen - although some people might complain about low res which I think is ridiculous.\n",
              "26:4_0              Logic board                                                                                                                                                                  Logic board utterly fried, cried, and laid down and died.\n",
              "908:1_0     battery cycle count                                                                                  However, it did not have any scratches, ZERO battery cycle count (pretty surprised), and all the hardware seemed to be working perfectly.\n",
              "787:444_0    portable computing                                                                                                                        The criticism has waned, and now I'd be the first to recommend an Air for truly portable computing.\n",
              "25:1_0                footprint                                                                                                                                                                     It's silent and has a very small footprint on my desk.\n",
              "29:1027_1           heat output                                                                                                                                                         The nicest  part is the low heat output and ultra quiet operation.\n",
              "928:1_0                  Mac OS                                                                                                             I like coming back to Mac OS but this laptop is lacking in speaker quality compared to my $400  old HP laptop.\n",
              "568:1_0                   price                                                                                                                                                                                             The price is 200 dollars down.\n",
              "792:2_0                 baterry                                                                                                                                                                                                The baterry is very longer.\n",
              "842:1_0                warranty                                                                                                                                                            And mine had broke but I sent it in under warranty-no problems.\n",
              "671:1_1                   price                                                                                                                    Price was higher when purchased on MAC when compared to price showing on PC when I bought this product.\n",
              "48:1_0     Hardware performance                                                                                                                                 It's not inexpensive but the Hardware performance is impressive for a computer this small.\n",
              "294:0_0           functionality                                                                                                                                                                 You just cannot beat the functionality of an Apple device.\n",
              "29:319_0       USB3 Peripherals                                                                                                                                                   USB3 Peripherals are noticably less expensive than the ThunderBolt ones."
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "polarity  predictions_1\n",
              "negative  neutral          14\n",
              "          positive         12\n",
              "neutral   negative         50\n",
              "          positive         45\n",
              "positive  negative         18\n",
              "          neutral          21\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "polarity  predictions_1\n",
              "negative  neutral          0.08750\n",
              "          positive         0.07500\n",
              "neutral   negative         0.31250\n",
              "          positive         0.28125\n",
              "positive  negative         0.11250\n",
              "          neutral          0.13125\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW7mvWOYLLVI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}